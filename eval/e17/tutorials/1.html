<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">

<!-- Mirrored from classic.scraperwiki.com/docs/python/python_css_guide/ by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 27 Mar 2014 18:35:55 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
	<title>
    Documentation / HTML parsing guide
 | ScraperWiki</title>
	<link rel="image_src" href="https://media.scraperwiki.com/images/footer_tractor.png" />

    

    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jqueryui/1.9.2/jquery-ui.min.js"></script>

	

	<script type="text/javascript" src="https://media.scraperwiki.com/CACHE/js/373245081b58.js"></script>

  <script type="text/javascript" src="https://media.scraperwiki.com/js/archive.js"></script>

	
    <script type="text/javascript" src="https://media.scraperwiki.com/js/ZeroClipboard.js?"></script>
    <script src="https://media.scraperwiki.com/js/jquery.colortip.js" type="text/javascript"></script>


	<link rel="stylesheet" href="https://media.scraperwiki.com/CACHE/css/a0e031914b27.css" type="text/css" />
	<!--[if IE 7]>
    <link rel="stylesheet" type="text/css" href="https://media.scraperwiki.com/css/ie7.css?08b6f6b01032" />
	<![endif]-->

	<link rel="stylesheet" type="text/css" href="https://media.scraperwiki.com/css/archive.css" />

	
    <link href="https://media.scraperwiki.com/css/jquery.colortip.css" rel="stylesheet" type="text/css" />

	

	
	    <script type="text/javascript">

	      var _gaq = _gaq || [];
	      _gaq.push(['_setAccount', 'UA-21451224-1']);
          _gaq.push(['_setDomainName', 'none']);
          _gaq.push(['_setCustomVar', 1, 'Registered User', 'False', 2]);
          
	      _gaq.push(['_trackPageview']);

	      (function() {
	        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	      })();

	    </script>
	
</head>


<body class="docs python python_css_guide">





    <noscript>
        <div id="alert_outer" class="error">
        	<div id="alert_inner">
        	    Oh no! You need to enable Javascript to use ScraperWiki.
                <a href="http://support.google.com/bin/answer.py?hl=en&amp;answer=23852">Find out how</a>
            </div>
        </div>
    </noscript>
    <!--[if lte IE 6]>
        <div id="alert_outer" class="error">
        	<div id="alert_inner">
        	    Oh no! Your browser is too old to use ScraperWiki.
                <a href="http://browserchoice.eu">Click here to upgrade</a>
            </div>
        </div>
    <![endif]-->
    <!--[if IE 7]>
        <div id="alert_outer" class="warning">
        	<div id="alert_inner">
        	    Still on IE7? For the best experience, you should upgrade your browser.
                <a href="http://browserchoice.eu">Cripes, upgrade me!</a>
            </div>
        </div>
    <![endif]-->

	<div id="nav">
        <h1><a href="../../../index.html">ScraperWiki</a></h1>
        <ul class="supernav">
            <li class="code active default"><a href="../../../index.html">ScraperWiki Classic</a></li>
            
            <li class="new"><a href="https://scraperwiki.com/">New ScraperWiki <img src="https://media.scraperwiki.com/images/nav-external-link-icon.gif" width="8" height="9" alt="" style="margin-left: 2px;"></a></li>
        </ul>
        <div class="subnav code">
            <ul>
                <li class="browse"><a href="../../../browse/scrapers/index.html">Browse Classic Archive</a></li>
                <li class="docs"><a href="../../index.html">Classic Documentation</a></li>
                <li class="search"><form action="http://google.com/search" method="get" class="google-search"><input type="text" class="text" name="q" value="Search scrapers..."/></form></li>
            </ul>
        </div>
        
    </div>

    <div id="archive_placeholder_top"></div>


	<div id="header">
    
<h2><a href="../index.html">Documentation</a> / <em>HTML parsing guide</em></h2>
	<p>Extract data from HTML using CSS selectors in Python</p>
	
	</div>


    <div id="archive_placeholder_middle"></div>


    <div id="content">
        

  <div class="documentationpage">
    
    <div id="help_content">
    
        

<p class="language_chooser">
    
    <a href="../index.html" class="back" title="Back to documentation homepage">
        <img src="https://media.scraperwiki.com//images/icons/back_arrow.png" width="16" height="16" alt="" />
        Back to contents</a>
    
    
    
    <a href="../../php/php_css_guide/index.html" class="php" title="Switch to PHP documentation"><img src="https://media.scraperwiki.com//images/icons/php.png" width="16" height="16" alt="" /> PHP</a>
    
    
    <a href="index.html" class="python" title="Switch to Python documentation"><img src="https://media.scraperwiki.com//images/icons/python.png" width="16" height="16" alt="" /> Python</a>
    
    
    <a href="../../ruby/ruby_css_guide/index.html" class="ruby" title="Switch to Ruby documentation"><img src="https://media.scraperwiki.com//images/icons/ruby.png" width="16" height="16" alt="" /> Ruby</a>
    
    <strong>Choose a language:</strong>
   <br class="clear"/>
</p>


		
      		<p>The easiest and most familiar way to extract data from HTML web pages is to use
"CSS selectors". These are part of the same rules which in web stylesheets are
used to describe the spacing, colour and layout of web pages.</p>

<p>For more details, read the <a href="http://lxml.de/lxmlhtml.html">lxml documentation</a>,
or the <a href="http://www.w3.org/TR/CSS2/selector.html">CSS selector specification</a>.</p>

<h2>Getting started</h2>

<p>Grab the HTML web page, and parse the HTML using lxml.</p>

<code>import scraperwiki
import lxml.html
html = scraperwiki.scrape("https://scraperwiki.com/")
root = lxml.html.fromstring(html)
</code>

<p>Select all <b>&lt;a></b> elements that are inside <b>&lt;div class="featured"></b>.
These queries work the same way as CSS stylesheets or jQuery. They are called
CSS selectors, and are quite powerful.
</p>

<code>for el in root.cssselect("div.featured a"):
    print el
</code>


<p>Print out all of a tag and its contents as HTML.</p>
<code>    print lxml.html.tostring(el)</code>

<p>Read attributes, such as the target of the <b>&lt;a&gt;</b> tags.</p>
<code>    print el.attrib['href']</code>


<h2>Simple text extraction</h2>

<p>Select the first <b>&lt;strong></b> element inside <b>&lt;div id="footer_inner"></b>.</p>
<code>el = root.cssselect("div#footer_inner strong")[0]
print el
</code>

<p>Extract the text from inside the tag.</p>
<code>print el.text</code>

<p>Any trailing text from just after the close tag.</p>
<code>print el.tail</code>


<h2>Deep text extraction</h2>

<p>Get all text recursively, throwing away any child tags.</p>
<code>eg = lxml.html.fromstring('&lt;h2&gt;A thing &lt;b&gt;goes boom&lt;/b&gt; up &lt;i&gt;on &lt;em&gt;the tree&lt;/em&gt;&lt;/i&gt;&lt;/h2&gt;')
print eg.text_content() # 'A thing goes boom up on the tree'
</code>

<p>Sometimes you have nearly pure text elements that still have &lt;i&gt; and &lt;b&gt; elements which you want to retain.  
Such an element can be extracted using a recursive function.</p>
<code>def ctext(el):
    result = [ ]
    if el.text:
        result.append(el.text)
    for sel in el:
        assert sel.tag in ["b", "i"]
        result.append("&lt;"+sel.tag+"&gt;")
        result.append(ctext(sel))
        result.append("&lt;/"+sel.tag+"&gt;")
        if sel.tail:
            result.append(sel.tail)
    return "".join(result)
</code>

<p>This gives an error if there are other unexpected elements, such as &lt;em&gt;.</p>
    <code>print ctext(eg)</code>

<h2>Finding data manually</h2>

<p>Iterate down through the elements in the document and see the tags and attributes on each element.</p>
<code>for el in root:
    print el.tag
    for el2 in el:
        print "--", el2.tag, el2.attrib
</code>

<p>Navigate around the document.</p>
<code>eg = lxml.html.fromstring('&lt;h2&gt;A thing &lt;b&gt;goes boom&lt;/b&gt; up &lt;i&gt;on &lt;em&gt;the tree&lt;/em&gt;&lt;/i&gt;&lt;/h2&gt;')
print eg[1].tag                # i
print eg[1].getparent().tag    # h2
print eg[1].getprevious().tag  # b
print eg[1].getnext()          # None
print eg[1].getchildren()      # [&lt;Element em&gt;]
</code>



    	
	
    </div>
  </div>


    </div>


    <div id="archive_placeholder_bottom"></div>

    <script type="text/javascript" defer="defer">
        
    // Add copy button bumf to every <code> element
    $("code").wrap('<div class="code_outer" style="position:relative"/>').after('<a href="#" class="copy_to_clipboard" title="Click to copy this snippet to your clipboard">Copy</a>');

    // Make the copy button work
    ZeroClipboard.setMoviePath( 'https://media.scraperwiki.com/js/ZeroClipboard.swf' );
    $(".copy_to_clipboard").each(function(i) {
        
        var el = $(this);
        var parent = el.parent();
        var code = el.siblings('code');

        // add eleven spaces to end of first line, so Copy button never obscures text
        // (this was easiest way to do it without altering the overflow scrolling behaviour)
        var t = code.text().replace(/\n/, "           \n")
        code.text(t);
            
        clip = new ZeroClipboard.Client();
        clip.setText(code.text().replace(/\s+\n/, "\n"));
        clip.setHandCursor( true );

        clip.addEventListener( 'complete', function(client, text) {
            //  alert("Copied text to clipboard: " + text );
            el.text('Copied').addClass('copied');
            el.focus(); // so flash doesn't have keyboard focus afterwards
        });
        
        clip.addEventListener( 'onMouseOver', function(client, text) {
            if(el.is('.copied')){
                el.text('Copy').removeClass('copied');
            }
        });
        
        clip.glue(el[0], parent[0]);
        
    });

    // popup bubbles on index page doclinks
    $(document).ready(function(){
        $('.doclink a[title]').colorTip();
    });


    </script>

    
    
    



</body>


<!-- Mirrored from classic.scraperwiki.com/docs/python/python_css_guide/ by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 27 Mar 2014 18:35:55 GMT -->
</html>
