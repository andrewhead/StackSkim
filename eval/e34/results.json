[
  {
    "kind": "customsearch#result", 
    "title": "I Don't Need No Stinking API: Web Scraping For Fun and Profit", 
    "displayLink": "blog.hartleybrody.com", 
    "htmlTitle": "I Don&#39;t Need No Stinking API: Web <b>Scraping</b> For Fun and Profit", 
    "formattedUrl": "https://blog.hartleybrody.com/web-scraping/", 
    "htmlFormattedUrl": "https://blog.hartleybrody.com/web-<b>scraping</b>/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0", 
          "fb:admins": "1428990153"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "244", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcS15HxYqsv6-Thr11nSPk789jF4molgyK0KNdUUZt391xh7KIrLj9QdsqKI", 
          "height": "206"
        }
      ], 
      "cse_image": [
        {
          "src": "https://blog.hartleybrody.com/guide-to-web-scraping/img/web-scraping-ebook.png"
        }
      ]
    }, 
    "snippet": "Here's how (and why) you should consider web scraping. ... If you've ever \nneeded to pull data from a third party website, chances are you started by \nchecking to\u00a0...", 
    "htmlSnippet": "Here&#39;s how (and why) you should consider web <b>scraping</b>. ... If you&#39;ve ever <br>\nneeded to pull data from a third party <b>website</b>, chances are you started by <br>\nchecking to&nbsp;...", 
    "link": "https://blog.hartleybrody.com/web-scraping/", 
    "cacheId": "gcElod5t1roJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "import.io | Web Data Platform & Free Web Scraping Tool", 
    "displayLink": "import.io", 
    "htmlTitle": "import.io | Web Data Platform &amp; Free Web <b>Scraping</b> Tool", 
    "formattedUrl": "https://import.io/", 
    "htmlFormattedUrl": "https://import.io/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "259", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcTMORibTv6WjLMsOCy_ToIehgSYRRh_G5PaNSVq8jirEPB4YKty-zW5UAW3", 
          "height": "194"
        }
      ], 
      "cse_image": [
        {
          "src": "https://i.ytimg.com/vi/cdmsTxu45-c/hqdefault.jpg"
        }
      ]
    }, 
    "snippet": "Turn the web into data, today. Transform any website into a table of data or an \nAPI in minutes without even writing any code with our free app.", 
    "htmlSnippet": "Turn the web into data, today. Transform any <b>website</b> into a table of data or an <br>\nAPI in minutes without even writing any code with our free app.", 
    "link": "https://import.io/", 
    "cacheId": "zEEspCk8wCIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web scraping - Wikipedia, the free encyclopedia", 
    "displayLink": "en.wikipedia.org", 
    "htmlTitle": "Web <b>scraping</b> - Wikipedia, the free encyclopedia", 
    "formattedUrl": "en.wikipedia.org/wiki/Web_scraping", 
    "htmlFormattedUrl": "en.wikipedia.org/wiki/Web_<b>scraping</b>", 
    "snippet": "Web scraping (web harvesting or web data extraction) is a computer software \ntechnique of extracting information from websites. Usually, such software \nprograms\u00a0...", 
    "htmlSnippet": "Web <b>scraping</b> (web harvesting or web data extraction) is a computer software <br>\ntechnique of extracting information from <b>websites</b>. Usually, such software <br>\nprograms&nbsp;...", 
    "link": "http://en.wikipedia.org/wiki/Web_scraping", 
    "cacheId": "uyRVllVQ2KYJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "api - What's the best way of scraping data from a website? - Stack ...", 
    "displayLink": "stackoverflow.com", 
    "htmlTitle": "api - What&#39;s the best way of <b>scraping</b> data from a <b>website</b>? - Stack <b>...</b>", 
    "formattedUrl": "stackoverflow.com/.../whats-the-best-way-of-scraping-data-from-a-website", 
    "htmlFormattedUrl": "stackoverflow.com/.../whats-the-best-way-of-<b>scraping</b>-data-from-a-<b>website</b>", 
    "pagemap": {
      "answer": [
        {
          "text": "You will definitely want to start with a good web scraping framework. Later on you may decide that they are too limiting and you can put together your own stack of libraries but without a lot...", 
          "upvotecount": "60"
        }, 
        {
          "text": "Yes you can do it yourself. It is just a matter of grabbing the sources of the page and parsing them the way you want. There are various possibilities. A good combo is using python-requests...", 
          "upvotecount": "4"
        }
      ], 
      "qapage": [
        {
          "image": "http://cdn.sstatic.net/stackoverflow/img/apple-touch-icon@2.png?v=ea71a5211a91&a", 
          "description": "I need to extract some information from a website, but the website doesn\u2019t provide any API or mechanism to access that info programmatically. I've found some useful third-party tools(Kimono...", 
          "primaryimageofpage": "http://cdn.sstatic.net/stackoverflow/img/apple-touch-icon@2.png?v=ea71a5211a91&a", 
          "name": "What's the best way of scraping data from a website?", 
          "title": "What's the best way of scraping data from a website?"
        }
      ], 
      "cse_image": [
        {
          "src": "http://cdn.sstatic.net/stackoverflow/img/apple-touch-icon@2.png?v=ea71a5211a91&a"
        }
      ], 
      "metatags": [
        {
          "og:url": "http://stackoverflow.com/questions/22168883/whats-the-best-way-of-scraping-data-from-a-website", 
          "twitter:app:url:iphone": "se-zaphod://stackoverflow.com/questions/22168883/whats-the-best-way-of-scraping-data-from-a-website", 
          "twitter:app:url:ipad": "se-zaphod://stackoverflow.com/questions/22168883/whats-the-best-way-of-scraping-data-from-a-website", 
          "twitter:app:country": "US", 
          "twitter:domain": "stackoverflow.com", 
          "twitter:description": "I need to extract some information from a website, but the website doesn\u2019t provide any API or mechanism to access that info programmatically.  I've found some useful third-party tools(Kimono Labs &...", 
          "og:type": "website", 
          "twitter:app:name:iphone": "Stack Exchange iOS", 
          "twitter:app:name:ipad": "Stack Exchange iOS", 
          "twitter:app:id:ipad": "871299723", 
          "twitter:app:name:googleplay": "Stack Exchange Android", 
          "twitter:app:url:googleplay": "http://stackoverflow.com/questions/22168883/whats-the-best-way-of-scraping-data-from-a-website", 
          "twitter:card": "summary", 
          "twitter:title": "What's the best way of scraping data from a website?", 
          "twitter:app:id:googleplay": "com.stackexchange.marvin", 
          "og:image": "http://cdn.sstatic.net/stackoverflow/img/apple-touch-icon@2.png?v=ea71a5211a91&a", 
          "twitter:app:id:iphone": "871299723"
        }
      ], 
      "question": [
        {
          "answercount": "2", 
          "text": "I need to extract some information from a website, but the website doesn\u2019t provide any API or mechanism to access that info programmatically. I've found some useful third-party tools(Kimono...", 
          "image": "http://cdn.sstatic.net/stackoverflow/img/apple-touch-icon.png?v=41f6e13ade69", 
          "name": "What's the best way of scraping data from a website? [closed]", 
          "upvotecount": "16"
        }
      ]
    }, 
    "snippet": "You will definitely want to start with a good web scraping framework. Later on you \nmay decide that they are too limiting and you can put together your\u00a0...", 
    "htmlSnippet": "You will definitely want to start with a good web <b>scraping</b> framework. Later on you <br>\nmay decide that they are too limiting and you can put together your&nbsp;...", 
    "link": "http://stackoverflow.com/questions/22168883/whats-the-best-way-of-scraping-data-from-a-website", 
    "cacheId": "9Oqm2XXSL0gJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scrapy | A Fast and Powerful Scraping and Web Crawling Framework", 
    "displayLink": "scrapy.org", 
    "htmlTitle": "Scrapy | A Fast and Powerful <b>Scraping</b> and Web Crawling Framework", 
    "formattedUrl": "scrapy.org/", 
    "htmlFormattedUrl": "scrapy.org/", 
    "pagemap": {
      "metatags": [
        {
          "msapplication-tilecolor": "#da532c", 
          "msapplication-tileimage": "/favicons/mstile-144x144.png"
        }
      ]
    }, 
    "snippet": "Meet Scrapy. An open source and collaborative framework for extracting the data \nyou need from websites. In a fast, simple, yet extensible way.", 
    "htmlSnippet": "Meet Scrapy. An open source and collaborative framework for extracting the data <br>\nyou need from <b>websites</b>. In a fast, simple, yet extensible way.", 
    "link": "http://scrapy.org/", 
    "cacheId": "6lgTG3BJeJkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Automated data scraping from websites into Excel - YouTube", 
    "displayLink": "www.youtube.com", 
    "htmlTitle": "Automated data <b>scraping</b> from <b>websites</b> into Excel - YouTube", 
    "formattedUrl": "www.youtube.com/watch?v=qbOdUaf4yfI", 
    "htmlFormattedUrl": "www.youtube.com/watch?v=qbOdUaf4yfI", 
    "pagemap": {
      "videoobject": [
        {
          "isfamilyfriendly": "True", 
          "name": "Automated data scraping from websites into Excel", 
          "unlisted": "False", 
          "url": "http://www.youtube.com/watch?v=qbOdUaf4yfI", 
          "datepublished": "2012-11-03", 
          "regionsallowed": "AD,AE,AF,AG,AI,AL,AM,AO,AQ,AR,AS,AT,AU,AW,AX,AZ,BA,BB,BD,BE,BF,BG,BH,BI,BJ,BL,BM,BN,BO,BQ,BR,BS,BT,BV,BW,BY,BZ,CA,CC,CD,CF,CG,CH,CI,CK,CL,CM,CN,CO,CR,CU,CV,CW,CX,CY,CZ,DE,DJ,DK,DM,DO,DZ,EC,EE,EG,EH...", 
          "channelid": "UC-vzNYU9x8IYPk_r89mGvXA", 
          "videoid": "qbOdUaf4yfI", 
          "paid": "False", 
          "height": "720", 
          "playertype": "HTML5 Flash", 
          "width": "960", 
          "interactioncount": "126962", 
          "duration": "PT12M43S", 
          "embedurl": "https://www.youtube.com/embed/qbOdUaf4yfI", 
          "thumbnailurl": "http://i.ytimg.com/vi/qbOdUaf4yfI/maxresdefault.jpg", 
          "genre": "Education", 
          "description": "Our Excel training videos on YouTube cover formulas, functions and VBA. Useful for beginners as well as advanced learners. New upload every Thursday. For det..."
        }
      ], 
      "metatags": [
        {
          "twitter:app:name:googleplay": "YouTube", 
          "twitter:app:url:ipad": "vnd.youtube://www.youtube.com/watch?v=qbOdUaf4yfI&feature=applinks", 
          "twitter:image": "http://i.ytimg.com/vi/qbOdUaf4yfI/maxresdefault.jpg", 
          "al:web:url": "http://www.youtube.com/watch?v=qbOdUaf4yfI&feature=applinks", 
          "twitter:site": "@youtube", 
          "twitter:app:url:googleplay": "http://www.youtube.com/watch?v=qbOdUaf4yfI", 
          "fb:app_id": "87741124305", 
          "og:video:url": "https://www.youtube.com/embed/qbOdUaf4yfI", 
          "og:url": "http://www.youtube.com/watch?v=qbOdUaf4yfI", 
          "twitter:app:url:iphone": "vnd.youtube://www.youtube.com/watch?v=qbOdUaf4yfI&feature=applinks", 
          "twitter:url": "http://www.youtube.com/watch?v=qbOdUaf4yfI", 
          "al:ios:app_store_id": "544007664", 
          "title": "Automated data scraping from websites into Excel", 
          "og:video:type": "text/html", 
          "og:type": "video", 
          "al:android:package": "com.google.android.youtube", 
          "twitter:player:width": "960", 
          "og:title": "Automated data scraping from websites into Excel", 
          "twitter:title": "Automated data scraping from websites into Excel", 
          "attribution": "familycomputerclub%2Buser/", 
          "al:ios:url": "vnd.youtube://www.youtube.com/watch?v=qbOdUaf4yfI&feature=applinks", 
          "twitter:player": "https://www.youtube.com/embed/qbOdUaf4yfI", 
          "twitter:app:name:iphone": "YouTube", 
          "og:video:secure_url": "https://www.youtube.com/embed/qbOdUaf4yfI", 
          "twitter:app:name:ipad": "YouTube", 
          "twitter:app:id:ipad": "544007664", 
          "al:ios:app_name": "YouTube", 
          "og:video:height": "720", 
          "al:android:app_name": "YouTube", 
          "twitter:app:id:googleplay": "com.google.android.youtube", 
          "og:image": "http://i.ytimg.com/vi/qbOdUaf4yfI/maxresdefault.jpg", 
          "twitter:app:id:iphone": "544007664", 
          "og:site_name": "YouTube", 
          "twitter:card": "player", 
          "twitter:description": "Our Excel training videos on YouTube cover formulas, functions and VBA. Useful for beginners as well as advanced learners. New upload every Thursday. For det...", 
          "og:description": "Our Excel training videos on YouTube cover formulas, functions and VBA. Useful for beginners as well as advanced learners. New upload every Thursday. For det...", 
          "og:video:tag": "pull data from web pages", 
          "al:android:url": "vnd.youtube://www.youtube.com/watch?v=qbOdUaf4yfI&feature=applinks", 
          "og:video:width": "960", 
          "twitter:player:height": "720"
        }
      ], 
      "imageobject": [
        {
          "url": "http://i.ytimg.com/vi/qbOdUaf4yfI/maxresdefault.jpg", 
          "width": "1280", 
          "height": "720"
        }
      ], 
      "person": [
        {
          "url": "http://www.youtube.com/user/familycomputerclub"
        }, 
        {
          "url": "https://plus.google.com/110639302525481632502"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "259", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTMlF5QkFAEtxNXusq_OstA3QGwf_oAFfuj7YRR3mC9QEqiCxzoSoHTECU", 
          "height": "194"
        }
      ], 
      "cse_image": [
        {
          "src": "http://i.ytimg.com/vi/qbOdUaf4yfI/maxresdefault.jpg"
        }
      ]
    }, 
    "snippet": "Nov 3, 2012 ... You can scrape, pull or get data from websites into Excel by ... to find out how one \nor many tables or data can be scraped from the website 2.", 
    "htmlSnippet": "Nov 3, 2012 <b>...</b> You can <b>scrape</b>, pull or get data from <b>websites</b> into Excel by ... to find out how one <br>\nor many tables or data can be scraped from the <b>website</b> 2.", 
    "link": "http://www.youtube.com/watch?v=qbOdUaf4yfI", 
    "cacheId": "s5-MoemSpMMJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping websites using the Scraper extension for Chrome | School ...", 
    "displayLink": "schoolofdata.org", 
    "htmlTitle": "<b>Scraping websites</b> using the Scraper extension for Chrome | School <b>...</b>", 
    "formattedUrl": "schoolofdata.org/handbook/recipes/scraper-extension-for-chrome/", 
    "htmlFormattedUrl": "schoolofdata.org/handbook/recipes/<b>scrape</b>r-extension-for-chrome/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "362", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSQDjqREohYkTwbq1xiw0UWBkE3aR666bRYnjwqzvFLnzM13dl8DLCYzUg", 
          "height": "139"
        }
      ], 
      "cse_image": [
        {
          "src": "http://farm9.staticflickr.com/8073/8263440961_9b94e63d56_b_d.jpg"
        }
      ]
    }, 
    "snippet": "Sep 2, 2013 ... It will help you scrape a website's content and upload the results to google docs. \nWalkthrough: Scraping a website with the Scraper extension.", 
    "htmlSnippet": "Sep 2, 2013 <b>...</b> It will help you <b>scrape a website&#39;s</b> content and upload the results to google docs. <br>\nWalkthrough: <b>Scraping a website</b> with the Scraper extension.", 
    "link": "http://schoolofdata.org/handbook/recipes/scraper-extension-for-chrome/", 
    "cacheId": "QfNT1I6s19QJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to scrape data without coding - a tutorial on Import.io", 
    "displayLink": "www.interhacktives.com", 
    "htmlTitle": "<b>How to scrape</b> data without coding - a tutorial on Import.io", 
    "formattedUrl": "www.interhacktives.com/.../scrape-data-without-coding-step-step-tutorial- import-io/", 
    "htmlFormattedUrl": "www.interhacktives.com/.../<b>scrape</b>-data-without-coding-step-step-tutorial- import-io/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@Interhacktives", 
          "og:locale": "en_US", 
          "twitter:site": "@Interhacktives", 
          "fb:app_id": "307752309426050", 
          "og:url": "http://www.interhacktives.com/2014/03/06/scrape-data-without-coding-step-step-tutorial-import-io/", 
          "og:image": "http://i0.wp.com/www.interhacktives.com/wp-content/uploads/2014/03/IO.png?resize=440%2C440", 
          "author": "Aleksandra Wisniewska", 
          "twitter:image:width": "280", 
          "og:type": "article", 
          "article:modified_time": "2014-03-14T23:03:08+00:00", 
          "twitter:title": "How to scrape data without coding - a tutorial on Import.io", 
          "article:tag": "Data", 
          "article:section": "Archive", 
          "og:title": "How to scrape data without coding - a tutorial on Import.io", 
          "twitter:image:height": "150", 
          "msapplication-tileimage": "http://i0.wp.com/www.interhacktives.com/wp-content/uploads/2014/11/10520604_10205177105286589_1625184611395691805_o-546f1c52_site_icon.png?fit=114%2C114", 
          "article:author": "http://www.interhacktives.com/author/aleksandra/", 
          "article:published_time": "2014-03-06T13:06:47+00:00", 
          "viewport": "width=device-width, initial-scale=1.0", 
          "og:site_name": "#Interhacktives", 
          "twitter:card": "summary_large_image", 
          "og:description": "A step-by-step guide on how to use Import.io to scrape data without having to know how to code.", 
          "twitter:image:src": "http://i0.wp.com/www.interhacktives.com/wp-content/uploads/2014/03/IO.png?resize=280%2C150", 
          "gm-gpx-v": "3.6"
        }
      ], 
      "breadcrumb": [
        {
          "url": "Home", 
          "title": "Home"
        }, 
        {
          "url": "Archive", 
          "title": "Archive"
        }, 
        {
          "title": "How to scrape data without coding? A step by step tutorial on..."
        }
      ], 
      "article": [
        {
          "image": "http://i0.wp.com/www.interhacktives.com/wp-content/uploads/2014/03/IO.png?w=700", 
          "author": "Aleksandra Wisniewska", 
          "name": "How to scrape data without coding? A step by step tutorial on import.io", 
          "interactioncount": "UserComments:11", 
          "datecreated": "2014-03-06T13:06:47+00:00"
        }, 
        {
          "name": "How to get started with GitHub for Dummies (Journalists)", 
          "author": "Krystina Shveda", 
          "url": "How to get started with GitHub for Dummies (Journalists)", 
          "image": "http://i0.wp.com/www.interhacktives.com/wp-content/uploads/2015/05/octocat-re.jpg?resize=326%2C159", 
          "interactioncount": "UserComments:0", 
          "datecreated": "2015-05-04T20:42:43+00:00"
        }, 
        {
          "name": "Cath Levett: The Guardian Head of Graphics", 
          "author": "Jonathan Frayman", 
          "url": "Cath Levett: The Guardian Head of Graphics", 
          "image": "http://i1.wp.com/www.interhacktives.com/wp-content/uploads/2015/05/guardpoll.png?resize=326%2C159", 
          "interactioncount": "UserComments:0", 
          "datecreated": "2015-05-04T20:32:32+00:00"
        }
      ], 
      "organization": [
        {
          "url": "http://www.interhacktives.com/", 
          "name": "#Interhacktives"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "225", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTMN-Y6Fmz8RpPdJKMnmni-r89bTabTZBZrusjYThdBy7ubiotS7t1cg_M", 
          "height": "225"
        }
      ], 
      "cse_image": [
        {
          "src": "http://i0.wp.com/www.interhacktives.com/wp-content/uploads/2014/03/IO.png?resize=440%2C440"
        }
      ]
    }, 
    "snippet": "Mar 6, 2014 ... Import.io (pronounced import-eye-oh) lets you scrape data from any website into \na searchable database. It is perfect for gathering, aggregating\u00a0...", 
    "htmlSnippet": "Mar 6, 2014 <b>...</b> Import.io (pronounced import-eye-oh) lets you <b>scrape</b> data from any <b>website</b> into <br>\na searchable database. It is perfect for gathering, aggregating&nbsp;...", 
    "link": "http://www.interhacktives.com/2014/03/06/scrape-data-without-coding-step-step-tutorial-import-io/", 
    "cacheId": "SEZv68DM1aUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "7 tools for scraping - Use for datajournalism & insightful content", 
    "displayLink": "www.notprovided.eu", 
    "htmlTitle": "7 tools for <b>scraping</b> - Use for datajournalism &amp; insightful content", 
    "formattedUrl": "www.notprovided.eu/7-tools-web-scraping-use-data-journalism-creating- insightful-content/", 
    "htmlFormattedUrl": "www.notprovided.eu/7-tools-web-<b>scraping</b>-use-data-journalism-creating- insightful-content/", 
    "pagemap": {
      "metatags": [
        {
          "og:updated_time": "2015-03-11T18:58:46+00:00", 
          "og:url": "http://www.notprovided.eu/7-tools-web-scraping-use-data-journalism-creating-insightful-content/", 
          "article:section": "Technical SEO", 
          "og:type": "article", 
          "twitter:domain": "NotProvided.eu", 
          "og:site_name": "NotProvided.eu", 
          "twitter:image:src": "http://www.notprovided.eu/assets/scraper-example.jpg", 
          "twitter:card": "summary", 
          "twitter:description": "I've been using a lot of public data so I wanted to show you seven tools to easily scrape these sources and use that for creating insightful content!", 
          "og:locale": "en_US", 
          "og:description": "I've been using a lot of public data so I wanted to show you seven tools to easily scrape these sources and use that for creating insightful content!", 
          "og:image": "http://www.notprovided.eu/assets/scraper-example.jpg", 
          "og:title": "7 tools for scraping - Use for datajournalism & insightful content", 
          "twitter:title": "7 tools for scraping - Use for datajournalism & insightful content", 
          "twitter:creator": "@jbobbink", 
          "article:modified_time": "2015-03-11T18:58:46+00:00", 
          "article:published_time": "2014-01-21T19:00:21+00:00", 
          "twitter:site": "@jbobbink", 
          "viewport": "width=device-width, initial-scale=1.0, user-scalable=no"
        }
      ], 
      "person": [
        {
          "jobtitle": "International SEO"
        }
      ], 
      "article": [
        {
          "image": "http://www.notprovided.eu/assets/jan-willem-bobbink.jpg", 
          "description": "I've been using a lot of public data so I wanted to show you seven tools to easily scrape these sources and use that for creating insightful content!", 
          "name": "Seven tools for web scraping - To use for data journalism & creating insightful content", 
          "author": "Jan-Willem Bobbink"
        }
      ], 
      "postaladdress": [
        {
          "addresslocality": "Amsterdam", 
          "addressregion": "- Europe", 
          "postalcode": "9999XX", 
          "sameas": "Jan-Willem Bobbink"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "246", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRD-6WdByLy-eWT6B1NGRPwSo5clnD__9oU1H-A0YgdrVWrWQ_gAR0FrNA", 
          "height": "205"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.notprovided.eu/assets/scraper-example.jpg"
        }
      ]
    }, 
    "snippet": "Jan 21, 2014 ... Kimono has two easy ways to scrape specific URLs: just paste the URL into their \nwebsite or use their bookmark. Once you have pointed out the\u00a0...", 
    "htmlSnippet": "Jan 21, 2014 <b>...</b> Kimono has two easy ways to <b>scrape</b> specific URLs: just paste the URL into their <br>\n<b>website</b> or use their bookmark. Once you have pointed out the&nbsp;...", 
    "link": "http://www.notprovided.eu/7-tools-web-scraping-use-data-journalism-creating-insightful-content/", 
    "cacheId": "0zOwzdHDmIcJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to Scrape Websites for Data without Programming Skills ...", 
    "displayLink": "www.poynter.org", 
    "htmlTitle": "<b>How to Scrape Websites</b> for Data without Programming Skills <b>...</b>", 
    "formattedUrl": "www.poynter.org/.../how-to-scrape-websites-for-data-without-programming- skills/", 
    "htmlFormattedUrl": "www.poynter.org/.../<b>how-to-scrape</b>-<b>websites</b>-for-data-without-programming- skills/", 
    "pagemap": {
      "metatags": [
        {
          "parsely-page": "{\"title\":\"How to Scrape Websites for Data without Programming Skills\",\"link\":\"http:\\/\\/www.poynter.org\\/news\\/102589\\/how-to-scrape-websites-for-data-without-programming-skills\\/\",\"image_url\":\"\",\"type\":\"post\",\"post_id\":\"102589\",\"pub_date\":\"2010-05-11T23:09:25Z\",\"section\":\"Uncategorized\",\"author\":\"Michelle Minkoff\",\"tags\":[\"best practices\",\"best practices: reporting and writing and editing\",\"data-driven journalism\",\"e-media tidbits\",\"wtsp\"]}", 
          "wp-parsely_version": "1.6", 
          "twitter:account_id": "8383592"
        }
      ]
    }, 
    "snippet": "How to Scrape Websites for Data without Programming Skills. avatar by Michelle \nMinkoff Published May 11, 2010 7:09 pm. Searching for data to back up your\u00a0...", 
    "htmlSnippet": "<b>How to Scrape Websites</b> for Data without Programming Skills. avatar by Michelle <br>\nMinkoff Published May 11, 2010 7:09 pm. Searching for data to back up your&nbsp;...", 
    "link": "http://www.poynter.org/news/102589/how-to-scrape-websites-for-data-without-programming-skills/", 
    "cacheId": "gfPg3iumLGIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "HTML Scraping \u2014 The Hitchhiker's Guide to Python", 
    "displayLink": "docs.python-guide.org", 
    "htmlTitle": "HTML <b>Scraping</b> \u2014 The Hitchhiker&#39;s Guide to Python", 
    "formattedUrl": "docs.python-guide.org/en/latest/scenarios/scrape/", 
    "htmlFormattedUrl": "docs.python-guide.org/en/latest/scenarios/<b>scrape</b>/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=0.9, maximum-scale=0.9"
        }
      ]
    }, 
    "snippet": "Web Scraping\u00b6. Web sites are written using HTML, which means that each web \npage is a structured document. Sometimes it would be great to obtain some data\n\u00a0...", 
    "htmlSnippet": "Web <b>Scraping</b>\u00b6. Web sites are written using HTML, which means that each web <br>\npage is a structured document. Sometimes it would be great to obtain some data<br>\n&nbsp;...", 
    "link": "http://docs.python-guide.org/en/latest/scenarios/scrape/", 
    "cacheId": "1LxiUUNg0UUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Getting Data from the Web - The Data Journalism Handbook", 
    "displayLink": "datajournalismhandbook.org", 
    "htmlTitle": "Getting Data from the Web - The Data Journalism Handbook", 
    "formattedUrl": "datajournalismhandbook.org/1.0/en/getting_data_3.html", 
    "htmlFormattedUrl": "datajournalismhandbook.org/1.0/en/getting_data_3.html", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ]
    }, 
    "snippet": "During screen scraping, you're extracting structured content from a normal web ... \ncode with little or no structural information e.g. older government websites.", 
    "htmlSnippet": "During screen <b>scraping</b>, you&#39;re extracting structured content from a normal web ... <br>\ncode with little or no structural information e.g. older government <b>websites</b>.", 
    "link": "http://datajournalismhandbook.org/1.0/en/getting_data_3.html", 
    "cacheId": "wc94YiboFtUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraper", 
    "displayLink": "webscraper.io", 
    "htmlTitle": "Web Scraper", 
    "formattedUrl": "webscraper.io/", 
    "htmlFormattedUrl": "web<b>scrape</b>r.io/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "225", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQ20W4w8lxBYaYYL3Mo_ClwC03qHIpCbXk6mFmJLzczV1wRyBLcry4GB-s", 
          "height": "225"
        }
      ], 
      "cse_image": [
        {
          "src": "http://webscraper.io/images/landing/dynamic-web-pages.png"
        }
      ]
    }, 
    "snippet": "See how simple it is to scrape an e-commerce site with multi-level navigation. ... \nUnlike other scraping tools that extract data only from HTML Web Scraper can\u00a0...", 
    "htmlSnippet": "See how simple it is to <b>scrape</b> an e-commerce site with multi-level navigation. ... <br>\nUnlike other <b>scraping</b> tools that extract data only from HTML Web Scraper can&nbsp;...", 
    "link": "http://webscraper.io/", 
    "cacheId": "uvWJ3IuYpKYJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Is web scraping illegal? Depends on the meaning of the word is ...", 
    "displayLink": "www.distilnetworks.com", 
    "htmlTitle": "Is web <b>scraping</b> illegal? Depends on the meaning of the word is <b>...</b>", 
    "formattedUrl": "www.distilnetworks.com/is-web-scraping-illegal-depends-on-what-the- meaning-of-the-word-is-is/", 
    "htmlFormattedUrl": "www.distilnetworks.com/is-web-<b>scraping</b>-illegal-depends-on-what-the- meaning-of-the-word-is-is/", 
    "pagemap": {
      "metatags": [
        {
          "og:updated_time": "2015-01-18T12:22:54+00:00", 
          "og:url": "http://www.distilnetworks.com/is-web-scraping-illegal-depends-on-what-the-meaning-of-the-word-is-is/", 
          "article:section": "Blog", 
          "og:type": "article", 
          "twitter:domain": "Distil Networks", 
          "og:site_name": "Distil Networks", 
          "twitter:image:src": "http://www.distilnetworks.com/files/2013/07/clinton.jpg", 
          "twitter:card": "summary", 
          "twitter:description": "Depending on who you ask, web scraping can be loved or hated. Startups love it because it\u2019s a cheap and powerful way to gather data without the need for partnerships.", 
          "og:locale": "en_US", 
          "og:description": "Depending on who you ask, web scraping can be loved or hated. Startups love it because it\u2019s a cheap and powerful way to gather data without the need for partnerships.", 
          "twitter:title": "Is web scraping illegal? Depends on the meaning of the word is", 
          "og:image": "http://www.distilnetworks.com/files/2013/07/clinton.jpg", 
          "twitter:creator": "@ramiessaid", 
          "og:title": "Is web scraping illegal? Depends on the meaning of the word is", 
          "article:modified_time": "2015-01-18T12:22:54+00:00", 
          "article:publisher": "https://www.facebook.com/distilinc", 
          "article:tag": "AT&T Scraper,preventing website scraping,Web Scraping,web scraping lawsuits", 
          "article:published_time": "2013-07-18T14:13:54+00:00", 
          "twitter:site": "@distil", 
          "viewport": "width=device-width, initial-scale=1.0, user-scalable=no"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "301", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcT8a3M6FkIMKgTXHRnwpVjCCA8s7JWZL-jZk7qIwQuyBLQCJCDkVW_7YxY", 
          "height": "168"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.distilnetworks.com/files/2013/07/clinton.jpg"
        }
      ]
    }, 
    "snippet": "Jul 18, 2013 ... Web scraping started in a legal grey area where the use of bots to scrape a \nwebsite was simply a nuisance. Not much could be done about the\u00a0...", 
    "htmlSnippet": "Jul 18, 2013 <b>...</b> Web scraping started in a legal grey area where the use of bots to <b>scrape a</b> <br>\n<b>website</b> was simply a nuisance. Not much could be done about the&nbsp;...", 
    "link": "http://www.distilnetworks.com/is-web-scraping-illegal-depends-on-what-the-meaning-of-the-word-is-is/", 
    "cacheId": "WX_H7Pt1MqYJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping Tutorial: Learn Web Scraping - Udemy", 
    "displayLink": "www.udemy.com", 
    "htmlTitle": "Web <b>Scraping</b> Tutorial: Learn Web <b>Scraping</b> - Udemy", 
    "formattedUrl": "https://www.udemy.com/learn-web-scraping-in-minutes/", 
    "htmlFormattedUrl": "https://www.udemy.com/learn-web-<b>scraping</b>-in-minutes/", 
    "pagemap": {
      "rating": [
        {
          "average": "4.2985"
        }
      ], 
      "metatags": [
        {
          "twitter:site": "@udemy", 
          "udemy_com:instructor": "https://www.udemy.com/u/mattellsworth/", 
          "twitter:image": "https://dujk9xa5fr1wz.cloudfront.net/course/200_H/107672_35da_7.jpg", 
          "og:locale": "en_US", 
          "google-play-app": "app-id=com.udemy.android", 
          "fb:app_id": "313137469260", 
          "og:url": "https://www.udemy.com/learn-web-scraping-in-minutes/", 
          "og:image": "https://dujk9xa5fr1wz.cloudfront.net/course/200_H/107672_35da_7.jpg", 
          "title": "Web Scraping Tutorial: Learn Web Scraping - Udemy", 
          "og:type": "udemy_com:course", 
          "apple-itunes-app": "app-id=562413829", 
          "udemy_com:available": "1", 
          "og:title": "Web Scraping Tutorial: Learn Web Scraping - Udemy", 
          "twitter:title": "Web Scraping Tutorial: Learn Web Scraping - Udemy", 
          "medium": "mult", 
          "udemy_com:category": "Business", 
          "udemy_com:price": "$149", 
          "twitter:url": "https://www.udemy.com/learn-web-scraping-in-minutes/", 
          "viewport": "width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no", 
          "og:site_name": "Udemy", 
          "twitter:card": "summary", 
          "twitter:description": "No coding necessary. Now anybody can get data they need in minutes. This is a game changer for sales marketing.", 
          "og:description": "No coding necessary. Now anybody can get data they need in minutes. This is a game changer for sales marketing."
        }
      ], 
      "creativework": [
        {
          "datemodified": "2015-04-13 14:41:57"
        }
      ], 
      "review-aggregate": [
        {
          "votes": "67 ratings", 
          "itemreviewed": "Web Scraping for Sales & Growth Hacking with Import io"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "160", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcT-5WBZ3MZIxTQeiL2tb9W2nGaIYiIj7h0ULynS2cchGf7AgWOjPIGTQYA", 
          "height": "89"
        }
      ], 
      "cse_image": [
        {
          "src": "https://dujk9xa5fr1wz.cloudfront.net/course/200_H/107672_35da_7.jpg"
        }
      ]
    }, 
    "snippet": "\"Understanding how to scrape the web can be a startup employee's best asset. \n.... through another crawler to get extra details like the website for the business.", 
    "htmlSnippet": "&quot;Understanding <b>how to scrape</b> the web can be a startup employee&#39;s best asset. <br>\n.... through another crawler to get extra details like the <b>website</b> for the business.", 
    "link": "https://www.udemy.com/learn-web-scraping-in-minutes/", 
    "cacheId": "GR_4vLRVqVEJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping websites using the Scraper extension for Chrome \u2014 Data ...", 
    "displayLink": "datapatterns.readthedocs.org", 
    "htmlTitle": "<b>Scraping websites</b> using the Scraper extension for Chrome \u2014 Data <b>...</b>", 
    "formattedUrl": "https://datapatterns.readthedocs.org/.../scraper-extension-for-chrome.html", 
    "htmlFormattedUrl": "https://datapatterns.readthedocs.org/.../<b>scrape</b>r-extension-for-chrome.html", 
    "pagemap": {
      "cse_thumbnail": [
        {
          "width": "362", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSQDjqREohYkTwbq1xiw0UWBkE3aR666bRYnjwqzvFLnzM13dl8DLCYzUg", 
          "height": "139"
        }
      ], 
      "cse_image": [
        {
          "src": "http://farm9.staticflickr.com/8073/8263440961_9b94e63d56_b_d.jpg"
        }
      ]
    }, 
    "snippet": "If you are using Google Chrome there is a browser extension for scraping web \npages. It's called \u201cScraper\u201d and it is easy to use. It will help you scrape a website's\n\u00a0...", 
    "htmlSnippet": "If you are using Google Chrome there is a browser extension for scraping web <br>\npages. It&#39;s called \u201cScraper\u201d and it is easy to use. It will help you <b>scrape a website&#39;s</b><br>\n&nbsp;...", 
    "link": "https://datapatterns.readthedocs.org/en/latest/recipes/scraper-extension-for-chrome.html", 
    "cacheId": "s0FbxaFNFYsJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Kimono : Turn websites into structured APIs from your browser in ...", 
    "displayLink": "www.kimonolabs.com", 
    "htmlTitle": "Kimono : Turn <b>websites</b> into structured APIs from your browser in <b>...</b>", 
    "formattedUrl": "https://www.kimonolabs.com/", 
    "htmlFormattedUrl": "https://www.kimonolabs.com/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "80", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPF3PSsQPeT6IVmaI3dbzjDY4LKyrd_J4ruEy9qc-wHO22iolp84E_MQ", 
          "height": "80"
        }
      ], 
      "cse_image": [
        {
          "src": "https://www.kimonolabs.com/img/stopwatch.svg?v=9"
        }
      ]
    }, 
    "snippet": "No more scraping. Build an API in seconds with kimono to power your apps, \nmodels and visualizations with live data without writing any code\u00a0...", 
    "htmlSnippet": "No more <b>scraping</b>. Build an API in seconds with kimono to power your apps, <br>\nmodels and visualizations with live data without writing any code&nbsp;...", 
    "link": "https://www.kimonolabs.com/", 
    "cacheId": "isP38kS8y-cJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Introduction to Web Scraping using Scrapy and Postgres \u2013 New Coder", 
    "displayLink": "newcoder.io", 
    "htmlTitle": "Introduction to Web <b>Scraping</b> using Scrapy and Postgres \u2013 New Coder", 
    "formattedUrl": "newcoder.io/scrape/intro/", 
    "htmlFormattedUrl": "newcoder.io/<b>scrape</b>/intro/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1", 
          "author": "Lynn Root"
        }
      ]
    }, 
    "snippet": "Your favorite website doesn't have an API? Web scraping is a great alternative to \ngrabbing the data you want. This tutorial will walk you through how to make a\u00a0...", 
    "htmlSnippet": "Your favorite <b>website</b> doesn&#39;t have an API? Web <b>scraping</b> is a great alternative to <br>\ngrabbing the data you want. This tutorial will walk you through how to make a&nbsp;...", 
    "link": "http://newcoder.io/scrape/intro/", 
    "cacheId": "WdMh-x-6ZxUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping 101 with Python", 
    "displayLink": "www.gregreda.com", 
    "htmlTitle": "Web <b>Scraping</b> 101 with Python", 
    "formattedUrl": "www.gregreda.com/2013/03/03/web-scraping-101-with-python/", 
    "htmlFormattedUrl": "www.gregreda.com/2013/03/03/web-<b>scraping</b>-101-with-python/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@gjreda", 
          "og:url": "http://www.gregreda.com", 
          "twitter:domain": "gregreda.com", 
          "copyright": "\u00a9 Copyright Greg Reda, 2013 to Present", 
          "author": "Greg Reda", 
          "twitter:image": "http://www.gregreda.com/theme/images/avatar.jpg", 
          "twitter:description": "A beginner's guide to getting started with web scraping using Python and BeautifulSoup.", 
          "og:type": "website", 
          "og:description": "Greg Reda is an independent data science and strategy consultant, helping clients effectively utilize data to gain insight, inform decisions, and grow their business.", 
          "twitter:title": "Web Scraping 101 with Python", 
          "og:title": "Greg Reda: independent data science and strategy consulting.", 
          "twitter:card": "summary", 
          "twitter:site": "@gjreda", 
          "og:image": "/theme/images/avatar.jpg", 
          "viewport": "width=device-width, initial-scale=1, maximum-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "280", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSwc56g72J9PQ1Qtunh5OvHVTZY0yYNtftiRBKBa3QmiEWRRds04ncTs-M", 
          "height": "180"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.gregreda.com/images/winners-and-runners-up.png"
        }
      ]
    }, 
    "snippet": "Mar 3, 2013 ... A beginner's guide to getting started with web scraping using Python and \nBeautifulSoup.", 
    "htmlSnippet": "Mar 3, 2013 <b>...</b> A beginner&#39;s guide to getting started with web <b>scraping</b> using Python and <br>\nBeautifulSoup.", 
    "link": "http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/", 
    "cacheId": "ndvZubDzma0J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Making Your Website Scrape-Proof: How to Thwart Content Thieves ...", 
    "displayLink": "www.speedawarenessmonth.com", 
    "htmlTitle": "Making Your <b>Website Scrape</b>-Proof: How to Thwart Content Thieves <b>...</b>", 
    "formattedUrl": "www.speedawarenessmonth.com/making-your-website-scrape-proof-how-to- thwart-content-thieves/", 
    "htmlFormattedUrl": "www.speedawarenessmonth.com/making-your-<b>website</b>-<b>scrape</b>-proof-how-to- thwart-content-thieves/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://www.speedawarenessmonth.com/making-your-website-scrape-proof-how-to-thwart-content-thieves/", 
          "og:type": "article", 
          "og:site_name": "Speed Awareness Month", 
          "og:locale": "en_US", 
          "og:description": "As a website owner, you probably love the idea of thousands of people coming to your site every day. But what if most of those requests were automated, coming from bots and scrapers that wanted to harvest and collect your content and information for their own purposes? Clearly, not all website traffic is desirable. These [\u2026]", 
          "og:title": "Making Your Website Scrape-Proof: How to Thwart Content Thieves - Speed Awareness Month", 
          "og:image": "http://www.speedawarenessmonth.com/wp-content/uploads/2013/09/istock-scraping-dude.jpg", 
          "viewport": "width=1024"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "183", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQ818d9Mf-ta9KIe-yM-pHn2dqVKqckE4-q7S0TLxHKhtnQqNB-ELNViEA-", 
          "height": "275"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.speedawarenessmonth.com/wp-content/uploads/2013/09/istock-scraping-dude.jpg"
        }
      ]
    }, 
    "snippet": "As a website owner, you probably love the idea of thousands of people coming to \nyour site every day. But what if most of those requests were automated, coming\u00a0...", 
    "htmlSnippet": "As a <b>website</b> owner, you probably love the idea of thousands of people coming to <br>\nyour site every day. But what if most of those requests were automated, coming&nbsp;...", 
    "link": "http://www.speedawarenessmonth.com/making-your-website-scrape-proof-how-to-thwart-content-thieves/", 
    "cacheId": "DJtKLDm1gz4J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "This Simple Data-Scraping Tool Could Change How Apps Are Made ...", 
    "displayLink": "www.wired.com", 
    "htmlTitle": "This Simple Data-<b>Scraping</b> Tool Could Change How Apps Are Made <b>...</b>", 
    "formattedUrl": "www.wired.com/2014/03/kimono/", 
    "htmlFormattedUrl": "www.wired.com/2014/03/kimono/", 
    "pagemap": {
      "website": [
        {
          "image": "http://www.wired.com/wp-content/uploads/images_blogs/design/2014/03/kimono-ft1-200x100.jpg", 
          "name": "This Simple Data-Scraping Tool Could Change How Apps Are Made | WIRED", 
          "description": "Kimono is a web app that lets you slurp data from any website and turn it instantly into an API."
        }
      ], 
      "article": [
        {
          "articlebody": "The number of web pages on the internet is somewhere north of two billion, perhaps as many as double that. It\u2019s a huge amount of raw information. By comparison, there are only roughly 10,000...", 
          "datepublished": "2014-03-04T06:30:58+00:00", 
          "name": "This Simple Data-Scraping Tool Could Change How Apps Are Made", 
          "interactioncount": "53", 
          "author": "Kyle VanHemert"
        }, 
        {
          "url": "http://www.wired.com/2015/05/wam-twitter-harassment/", 
          "image": "http://www.wired.com/wp-content/uploads/2015/05/twitter.jpg", 
          "name": "It\u2019s Too Easy for Trolls to Game Twitter\u2019s Anti-Abuse Tools"
        }, 
        {
          "url": "http://www.wired.com/2015/05/house-passes-usa-freedom-act/", 
          "image": "http://www.wired.com/wp-content/uploads/2015/05/460912556.jpg", 
          "name": "House Passes USA Freedom Act to Curb NSA Spying"
        }, 
        {
          "url": "http://www.wired.com/2015/05/instant-articles-facebook-shows-us-paper/", 
          "image": "http://www.wired.com/wp-content/uploads/2015/05/4-Video.jpg", 
          "name": "With Instant Articles, Facebook Shows Us What Paper Was For"
        }, 
        {
          "url": "http://www.wired.com/2015/05/kano-world/", 
          "image": "http://www.wired.com/wp-content/uploads/2015/05/kano.jpg", 
          "name": "The GitHub for Kids Urges Them to Be Inventors, Not Users"
        }, 
        {
          "url": "http://www.wired.com/2015/05/the-strain-mooc/", 
          "image": "http://www.wired.com/wp-content/uploads/2015/05/Strain_109_Shot5.pct_hires2_V2.jpg", 
          "name": "TV Execs Want You to Take College Classes About Their Shows"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "318", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRButbwgpOpoRnEi0IOc6fGJWv9LTUj0LxKTj0-SCdV4JQ44wLaHfF2oyGK", 
          "height": "159"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.wired.com/wp-content/uploads/images_blogs/design/2014/03/kimono-ft1.jpg"
        }
      ], 
      "metatags": [
        {
          "twitter:creator": "@wired", 
          "msapplication-tilecolor": "#cb0004", 
          "application-name": "WIRED: WIRED", 
          "twitter:domain": "WIRED", 
          "og:locale": "en_US", 
          "gmapkey": "ABQIAAAAF5yd_X_vTzike6sB6lp3wBQ4h890iMeKvsDZGQOc75SG0lWKAhQW755bw9E_-3ijKe6eqE5sg_NLEw", 
          "twitter:site": "@wired", 
          "og:url": "http://www.wired.com/2014/03/kimono/", 
          "og:image": "http://www.wired.com/wp-content/uploads/images_blogs/design/2014/03/kimono-ft1.jpg", 
          "author": "Kyle VanHemert", 
          "section": "Blog", 
          "og:type": "article", 
          "fb:admins": "648235154,789168297,688620285,650984415", 
          "apple-itunes-app": "app-id=373903654", 
          "subsection": "WIRED", 
          "og:title": "This Simple Data-Scraping Tool Could Change How Apps Are Made | WIRED", 
          "twitter:title": "This Simple Data-Scraping Tool Could Change How Apps Are Made | WIRED", 
          "article:section": "Design", 
          "msapplication-tooltip": "Read in-depth coverage of current and future trends in technology, and how they are shaping business, entertainment, communications, science, politics, and culture at Wired.com.", 
          "expirydate": "2060-12-31", 
          "msapplication-tileimage": "http://www.wired.com/wp-content/themes/Phoenix/assets/images/favicon_ie.png", 
          "fb:page_id": "19440638720", 
          "viewport": "width=device-width, initial-scale=1, minimal-ui", 
          "og:site_name": "WIRED", 
          "twitter:card": "summary_large_image", 
          "parsely-page": "{\"title\": \"This Simple Data-Scraping Tool Could Change How Apps Are Made\", \"link\": \"http://www.wired.com/2014/03/kimono/\", \"image_url\": \"http://www.wired.com/wp-content/uploads/images_blogs/design/2014/03/kimono-ft1-60x60.jpg\", \"type\": \"post\", \"post_id\": \"631304\", \"pub_date\": \"2014-03-04T06:30:58+00:00\", \"section\": \"WIRED\", \"author\": \"Kyle VanHemert\", \"tags\": []}", 
          "twitter:description": "Kimono is a web app that lets you slurp data from any website and turn it instantly into an API.", 
          "og:description": "Kimono is a web app that lets you slurp data from any website and turn it instantly into an API.", 
          "twitter:image:src": "http://www.wired.com/wp-content/uploads/images_blogs/design/2014/03/kimono-ft1.jpg", 
          "displaydate": "2014-03-04"
        }
      ]
    }, 
    "snippet": "Mar 4, 2014 ... Kimono is a web app that lets you slurp data from any website and turn ... the vast \nmajority of the stuff on the web, you need to scrape it yourself.", 
    "htmlSnippet": "Mar 4, 2014 <b>...</b> Kimono is a web app that lets you slurp data from any <b>website</b> and turn ... the vast <br>\nmajority of the stuff on the web, you need to <b>scrape</b> it yourself.", 
    "link": "http://www.wired.com/2014/03/kimono/", 
    "cacheId": "uhFMd4OsPfgJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "WebHarvy Web Scraper - Visual Web Scraping Software | Web Data ...", 
    "displayLink": "www.webharvy.com", 
    "htmlTitle": "WebHarvy Web Scraper - Visual Web <b>Scraping</b> Software | Web Data <b>...</b>", 
    "formattedUrl": "https://www.webharvy.com/", 
    "htmlFormattedUrl": "https://www.webharvy.com/", 
    "pagemap": {
      "metatags": [
        {
          "dc.description": "WebHarvy Web Scraper Software", 
          "dc.rights": "Copyright SysNucleus. All rights reserved.", 
          "rating": "General", 
          "author": "SysNucleus", 
          "dc.format": "text/html", 
          "dc.publisher": "SysNucleus", 
          "dc.creator": "SysNucleus", 
          "dc.language": "en", 
          "dc.title": "WebHarvy Web Scraper"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "257", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTEhO8rE07aHvs3J6hwq99hWs_zmLlLNAAXinhWxW8EHxJ46EOoiePrf8U", 
          "height": "167"
        }
      ], 
      "cse_image": [
        {
          "src": "https://www.webharvy.com/images/WebHarvy-pitch.png"
        }
      ]
    }, 
    "snippet": "WebHarvy can automatically scrape data (Text, URLs and Images) from web ... \nWatch the demo and see how easy it is to scrape websites using WebHarvy !", 
    "htmlSnippet": "WebHarvy can automatically scrape data (Text, URLs and Images) from web ... <br>\nWatch the demo and see how easy it is to <b>scrape websites</b> using WebHarvy !", 
    "link": "https://www.webharvy.com/", 
    "cacheId": "hLjVEc1uq3oJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "What is the easiest way to scrape ecommerce websites for product ...", 
    "displayLink": "www.quora.com", 
    "htmlTitle": "What is the easiest way to <b>scrape</b> ecommerce <b>websites</b> for product <b>...</b>", 
    "formattedUrl": "www.quora.com/What-is-the-easiest-way-to-scrape-ecommerce-websites-for- product-information", 
    "htmlFormattedUrl": "www.quora.com/What-is-the-easiest-way-to-<b>scrape</b>-ecommerce-<b>websites</b>-for- product-information", 
    "pagemap": {
      "breadcrumb": [
        {
          "url": "Logistics and Supply Chain Management", 
          "title": "Logistics and Supply Chain Management"
        }, 
        {
          "url": "Business", 
          "title": "Business"
        }, 
        {
          "url": "Business Development", 
          "title": "Business Development"
        }, 
        {
          "url": "Sales", 
          "title": "Sales"
        }, 
        {
          "url": "Lead Generation", 
          "title": "Lead Generation"
        }
      ]
    }, 
    "snippet": "I run a young online marketplace. For generating leads, I would like to scrape my \ncompetition (all online marketplaces like ebay, amazon etc)\u00a0...", 
    "htmlSnippet": "I run a young online marketplace. For generating leads, I would like to <b>scrape</b> my <br>\ncompetition (all online marketplaces like ebay, amazon etc)&nbsp;...", 
    "link": "http://www.quora.com/What-is-the-easiest-way-to-scrape-ecommerce-websites-for-product-information"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "This is how I scrape a website : learnprogramming", 
    "displayLink": "www.reddit.com", 
    "htmlTitle": "This is how I <b>scrape a website</b> : learnprogramming", 
    "formattedUrl": "www.reddit.com/r/.../comments/.../this_is_how_i_scrape_a_website/", 
    "htmlFormattedUrl": "www.reddit.com/r/.../comments/.../this_is_how_i_<b>scrape_a_website</b>/", 
    "pagemap": {
      "metatags": [
        {
          "og:site_name": "reddit", 
          "twitter:card": "summary", 
          "referrer": "always", 
          "og:description": "Hello everyone, In case anyone is curious about web scraping, I wrote a short little half-assed tutorial on the subject focusing on scraping XKCD...", 
          "twitter:title": "This is how I scrape a website \u2022 /r/learnprogramming", 
          "viewport": "width=1024", 
          "og:title": "This is how I scrape a website \u2022 /r/learnprogramming", 
          "twitter:site": "reddit", 
          "og:image": "https://www.redditstatic.com/icon.png", 
          "og:ttl": "600"
        }
      ], 
      "cse_image": [
        {
          "src": "https://www.redditstatic.com/icon.png"
        }
      ]
    }, 
    "snippet": "May 4, 2015 ... Hello everyone, In case anyone is curious about web scraping, I wrote a short \nlittle half-assed tutorial on the subject focusing on scraping\u00a0...", 
    "htmlSnippet": "May 4, 2015 <b>...</b> Hello everyone, In case anyone is curious about web <b>scraping</b>, I wrote a short <br>\nlittle half-assed tutorial on the subject focusing on <b>scraping</b>&nbsp;...", 
    "link": "http://www.reddit.com/r/learnprogramming/comments/34w8os/this_is_how_i_scrape_a_website/", 
    "cacheId": "92aooaSB9GMJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraper - Chrome Web Store", 
    "displayLink": "chrome.google.com", 
    "htmlTitle": "Web Scraper - Chrome Web Store", 
    "formattedUrl": "https://chrome.google.com/...scraper/jnhgnonknehpejjnehehllkliplmbmhn?...", 
    "htmlFormattedUrl": "https://chrome.google.com/...<b>scrape</b>r/jnhgnonknehpejjnehehllkliplmbmhn?...", 
    "pagemap": {
      "cse_thumbnail": [
        {
          "width": "102", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQ_fcr2adZCJPDLGIHe-0B_QawWrTA84zbRQxZQya5Efz2IQGV-pFY0", 
          "height": "102"
        }
      ], 
      "offer": [
        {
          "price": "$0", 
          "availability": "http://schema.org/InStock", 
          "pricecurrency": "USD"
        }
      ], 
      "metatags": [
        {
          "og:url": "https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn", 
          "referrer": "origin", 
          "og:type": "website", 
          "og:description": "Tool for data extraction from websites", 
          "og:title": "Web Scraper", 
          "og:image": "https://lh4.googleusercontent.com/taYGFyqbxUmoCS-3tvFWASNfqznlyZUMJ0fzkag1_6HFFRlqEilbr-_E3eDpVUlgKVk1b5Xo0g=s128-h128-e365", 
          "viewport": "width=device-width, initial-scale=1.0, maximum-scale=1.0"
        }
      ], 
      "aggregaterating": [
        {
          "ratingvalue": "4.186991869918699", 
          "ratingcount": "123"
        }
      ], 
      "webapplication": [
        {
          "name": "Web Scraper", 
          "url": "https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn", 
          "image": "https://lh4.googleusercontent.com/taYGFyqbxUmoCS-3tvFWASNfqznlyZUMJ0fzkag1_6HFFRlqEilbr-_E3eDpVUlgKVk1b5Xo0g=s128-h128-e365", 
          "interactioncount": "UserDownloads:39,136", 
          "softwareapplicationcategory": "http://schema.org/OtherApplication", 
          "version": "0.2.0.10", 
          "operatingsystems": "Chrome", 
          "description": "Tool for data extraction from websites"
        }
      ], 
      "document": [
        {
          "category": "7_productivity", 
          "supported_regions": "AE,AR,AT,AU,BE,BG,BR,CA,CH,CL", 
          "user_count": "39136", 
          "container": "CHROME", 
          "item_category": "EXTENSION", 
          "autogen": "false", 
          "works_offline": "false", 
          "stars3": "true", 
          "stars5": "false", 
          "available_on_android": "false", 
          "kiosk": "false", 
          "stars2": "true", 
          "page_lang_safe": "en", 
          "stars4": "true", 
          "payment_type": "free", 
          "by_google": "false", 
          "family_unsafe": "false", 
          "canonical": "true"
        }, 
        {
          "category": "7_productivity", 
          "supported_regions": "AE,AR,AT,AU,BE,BG,BR,CA,CH,CL", 
          "user_count": "38191", 
          "container": "CHROME", 
          "item_category": "EXTENSION", 
          "autogen": "false", 
          "works_offline": "false", 
          "unpub_user_count": "38191", 
          "stars3": "true", 
          "stars5": "false", 
          "available_on_android": "false", 
          "kiosk": "false", 
          "stars2": "true", 
          "page_lang_safe": "en", 
          "wilson_star_rating": "3.912154866953064", 
          "stars4": "true", 
          "payment_type": "free", 
          "by_google": "false", 
          "family_unsafe": "false", 
          "pagerank_devurl": "24000", 
          "canonical": "true"
        }
      ], 
      "cse_image": [
        {
          "src": "https://lh4.googleusercontent.com/taYGFyqbxUmoCS-3tvFWASNfqznlyZUMJ0fzkag1_6HFFRlqEilbr-_E3eDpVUlgKVk1b5Xo0g=s128-h128-e365"
        }
      ]
    }, 
    "snippet": "Dec 17, 2014 ... Tool for data extraction from websites.", 
    "htmlSnippet": "Dec 17, 2014 <b>...</b> Tool for data extraction from <b>websites</b>.", 
    "link": "https://chrome.google.com/webstore/detail/web-scraper/jnhgnonknehpejjnehehllkliplmbmhn?hl=en", 
    "cacheId": "Pzx9QAGeuTIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "HOWTO scrape websites with Ruby and Mechanize", 
    "displayLink": "readysteadycode.com", 
    "htmlTitle": "HOWTO <b>scrape websites</b> with Ruby and Mechanize", 
    "formattedUrl": "readysteadycode.com/howto-scrape-websites-with-ruby-and-mechanize", 
    "htmlFormattedUrl": "readysteadycode.com/<b>howto-scrape</b>-<b>websites</b>-with-ruby-and-mechanize", 
    "snippet": "Web scraping is an approach for extracting data from websites that don't provide \nan official API. Web scraping code is inherently \u201cbrittle\u201d (i.e. prone to breaking\u00a0...", 
    "htmlSnippet": "Web <b>scraping</b> is an approach for extracting data from <b>websites</b> that don&#39;t provide <br>\nan official API. Web <b>scraping</b> code is inherently \u201cbrittle\u201d (i.e. prone to breaking&nbsp;...", 
    "link": "http://readysteadycode.com/howto-scrape-websites-with-ruby-and-mechanize", 
    "cacheId": "QSWO2avqBTAJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "ScrapeBox \u2013 Harvest, Check, Ping, Post", 
    "displayLink": "www.scrapebox.com", 
    "htmlTitle": "<b>ScrapeBox</b> \u2013 Harvest, Check, Ping, Post", 
    "formattedUrl": "www.scrapebox.com/", 
    "htmlFormattedUrl": "www.<b>scrape</b>box.com/", 
    "pagemap": {
      "cse_thumbnail": [
        {
          "width": "246", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTKc4Mh1PTk_3FE_Gk4Xv721-sDyT5ghZVdbWpO_0kZetd6k7zslIck2Y8F", 
          "height": "205"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.scrapebox.com/wp-content/uploads/2009/10/scrapebox-interface.png"
        }
      ]
    }, 
    "snippet": "For example you can store site:.gov and ScrapeBox will search amongst the 242 \n.... ScrapeBox can also harvest proxies from various websites, so you can add\u00a0...", 
    "htmlSnippet": "For example you can store site:.gov and <b>ScrapeBox</b> will search amongst the 242 <br>\n.... <b>ScrapeBox</b> can also harvest proxies from various <b>websites</b>, so you can add&nbsp;...", 
    "link": "http://www.scrapebox.com/", 
    "cacheId": "fbHzBSmRUF4J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to scrape data from the internet using import.io \u2013 import.io ...", 
    "displayLink": "support.import.io", 
    "htmlTitle": "<b>How to scrape</b> data from the internet using import.io \u2013 import.io <b>...</b>", 
    "formattedUrl": "support.import.io/.../387487-how-to-scrape-data-from-the-internet-using- import", 
    "htmlFormattedUrl": "support.import.io/.../387487-<b>how-to-scrape</b>-data-from-the-internet-using- import", 
    "pagemap": {
      "metatags": [
        {
          "csrf-param": "authenticity_token", 
          "csrf-token": "HG4AtoNQTLt/T0Yk7EnM4ZHLH+2UHUNvEc8adsn4Baw=", 
          "viewport": "width=device-width, initial-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "283", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRsEwDm40CH310xRaouOtd1VI6XOGzkAVBUplTVd6x897Km8OWXf4tGry6O", 
          "height": "178"
        }
      ], 
      "cse_image": [
        {
          "src": "http://thedatacollator.files.wordpress.com/2014/05/screen-shot-2014-05-08-at-17-25-55.png?w=474&h=298"
        }
      ]
    }, 
    "snippet": "If there's a list on a website that you want to put into a spreadsheet: you can \nscrape it. If you want to find out some interesting statistics from the web: you can\u00a0...", 
    "htmlSnippet": "If there&#39;s a list on a <b>website</b> that you want to put into a spreadsheet: you can <br>\n<b>scrape</b> it. If you want to find out some interesting statistics from the web: you can&nbsp;...", 
    "link": "http://support.import.io/knowledgebase/articles/387487-how-to-scrape-data-from-the-internet-using-import", 
    "cacheId": "NqHYdlEcksIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Easy Web Scraping with Python - miguelgrinberg.com", 
    "displayLink": "blog.miguelgrinberg.com", 
    "htmlTitle": "Easy Web <b>Scraping</b> with Python - miguelgrinberg.com", 
    "formattedUrl": "blog.miguelgrinberg.com/post/easy-web-scraping-with-python", 
    "htmlFormattedUrl": "blog.miguelgrinberg.com/post/easy-web-<b>scraping</b>-with-python", 
    "pagemap": {
      "metatags": [
        {
          "copyright": "Copyright (c) 2012-2015 Miguel Grinberg", 
          "viewport": "width=device-width, initial-scale=1.0", 
          "author": "Miguel Grinberg"
        }
      ]
    }, 
    "snippet": "Apr 21, 2014 ... A little over a year ago I wrote an article on web scraping using Node.js ..... 2014 \nvideos (automagically), scraping websites and parallel python.", 
    "htmlSnippet": "Apr 21, 2014 <b>...</b> A little over a year ago I wrote an article on web scraping using Node.js ..... 2014 <br>\nvideos (automagically), <b>scraping websites</b> and parallel python.", 
    "link": "http://blog.miguelgrinberg.com/post/easy-web-scraping-with-python", 
    "cacheId": "9LCYm9aWo3AJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping a website's HTML in VBA", 
    "displayLink": "www.wiseowl.co.uk", 
    "htmlTitle": "<b>Scraping a website&#39;s</b> HTML in VBA", 
    "formattedUrl": "www.wiseowl.co.uk/blog/s393/scrape-website-html.htm", 
    "htmlFormattedUrl": "www.wiseowl.co.uk/blog/s393/<b>scrape</b>-<b>website</b>-html.htm", 
    "pagemap": {
      "metatags": [
        {
          "apple-mobile-web-app-title": "Wise Owl", 
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ]
    }, 
    "snippet": "Jan 13, 2014 ... Scraping a website's HTML in VBA. This blog shows how to go through a website\n, making sense of its HTML within VBA. We'll break the\u00a0...", 
    "htmlSnippet": "Jan 13, 2014 <b>...</b> <b>Scraping a website&#39;s</b> HTML in VBA. This blog shows how to go through a website<br>\n, making sense of its HTML within VBA. We&#39;ll break the&nbsp;...", 
    "link": "http://www.wiseowl.co.uk/blog/s393/scrape-website-html.htm", 
    "cacheId": "h9nuWNo87NkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web scraping tutorial | Hackaday", 
    "displayLink": "hackaday.com", 
    "htmlTitle": "Web <b>scraping</b> tutorial | Hackaday", 
    "formattedUrl": "hackaday.com/2012/12/10/web-scraping-tutorial/", 
    "htmlFormattedUrl": "hackaday.com/2012/12/10/web-<b>scraping</b>-tutorial/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://hackaday.com/2012/12/10/web-scraping-tutorial/", 
          "og:site_name": "Hackaday", 
          "application-name": "Hackaday", 
          "twitter:card": "summary_large_image", 
          "og:type": "article", 
          "og:description": "Web scraping is the act of programmatically harvesting data from a webpage. It consists of finding a way to format the URLs to pages containing useful information, and then parsing the DOM tree to get...", 
          "msapplication-tooltip": "Fresh hacks every day", 
          "msapplication-window": "width=device-width;height=device-height", 
          "msapplication-task": "name=Subscribe;action-uri=http://hackaday.com/feed/;icon-uri=http://0.gravatar.com/blavatar/4f3e6b6daa090af416a1ba595885efd1?s=16", 
          "og:title": "Web scraping tutorial", 
          "twitter:site": "@hackaday", 
          "og:image": "https://hackadaycom.files.wordpress.com/2012/12/web-scraping-tutorial.png?w=600&h=600", 
          "viewport": "width=960"
        }
      ], 
      "article": [
        {
          "image": "https://hackadaycom.files.wordpress.com/2012/12/web-scraping-tutorial.png?w=600&h=600", 
          "name": "Web scraping tutorial", 
          "description": "Web scraping is the act of programmatically harvesting data from a webpage. It consists of finding a way to format the URLs to pages containing useful information, and then parsing the DOM..."
        }, 
        {
          "url": "http://hackaday.com/2012/12/10/web-scraping-tutorial/", 
          "articlebody": "Web scraping is the act of programmatically harvesting data from a webpage. It consists of finding a way to format the URLs to pages containing useful information, and then parsing the DOM...", 
          "image": "https://hackadaycom.files.wordpress.com/2012/12/web-scraping-tutorial.png?w=600&h=600", 
          "name": "Web scraping tutorial", 
          "datepublished": "December 10, 2012"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "401", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcTwcRQLCQOKjy96M9GuT5Xr7vRQpvdWHFuBZ2k97MXVpGT-VNySmcJijQ", 
          "height": "107"
        }
      ], 
      "cse_image": [
        {
          "src": "https://hackadaycom.files.wordpress.com/2012/12/web-scraping-tutorial.png?w=600&h=600"
        }
      ], 
      "hcard": [
        {
          "nickname": "joshuac", 
          "fn": "joshuac"
        }, 
        {
          "url": "http://blog.allgaiershops.com/", 
          "url_text": "mohonri", 
          "nickname": "mohonri", 
          "fn": "mohonri"
        }, 
        {
          "nickname": "joshuac", 
          "fn": "joshuac"
        }, 
        {
          "fn": "g19fanatic"
        }, 
        {
          "nickname": "Matt", 
          "fn": "Matt"
        }, 
        {
          "url": "http://fomori.org/", 
          "url_text": "devsnd", 
          "nickname": "devsnd", 
          "fn": "devsnd"
        }, 
        {
          "fn": "SoMuchYiff!"
        }, 
        {
          "url": "http://gravatar.com/hartleybrody", 
          "url_text": "hartleybrody", 
          "nickname": "hartleybrody", 
          "fn": "hartleybrody"
        }, 
        {
          "nickname": "JoeSponge", 
          "fn": "JoeSponge"
        }, 
        {
          "url": "http://www.facebook.com/MyRepublic", 
          "url_text": "Virgil Tudorancea", 
          "fn": "Virgil Tudorancea"
        }
      ]
    }, 
    "snippet": "Dec 10, 2012 ... The company I work for scrape websites for comercial purposes. lets ... So take \nall the books or download the complete website? no, they go to\u00a0...", 
    "htmlSnippet": "Dec 10, 2012 <b>...</b> The company I work for <b>scrape websites</b> for comercial purposes. lets ... So take <br>\nall the books or download the complete website? no, they go to&nbsp;...", 
    "link": "http://hackaday.com/2012/12/10/web-scraping-tutorial/", 
    "cacheId": "toV2VuAXtWYJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scrapinghub | Web Crawling Platform & Services", 
    "displayLink": "scrapinghub.com", 
    "htmlTitle": "Scrapinghub | Web Crawling Platform &amp; Services", 
    "formattedUrl": "scrapinghub.com/", 
    "htmlFormattedUrl": "<b>scraping</b>hub.com/", 
    "pagemap": {
      "metatags": [
        {
          "publisher": "Scrapinghub", 
          "copyright": "Scrapinghub", 
          "author": "Scrapinghub", 
          "msapplication-tilecolor": "#ffffff", 
          "msapplication-tileimage": "/images/ms-icon-144x144.png", 
          "viewport": "width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "225", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTnO3KahYft6AH-gnB15L0Z6T_VvUMnqfG6eRiZnfFM7vAIaeFy8fYorRc", 
          "height": "225"
        }
      ], 
      "cse_image": [
        {
          "src": "http://scrapinghub.com/images/testimonials/mikeseidle.jpg"
        }
      ]
    }, 
    "snippet": "Hiring Scrapinghub and building our next-generation scraping system on open \nsource Scrapy and Scrapyd are some of the best decisions we've made. Scrapy\u00a0...", 
    "htmlSnippet": "Hiring Scrapinghub and building our next-generation <b>scraping</b> system on open <br>\nsource Scrapy and Scrapyd are some of the best decisions we&#39;ve made. Scrapy&nbsp;...", 
    "link": "http://scrapinghub.com/", 
    "cacheId": "U8ReEf9ykpcJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to Scrap Any Website's content using ScrapyTutorial of How to ...", 
    "displayLink": "www.slideshare.net", 
    "htmlTitle": "How to Scrap Any <b>Website&#39;s</b> content using ScrapyTutorial of How to <b>...</b>", 
    "formattedUrl": "www.slideshare.net/.../how-to-scrap-websites-content-using-scrapytutorial-of- how-to-scrape-crawling-websites-content-using-scrapy-python", 
    "htmlFormattedUrl": "www.slideshare.net/.../how-to-scrap-<b>websites</b>-content-using-scrapytutorial-of- <b>how-to-scrape</b>-crawling-<b>websites</b>-content-using-scrapy-python", 
    "pagemap": {
      "metatags": [
        {
          "og_image": "http://cdn.slidesharecdn.com/ss_thumbnails/howtoscrap-130714115838-phpapp02-thumbnail-4.jpg?cb=1373804217", 
          "twitter:app:name:googleplay": "SlideShare Android", 
          "twitter:app:url:ipad": "slideshare-app://ss/24221331", 
          "slideshow_author": "http://www.slideshare.net/antonrifco", 
          "csrf-token": "FSrXVJ1inKX2pJ3TaOjstmLLg0lZYbXnWv1s4RpyJ0Y=", 
          "slideshow_category": "Self Improvement", 
          "twitter:app:url:googleplay": "http://www.slideshare.net/antonrifco/how-to-scrap-websites-content-using-scrapytutorial-of-how-to-scrape-crawling-websites-content-using-scrapy-python", 
          "og_title": "How to Scrap Any Website's content using ScrapyTutorial of How to scr\u2026", 
          "al:ios:url": "slideshare-app://ss/24221331", 
          "twitter:app:url:iphone": "slideshare-app://ss/24221331", 
          "slideshow_comment_count": "2", 
          "al:ios:app_store_id": "917418728", 
          "al:android:package": "net.slideshare.mobile", 
          "slideshow_embed_count": "1", 
          "twitter:app:id:ipad": "917418728", 
          "thumbnail": "http://cdn.slidesharecdn.com/ss_thumbnails/howtoscrap-130714115838-phpapp02-thumbnail.jpg?cb=1373804217", 
          "slideshow_updated_at": "2013-07-14 12:16:57 UTC", 
          "og_description": "Tutorial of How to scrape (crawling) website's content using Scrapy Python", 
          "fb_app_id": "2490221586", 
          "include_mode": "async", 
          "twitter:app:name:iphone": "SlideShare iOS", 
          "slideshow_favorites_count": "18", 
          "csrf-param": "authenticity_token", 
          "al:ios:app_name": "SlideShare iOS", 
          "slideshow_download_count": "123", 
          "al:android:app_name": "SlideShare Android", 
          "twitter:app:id:googleplay": "net.slideshare.mobile", 
          "slideshow_view_count": "7288", 
          "twitter:app:id:iphone": "917418728", 
          "viewport": "width=device-width, initial-scale=1.0, maximum-scale=1, user-scalable=no", 
          "twitter:app:name:ipad": "SlideShare iOS", 
          "slideshow_published_time": "2013-07-14T11:58:38Z", 
          "og_type": "slideshare:presentation", 
          "al:android:url": "slideshare-app://ss/24221331", 
          "og_url": "http://www.slideshare.net/antonrifco/how-to-scrap-websites-content-using-scrapytutorial-of-how-to-scrape-crawling-websites-content-using-scrapy-python", 
          "slideshow_created_at": "2013-07-14 11:58:38 UTC"
        }
      ], 
      "text": [
        {
          "text": "1. HOWTO SCRAPE ANY WEBSITE FOR FUN ;) by Anton Rifco anton.rifco@gmail.com Some pictures taken from internet. This article possess no copyright. Use it for your own purpose July 2013 Monday,..."
        }
      ], 
      "mediaobject": [
        {
          "inlanguage": "en", 
          "playertype": "HTML5", 
          "headline": "How to Scrap Any Website's content using ScrapyTutorial of How to scrape (crawling) website's content using Scrapy Python", 
          "image": "http://image.slidesharecdn.com/howtoscrap-130714115838-phpapp02/95/how-to-scrap-any-websites-content-using-scrapytutorial-of-how-to-scrape-crawling-websites-content-using-scrapy-python-1-638.jpg?cb=1373804217", 
          "interactioncount": "UserComments:2", 
          "datepublished": "2013-07-14T11:58:38Z", 
          "url": "http://www.slideshare.net/BondanSatriaNusantara?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshow", 
          "commenttime": "2 weeks ago", 
          "embedurl": "https://www.slideshare.net/slideshow/embed_code/key/hZt97jTxgW6KNf", 
          "thumbnailurl": "http://cdn.slidesharecdn.com/ss_thumbnails/howtoscrap-130714115838-phpapp02-thumbnail.jpg?cb=1373804217", 
          "description": "Tutorial of How to scrape (crawling) website's content using Scrapy Python"
        }
      ], 
      "usercomments": [
        {
          "url": "http://www.slideshare.net/ranvijaystpl?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare", 
          "commenttext": "I can scrap 90% websites.( contact.ranvijay@gmail.com ) http://ranvijaypythonscrapy.blogspot.in/2014/11/how-to-scrape-website-that-requires_27.html", 
          "image": "http://public.slidesharecdn.com/b/images/user-48x48.png", 
          "name": "Ranvijay Kumar", 
          "commenttime": "2015-05-07T12:37:37Z"
        }, 
        {
          "commenttext": "cool", 
          "name": "Con R\u1ec7p", 
          "url": "http://www.slideshare.net/conrep69?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideshare", 
          "jobtitle": "CEO", 
          "image": "http://public.slidesharecdn.com/b/images/user-48x48.png", 
          "worksfor": "B\u00e1n v\u00e9 s\u1ed1", 
          "commenttime": "2014-06-03T11:38:48Z"
        }
      ], 
      "organization": [
        {
          "url": "http://www.slideshare.net/antonrifco?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview", 
          "jobtitle": ", Product Manager", 
          "image": "http://cdn.slidesharecdn.com/profile-photo-antonrifco-48x48.jpg?cb=1429852211", 
          "worksfor": "Traveloka.com", 
          "name": "Anton Rifco Susilo"
        }
      ], 
      "cse_image": [
        {
          "src": "http://image.slidesharecdn.com/howtoscrap-130714115838-phpapp02/95/how-to-scrap-any-websites-content-using-scrapytutorial-of-how-to-scrape-crawling-websites-content-using-scrapy-python-1-638.jpg?cb=1373804217", 
          "height": "197", 
          "type": "1", 
          "width": "256"
        }
      ], 
      "thumbnail": [
        {
          "src": "http://cdn.slidesharecdn.com/ss_thumbnails/howtoscrap-130714115838-phpapp02-thumbnail.jpg?cb=1373804217"
        }
      ]
    }, 
    "snippet": "Jul 14, 2013 ... Tutorial of How to scrape (crawling) website's content using Scrapy Python.", 
    "htmlSnippet": "Jul 14, 2013 <b>...</b> Tutorial of <b>How to scrape</b> (crawling) <b>website&#39;s</b> content using Scrapy Python.", 
    "link": "http://www.slideshare.net/antonrifco/how-to-scrap-websites-content-using-scrapytutorial-of-how-to-scrape-crawling-websites-content-using-scrapy-python", 
    "cacheId": "YkLIUkaqyc4J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping | R-bloggers", 
    "displayLink": "www.r-bloggers.com", 
    "htmlTitle": "Web <b>Scraping</b> | R-bloggers", 
    "formattedUrl": "www.r-bloggers.com/search/web%20scraping", 
    "htmlFormattedUrl": "www.r-bloggers.com/search/web%20<b>scraping</b>", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://www.r-bloggers.com", 
          "og:type": "article", 
          "og:description": "R news and tutorials contributed by (573) R bloggers", 
          "og:site_name": "R-bloggers", 
          "og:title": "R-bloggers"
        }
      ]
    }, 
    "snippet": "Nov 24, 2014 ... rvest is new package that makes it easy to scrape (or harvest) data from html web \n... It is a great website for both learning about R and keeping\u00a0...", 
    "htmlSnippet": "Nov 24, 2014 <b>...</b> rvest is new package that makes it easy to <b>scrape</b> (or harvest) data from html web <br>\n... It is a great <b>website</b> for both learning about R and keeping&nbsp;...", 
    "link": "http://www.r-bloggers.com/search/web%20scraping", 
    "cacheId": "ZRFvHQOI-D0J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "ScrapeHero - Web scraping service - Full Service - Fixed Pricing ...", 
    "displayLink": "www.scrapehero.com", 
    "htmlTitle": "<b>ScrapeHero</b> - Web <b>scraping</b> service - Full Service - Fixed Pricing <b>...</b>", 
    "formattedUrl": "www.scrapehero.com/", 
    "htmlFormattedUrl": "www.<b>scrape</b>hero.com/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:card": "summary", 
          "twitter:image": "http://www.scrapehero.com/images/logo.png", 
          "twitter:description": "Turn chaotic websites into meaningful and structured data through our web data extraction service, affordable service and a quick turnaround Startups (and everyone else) already use our Data as a Service (DaaS) platform to power their ideas. Let us get you the data while you build the next Facebook", 
          "twitter:title": "Data as a Service (DaaS) - we scrape websites and give you clean data", 
          "twitter:site": "@scrapehero", 
          "viewport": "width=device-width, initial-scale=1, maximum-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "78", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTC9JT_IJeeFWKFUt4sqe3eevLb1AswyuH71yKuMRMJqe4iPub5tfRC", 
          "height": "78"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.scrapehero.com/images/logo.png"
        }
      ]
    }, 
    "snippet": "Gather data from websites for an affordable price, get it in any format you like.", 
    "htmlSnippet": "Gather data from <b>websites</b> for an affordable price, get it in any format you like.", 
    "link": "http://www.scrapehero.com/", 
    "cacheId": "l9Jxv23_KIEJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Case study: Scraping recipes website (includes video) / Knowledge ...", 
    "displayLink": "support.scrapinghub.com", 
    "htmlTitle": "Case study: <b>Scraping</b> recipes <b>website</b> (includes video) / Knowledge <b>...</b>", 
    "formattedUrl": "support.scrapinghub.com/topic/294065-/", 
    "htmlFormattedUrl": "support.<b>scraping</b>hub.com/topic/294065-/", 
    "pagemap": {
      "metatags": [
        {
          "title": "Case study: Scraping recipes website (includes video) / Knowledge Base forum / Scrapinghub", 
          "viewport": "user-scalable=no, width=device-width, initial-scale=1.0, maximum-scale=1.0", 
          "apple-mobile-web-app-capable": "yes"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "297", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSKyKeLs3NsOOzZnoTWz-HbbPhi-Qov1OtmUBJSGkd262sFS_I3q16u9w0", 
          "height": "170"
        }
      ], 
      "cse_image": [
        {
          "src": "http://support.scrapinghub.com/s/attachments/8940/24895/422020/4c1d26b39fe7f12087100b96ddb3430a.png"
        }
      ]
    }, 
    "snippet": "Let's assume we want to scrape all recipes from food.com for a mobile \napplication or a website.In this tutorial I will show you how to make it real with our \namazing\u00a0...", 
    "htmlSnippet": "Let&#39;s assume we want to <b>scrape</b> all recipes from food.com for a mobile <br>\napplication or a <b>website</b>.In this tutorial I will show you how to make it real with our <br>\namazing&nbsp;...", 
    "link": "http://support.scrapinghub.com/topic/294065-/", 
    "cacheId": "ZpLVbrK8-bgJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Chapter 4: Scraping Data from HTML - ProPublica", 
    "displayLink": "www.propublica.org", 
    "htmlTitle": "Chapter 4: <b>Scraping</b> Data from HTML - ProPublica", 
    "formattedUrl": "www.propublica.org/nerds/item/scraping-websites", 
    "htmlFormattedUrl": "www.propublica.org/nerds/item/<b>scraping</b>-<b>websites</b>", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://www.propublica.org/nerds/item/scraping-websites", 
          "twitter:url": "http://www.propublica.org/nerds/item/scraping-websites", 
          "og:site_name": "ProPublica", 
          "twitter:card": "summary_large_image", 
          "article:published_time": "2010-12-30T17:20:14-0600", 
          "twitter:description": "Dollars for Docs Data Guide: A tutorial on scraping HTML from websites.", 
          "og:type": "article", 
          "og:description": "Dollars for Docs Data Guide: A tutorial on scraping HTML from websites.", 
          "twitter:title": "Chapter 4: Scraping Data from HTML", 
          "twitter:site": "@ProPublica", 
          "og:title": "Chapter 4: Scraping Data from HTML", 
          "fb:app_id": "229862657130557", 
          "scope": "Small", 
          "article:modified_time": "2011-04-04T15:53:15-0500", 
          "type": "article", 
          "viewport": "width=device-width"
        }
      ], 
      "article": [
        {
          "name": "Chapter 4: Scraping Data from HTML", 
          "description": "Dollars for Docs Data Guide: A tutorial on scraping HTML from websites."
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "240", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRdEiSI1aXfTAYDQ9WVinJ7Kp_c-Kc0Kjzz3iAEMeLDXcfv4O53sBGUBQE", 
          "height": "170"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.propublica.org/images/ngen/gypsy_big_image/pfizer-db-300px-scrn.png"
        }
      ]
    }, 
    "snippet": "Dec 30, 2010 ... Web-scraping is essentially the task of finding out what input a website expects \nand understanding the format of its response. For example\u00a0...", 
    "htmlSnippet": "Dec 30, 2010 <b>...</b> Web-<b>scraping</b> is essentially the task of finding out what input a <b>website</b> expects <br>\nand understanding the format of its response. For example&nbsp;...", 
    "link": "http://www.propublica.org/nerds/item/scraping-websites", 
    "cacheId": "Rb1c9nPCf8wJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "rvest: easy web scraping with R | RStudio Blog", 
    "displayLink": "blog.rstudio.org", 
    "htmlTitle": "rvest: easy web <b>scraping</b> with R | RStudio Blog", 
    "formattedUrl": "blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/", 
    "htmlFormattedUrl": "blog.rstudio.org/2014/11/24/rvest-easy-web-<b>scraping</b>-with-r/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@rstudio", 
          "og:url": "http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/", 
          "og:locale": "en_US", 
          "og:title": "rvest: easy web scraping with R", 
          "application-name": "RStudio Blog", 
          "twitter:card": "summary", 
          "twitter:image": "http://1.gravatar.com/blavatar/3f031d721d8b60a7cb8e1ef230fd4615?s=240", 
          "og:type": "article", 
          "og:description": "rvest is new package that makes it easy to scrape (or harvest) data from html web pages, inspired by libraries like beautiful soup. It is designed to work with magrittr so that you can express comp...", 
          "article:author": "http://blog.rstudio.org/author/hadleywickham/", 
          "msapplication-window": "width=device-width;height=device-height", 
          "article:modified_time": "2014-12-03T17:43:28+00:00", 
          "twitter:site": "@rstudio", 
          "article:publisher": "https://www.facebook.com/WordPresscom", 
          "og:image": "http://1.gravatar.com/blavatar/3f031d721d8b60a7cb8e1ef230fd4615?s=200", 
          "article:published_time": "2014-11-24T14:29:24+00:00", 
          "msapplication-task": "name=Subscribe;action-uri=http://blog.rstudio.org/feed/;icon-uri=http://1.gravatar.com/blavatar/5ca61dd8a61f125a031bcd060da076e5?s=16", 
          "og:site_name": "RStudio Blog"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "160", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSdac5bIKTQ80jDQrtYzdlk2pie2z2wY0ytCuLZ27wZSArqKAIXKEdtDHM", 
          "height": "160"
        }
      ], 
      "cse_image": [
        {
          "src": "http://1.gravatar.com/blavatar/3f031d721d8b60a7cb8e1ef230fd4615?s=200"
        }
      ], 
      "hcard": [
        {
          "url": "http://twitter.com/the_belal", 
          "url_text": "Jim Hester (@the_belal)", 
          "fn": "Jim Hester (@the_belal)"
        }, 
        {
          "url": "http://robertmorrisdata.wordpress.com/", 
          "url_text": "robertmorrism", 
          "nickname": "robertmorrism", 
          "fn": "robertmorrism"
        }, 
        {
          "url": "http://agilemobiledeveloper.com/", 
          "url_text": "bunkertor", 
          "nickname": "bunkertor", 
          "fn": "bunkertor"
        }, 
        {
          "url": "http://tm.durusau.net/?p=58142", 
          "url_text": "rvest: easy web scraping with R \u00ab Another Word For It", 
          "fn": "rvest: easy web scraping with R \u00ab Another Word For It"
        }, 
        {
          "url": "https://www.facebook.com/huidong.tian", 
          "url_text": "Huidong Tian", 
          "fn": "Huidong Tian"
        }, 
        {
          "url": "http://lookingatdata.wordpress.com/", 
          "url_text": "hadleywickham", 
          "nickname": "hadleywickham", 
          "fn": "hadleywickham"
        }, 
        {
          "url": "http://blog-dataxforce.rhcloud.com/?p=93", 
          "url_text": "rvest: easy web scraping with R | (R news & tutorials) | Data(X)force", 
          "fn": "rvest: easy web scraping with R | (R news & tutorials) | Data(X)force"
        }, 
        {
          "url": "http://saysmymind.wordpress.com/2014/11/30/web-scraping-in-r-using-rvest/", 
          "url_text": "Web scraping in R using rVest | Says My Mind", 
          "fn": "Web scraping in R using rVest | Says My Mind"
        }, 
        {
          "fn": "i@dr-rohlfs.de"
        }, 
        {
          "url": "http://lookingatdata.wordpress.com/", 
          "url_text": "hadleywickham", 
          "nickname": "hadleywickham", 
          "fn": "hadleywickham"
        }
      ]
    }, 
    "snippet": "Nov 24, 2014 ... rvest is new package that makes it easy to scrape (or harvest) data from html web \n... Navigate around a website as if you're in a browser with\u00a0...", 
    "htmlSnippet": "Nov 24, 2014 <b>...</b> rvest is new package that makes it easy to <b>scrape</b> (or harvest) data from html web <br>\n... Navigate around a <b>website</b> as if you&#39;re in a browser with&nbsp;...", 
    "link": "http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/", 
    "cacheId": "DakIIPU2VugJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "The Simple Way to Scrape an HTML Table: Google Docs | eagereyes", 
    "displayLink": "eagereyes.org", 
    "htmlTitle": "The Simple Way to <b>Scrape</b> an HTML Table: Google Docs | eagereyes", 
    "formattedUrl": "https://eagereyes.org/data/scrape-tables-using-google-docs", 
    "htmlFormattedUrl": "https://eagereyes.org/data/<b>scrape</b>-tables-using-google-docs", 
    "pagemap": {
      "hcard": [
        {
          "url": "http://peltiertech.com/WordPress/", 
          "photo": "https://0.gravatar.com/avatar/93bea07e713080ed0d5be6865d6e7cf4?s=112&d=mm&r=g", 
          "url_text": "Jon Peltier", 
          "fn": "Jon Peltier"
        }, 
        {
          "url": "http://www.treelab.org/", 
          "photo": "https://1.gravatar.com/avatar/7843811dcc143bb960d81dccef5e2d4a?s=112&d=mm&r=g", 
          "url_text": "Enrico Poli", 
          "fn": "Enrico Poli"
        }, 
        {
          "url": "http://ouseful.info/", 
          "photo": "https://1.gravatar.com/avatar/abbd9f90565ce9ae4d065d93a81d8c03?s=112&d=mm&r=g", 
          "url_text": "Tony Hirst", 
          "fn": "Tony Hirst"
        }, 
        {
          "photo": "https://0.gravatar.com/avatar/?s=112&d=mm&r=g", 
          "fn": "Robert Kosara"
        }, 
        {
          "photo": "https://0.gravatar.com/avatar/?s=112&d=mm&r=g", 
          "fn": "Robert Kosara"
        }, 
        {
          "photo": "https://2.gravatar.com/avatar/?s=112&d=mm&r=g", 
          "fn": "Robert Kosara"
        }, 
        {
          "url": "http://data.timgraham.net/", 
          "photo": "https://2.gravatar.com/avatar/868260cd64bf04a9636338726ad5029c?s=112&d=mm&r=g", 
          "url_text": "Tim", 
          "nickname": "Tim", 
          "fn": "Tim"
        }, 
        {
          "url": "http://i-ocean.blogspot.com/", 
          "photo": "https://0.gravatar.com/avatar/056534e80ec6698bc488c9f8dfea1c7a?s=112&d=mm&r=g", 
          "url_text": "derek", 
          "nickname": "derek", 
          "fn": "derek"
        }, 
        {
          "photo": "https://2.gravatar.com/avatar/25bd35124e5e7208c8aa846404db68d9?s=112&d=mm&r=g", 
          "nickname": "ftr", 
          "fn": "ftr"
        }, 
        {
          "url": "http://alexgerdom.wordpress.com/", 
          "photo": "https://0.gravatar.com/avatar/300be8a31581a2050025194ef8c76c0f?s=112&d=mm&r=g", 
          "url_text": "alexgerdom", 
          "nickname": "alexgerdom", 
          "fn": "alexgerdom"
        }
      ], 
      "metatags": [
        {
          "twitter:creator": "@eagereyes", 
          "og:image:height": "1020", 
          "og:locale": "en_US", 
          "twitter:site": "@eagereyes_feed", 
          "article:publisher": "https://www.facebook.com/eagereyes.org", 
          "og:image:secure_url": "https://d148z92cppxlnu.cloudfront.net/wp-content/uploads/2009/11/google-import.png", 
          "og:url": "https://eagereyes.org/data/scrape-tables-using-google-docs", 
          "og:image": "https://d148z92cppxlnu.cloudfront.net/wp-content/uploads/2009/11/google-import.png", 
          "twitter:image:width": "1650", 
          "og:type": "article", 
          "og:title": "The Simple Way to Scrape an HTML Table: Google Docs", 
          "twitter:title": "The Simple Way to Scrape an HTML Table: Google Docs", 
          "article:tag": "data", 
          "article:section": "Data", 
          "article:modified_time": "2015-01-16T22:22:16+00:00", 
          "og:image:width": "1650", 
          "article:author": "https://www.facebook.com/eagereyes.org", 
          "article:published_time": "2009-11-15T09:59:08+00:00", 
          "viewport": "width=device-width", 
          "og:updated_time": "2015-01-16T22:22:16+00:00", 
          "twitter:image:height": "1020", 
          "og:site_name": "eagereyes", 
          "og:image:type": "image/png", 
          "twitter:card": "summary", 
          "twitter:description": "Raw data is the best data, but a lot of public data can still only be found in tables rather than as directly machine-readable files. One example is the FDIC's List of Failed Banks. Here is a simple trick to scrape such data from a website: Use Google Docs.", 
          "og:description": "Raw data is the best data, but a lot of public data can still only be found in tables rather than as directly machine-readable files. One example is the FDIC's List of Failed Banks. Here is a simple trick to scrape such data from a website: Use Google Docs.", 
          "twitter:image:src": "https://d148z92cppxlnu.cloudfront.net/wp-content/uploads/2009/11/google-import.png"
        }
      ], 
      "imageobject": [
        {
          "contenturl": "https://d148z92cppxlnu.cloudfront.net/wp-content/uploads/2009/11/google-import.png", 
          "name": "google-import", 
          "url": "https://eagereyes.org/data/scrape-tables-using-google-docs/attachment/google-import", 
          "height": "1020", 
          "encodingformat": "image/png", 
          "width": "1650", 
          "thumbnailurl": "https://d148z92cppxlnu.cloudfront.net/wp-content/uploads/2009/11/google-import-825x510.png"
        }
      ], 
      "person": [
        {
          "url": "https://plus.google.com/+RobertKosara/", 
          "sameas": "http://eagereyes.org/about", 
          "image": "https://2.gravatar.com/avatar/50b46e7a1eeb1d4e8106b33f064a2c13?s=128&d=mm&r=g", 
          "name": "Robert Kosara", 
          "description": "Robert Kosara is a Research Scientist at Tableau Software, and formerly Associate Professor of Computer Science. His research focus is the communication of data using visualization. In addition..."
        }
      ], 
      "organization": [
        {
          "url": "https://plus.google.com/+RobertKosara/", 
          "name": "eagereyes", 
          "description": "Visualization and Visual Communication"
        }
      ], 
      "article": [
        {
          "copyrightyear": "2009", 
          "name": "The Simple Way to Scrape an HTML Table: Google Docs", 
          "inlanguage": "en_US", 
          "url": "https://eagereyes.org/data/scrape-tables-using-google-docs", 
          "text": "Raw data is the best data, but a lot of public data can still only be found in tables rather than as directly machine-readable files. One example is the FDIC\u2019s List of Failed Banks. Here...", 
          "datepublished": "2009-11-15T09:59:08+00:00", 
          "headline": "The Simple Way to Scrape an HTML Table: Google Docs", 
          "keywords": "data", 
          "articlesection": "Data", 
          "thumbnailurl": "https://d148z92cppxlnu.cloudfront.net/wp-content/uploads/2009/11/google-import-825x510.png", 
          "datemodified": "2015-01-16T22:22:16+00:00", 
          "description": "Raw data is the best data, but a lot of public data can still only be found in tables rather than as directly machine-readable files. One example is the FDIC's List of Failed Banks. Here is..."
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "286", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRtbDjr5_wF87q5HWaQdIal4FlJIgg5jzxoDCSeZf-SeMGm6zSekSMjvVc", 
          "height": "176"
        }
      ], 
      "cse_image": [
        {
          "src": "https://d148z92cppxlnu.cloudfront.net/wp-content/uploads/2009/11/google-import-825x510.png"
        }
      ]
    }, 
    "snippet": "Nov 15, 2009 ... One example is the FDIC's List of Failed Banks. Here is a simple trick to scrape \nsuch data from a website: Use Google Docs.", 
    "htmlSnippet": "Nov 15, 2009 <b>...</b> One example is the FDIC&#39;s List of Failed Banks. Here is a simple trick to <b>scrape</b> <br>\nsuch data from a <b>website</b>: Use Google Docs.", 
    "link": "https://eagereyes.org/data/scrape-tables-using-google-docs", 
    "cacheId": "lUk_PFRhedsJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "CloudScrape - Cloud-based web scraping platform", 
    "displayLink": "cloudscrape.com", 
    "htmlTitle": "<b>CloudScrape</b> - Cloud-based web <b>scraping</b> platform", 
    "formattedUrl": "cloudscrape.com/", 
    "htmlFormattedUrl": "cloud<b>scrape</b>.com/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0", 
          "author": "CloudScrape"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "258", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcQix-tH1jNyG19aqgvduWNUDw8sEhda5YCqWJpcQd2WW3KtYsjfsvtQ8isf", 
          "height": "196"
        }
      ], 
      "cse_image": [
        {
          "src": "http://cloudscrape.com/img/ss.png"
        }
      ]
    }, 
    "snippet": "Web scraping as a service. Use our browser-based scraping platform to extract \ndata from any website. Free plan available!", 
    "htmlSnippet": "Web <b>scraping</b> as a service. Use our browser-based <b>scraping</b> platform to extract <br>\ndata from any <b>website</b>. Free plan available!", 
    "link": "http://cloudscrape.com/", 
    "cacheId": "2u-Ae3hwr9cJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping the Web With Node.js | Scotch", 
    "displayLink": "scotch.io", 
    "htmlTitle": "<b>Scraping</b> the Web With Node.js | Scotch", 
    "formattedUrl": "https://scotch.io/tutorials/scraping-the-web-with-node-js", 
    "htmlFormattedUrl": "https://scotch.io/tutorials/<b>scraping</b>-the-web-with-node-js", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "kukicadnan", 
          "og:url": "https://scotch.io/tutorials/scraping-the-web-with-node-js", 
          "og:type": "article", 
          "og:site_name": "Scotch", 
          "application-name": "Scotch Scotch scotch", 
          "author": "Adnan Kukic", 
          "fb:app_id": "1389892087910588", 
          "msapplication-tilecolor": "#2A2A2A", 
          "fb:admins": "579622216,709634581", 
          "apple-mobile-web-app-capable": "yes", 
          "twitter:title": "Scraping the Web With Node.js", 
          "apple-mobile-web-app-status-bar-style": "black-translucent", 
          "msapplication-tileimage": "https://scotch.io/wp-content/themes/forty/img/icons/favicon-144.png", 
          "og:title": "Scraping the Web With Node.js", 
          "twitter:card": "summary_large_image", 
          "twitter:site": "@scotch_io", 
          "article:publisher": "https://www.facebook.com/scotchdevelopment", 
          "twitter:image:src": "https://cask.scotch.io/2014/03/node-js-web-scraping-cheerio-request.jpg", 
          "og:image": "https://cask.scotch.io/2014/03/node-js-web-scraping-cheerio-request.jpg", 
          "article:author": "kukicadnan", 
          "viewport": "width=device-width, initial-scale=1.0, maximum-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "348", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTWAQpfln2pPr8uJMr4jFIdCdm8UZMO02PyWyjhLsnh6yNpNU5VMQCC8-8", 
          "height": "145"
        }
      ], 
      "cse_image": [
        {
          "src": "https://cask.scotch.io/2014/03/node-js-web-scraping-cheerio-request.jpg"
        }
      ]
    }, 
    "snippet": "Mar 13, 2014 ... It can be done manually by copy and pasting data from a website, using \nspecialized software, or building your own scripts to scrape data. In this\u00a0...", 
    "htmlSnippet": "Mar 13, 2014 <b>...</b> It can be done manually by copy and pasting data from a <b>website</b>, using <br>\nspecialized software, or building your own scripts to <b>scrape</b> data. In this&nbsp;...", 
    "link": "https://scotch.io/tutorials/scraping-the-web-with-node-js", 
    "cacheId": "47_ab8GHRl8J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "An Intro to Web Scraping | The Bastards Book of Ruby", 
    "displayLink": "ruby.bastardsbook.com", 
    "htmlTitle": "An Intro to Web <b>Scraping</b> | The Bastards Book of Ruby", 
    "formattedUrl": "ruby.bastardsbook.com/chapters/web-scraping/", 
    "htmlFormattedUrl": "ruby.bastardsbook.com/chapters/web-<b>scraping</b>/", 
    "pagemap": {
      "metatags": [
        {
          "og:site_name": "The Bastards Book of Ruby", 
          "author": "Dan Nguyen", 
          "csrf-token": "L9IL60bLz/xHe+THCyPn25ubTFfnrivGhWpwKJMSZFo=", 
          "fb:admins": "daonguyen74", 
          "csrf-param": "authenticity_token", 
          "type": "book", 
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "279", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQC0Y_ck7vlaUotxgjkQiTk0XtQaGsO5WqLm9stjxUW9hBiWN1u_ys8IaY", 
          "height": "180"
        }
      ], 
      "cse_image": [
        {
          "src": "http://ruby.bastardsbook.com/assets/images/lede/web-scraping.jpg"
        }
      ]
    }, 
    "snippet": "Dec 3, 2011 ... This chapter introduces the strategy of web scraping with a very non-technical \noverview of how websites work. We won't cover any code.", 
    "htmlSnippet": "Dec 3, 2011 <b>...</b> This chapter introduces the strategy of web <b>scraping</b> with a very non-technical <br>\noverview of how <b>websites</b> work. We won&#39;t cover any code.", 
    "link": "http://ruby.bastardsbook.com/chapters/web-scraping/", 
    "cacheId": "5hdecWW0gXEJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to Scrape Web Pages with Node.js and jQuery - Tuts+ Code ...", 
    "displayLink": "code.tutsplus.com", 
    "htmlTitle": "<b>How to Scrape</b> Web Pages with Node.js and jQuery - Tuts+ Code <b>...</b>", 
    "formattedUrl": "code.tutsplus.com/.../how-to-scrape-web-pages-with-nodejs-and-jquery--net- 22478", 
    "htmlFormattedUrl": "code.tutsplus.com/.../<b>how-to-scrape</b>-web-pages-with-nodejs-and-jquery--net- 22478", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://code.tutsplus.com/tutorials/how-to-scrape-web-pages-with-nodejs-and-jquery--net-22478", 
          "og:site_name": "Code Tuts+", 
          "csrf-token": "TeD0HNSP3ysvf1gLvgIVKpzeGe8bEdN2waEd9numo2lQIzzV0vpIgd1JopC+1kuz8JLrh9Q86yVy3KIZsPQcCw==", 
          "og:type": "article", 
          "og:description": "Node.js is growing rapidly; one of the biggest reasons for this is thanks to the developers who create amazing tools that significantly improve productivity with Node. In this article, we will go through the basic installation of Express, a development framework, and creating a basic project with it. | Difficulty: Intermediate; Length: Short; Tags: Web Development, jQuery, Node.js, JavaScript", 
          "csrf-param": "authenticity_token", 
          "et.category": "Web Development", 
          "og:title": "How to Scrape Web Pages with Node.js and jQuery - Tuts+ Code Tutorial", 
          "fb:app_id": "1494084460809023", 
          "og:image": "https://cdn.tutsplus.com/net/uploads/legacy/1075_nodexpress/node.png", 
          "viewport": "initial-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "160", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcSx7lPFdS1rnSKpPY8tgzUuIIflriokcWqR1fhqgW5dmRqy3K2ra0TzFEQb", 
          "height": "160"
        }
      ], 
      "cse_image": [
        {
          "src": "https://cdn.tutsplus.com/net/uploads/legacy/1075_nodexpress/node.png"
        }
      ]
    }, 
    "snippet": "Oct 28, 2011 ... In this tutorial, we will scrape the YouTube home page, get all the regular sized \nthumbnails from the page as well as links and video duration\u00a0...", 
    "htmlSnippet": "Oct 28, 2011 <b>...</b> In this tutorial, we will <b>scrape</b> the YouTube home page, get all the regular sized <br>\nthumbnails from the page as well as links and video duration&nbsp;...", 
    "link": "http://code.tutsplus.com/tutorials/how-to-scrape-web-pages-with-nodejs-and-jquery--net-22478", 
    "cacheId": "4ZTRaDONYWAJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "What are the ethics of web scraping? - Quick Left", 
    "displayLink": "quickleft.com", 
    "htmlTitle": "What are the ethics of web <b>scraping</b>? - Quick Left", 
    "formattedUrl": "https://quickleft.com/blog/is-web-scraping-ethical/", 
    "htmlFormattedUrl": "https://quickleft.com/blog/is-web-<b>scraping</b>-ethical/", 
    "pagemap": {
      "metatags": [
        {
          "og:image": "https://quickleft.wpengine.com/wp-content/uploads/q_logo.png", 
          "og:url": "https://quickleft.com/blog/is-web-scraping-ethical/", 
          "og:type": "article", 
          "og:site_name": "Quick Left", 
          "og:locale": "en_US", 
          "og:description": "Someone recently asked: \"Is web scraping an ethical concept?\" I believe that web scraping is absolutely an ethical concept. Web scraping (or screen scraping) is a mechanism to have a computer read a website. There is absolutely no technical difference between an automated computer viewing a website and a human-driven computer viewing a website. Furthermore, \u2026", 
          "og:title": "What are the ethics of web scraping? - Quick Left", 
          "article:publisher": "https://www.facebook.com/quickleft", 
          "article:tag": "ethics", 
          "article:published_time": "2014-02-26T07:22:00+00:00", 
          "viewport": "width=device-width, initial-scale=1, maximum-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "136", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcScRAPAcfX1YjaU8gtklrPfafjLdyiGPgHRXuahQiG9ocRJpMtoYEQKwGY", 
          "height": "136"
        }
      ], 
      "cse_image": [
        {
          "src": "https://quickleft.com/wp-content/uploads/justin_abrahms.png"
        }
      ]
    }, 
    "snippet": "May 4, 2015 ... Web scraping (or screen scraping) is a mechanism to have a computer read a \nwebsite. There is absolutely no technical difference between an\u00a0...", 
    "htmlSnippet": "May 4, 2015 <b>...</b> Web <b>scraping</b> (or screen <b>scraping</b>) is a mechanism to have a computer read a <br>\n<b>website</b>. There is absolutely no technical difference between an&nbsp;...", 
    "link": "https://quickleft.com/blog/is-web-scraping-ethical/", 
    "cacheId": "nH-jXr2YpIIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How do I scrape a website using MATLAB? - MATLAB Answers ...", 
    "displayLink": "www.mathworks.com", 
    "htmlTitle": "How do I <b>scrape a website</b> using MATLAB? - MATLAB Answers <b>...</b>", 
    "formattedUrl": "www.mathworks.com/.../142409-how-do-i-scrape-a-website-using-matlab", 
    "htmlFormattedUrl": "www.mathworks.com/.../142409-how-do-i-<b>scrape-a-website</b>-using-matlab", 
    "pagemap": {
      "metatags": [
        {
          "csrf-param": "authenticity_token", 
          "csrf-token": "53XwAOO/I0ajW6bPwczKp+jlpq51AhzyR3A+mM3Op80=", 
          "confirm-close": "You may have unsaved changes to a question, answer, or comment."
        }
      ], 
      "Person": [
        {
          "name": "azizullah khan (view profile)"
        }, 
        {
          "name": "Image Analyst (view profile)"
        }, 
        {
          "name": "azizullah khan (view profile)"
        }, 
        {
          "name": "Image Analyst (view profile)"
        }, 
        {
          "name": "Image Analyst (view profile)"
        }
      ], 
      "CreativeWork": [
        {
          "answers_accepted_count": "0 accepted answers", 
          "question": "33 questions", 
          "answer_count": "4 answers", 
          "answers_reputation": "Reputation: 1", 
          "answers_accepted": "0 accepted answers", 
          "answer": "4 answers", 
          "question_count": "33 questions"
        }, 
        {
          "answers_accepted_count": "4,888 accepted answers", 
          "question": "0 questions", 
          "answer_count": "15,136 answers", 
          "answers_reputation": "Reputation: 24,502", 
          "answers_accepted": "4,888 accepted answers", 
          "answer": "15,136 answers", 
          "question_count": "0 questions"
        }, 
        {
          "answers_accepted_count": "0 accepted answers", 
          "question": "33 questions", 
          "answer_count": "4 answers", 
          "answers_reputation": "Reputation: 1", 
          "answers_accepted": "0 accepted answers", 
          "answer": "4 answers", 
          "question_count": "33 questions"
        }, 
        {
          "answers_accepted_count": "4,888 accepted answers", 
          "question": "0 questions", 
          "answer_count": "15,136 answers", 
          "answers_reputation": "Reputation: 24,502", 
          "answers_accepted": "4,888 accepted answers", 
          "answer": "15,136 answers", 
          "question_count": "0 questions"
        }, 
        {
          "answers_accepted_count": "4,888 accepted answers", 
          "question": "0 questions", 
          "answer_count": "15,136 answers", 
          "answers_reputation": "Reputation: 24,502", 
          "answers_accepted": "4,888 accepted answers", 
          "answer": "15,136 answers", 
          "question_count": "0 questions"
        }
      ], 
      "hcard": [
        {
          "fn": "azizullah khan (view profile)"
        }, 
        {
          "fn": "Image Analyst (view profile)"
        }, 
        {
          "fn": "azizullah khan (view profile)"
        }, 
        {
          "fn": "Image Analyst (view profile)"
        }, 
        {
          "fn": "Image Analyst (view profile)"
        }
      ]
    }, 
    "snippet": "Jul 18, 2014 ... ... 4,888 accepted answers; Reputation: 24,502. on 20 Jul 2014. I want to scrape \nthe text data from a table on a website. I have used urlfilter but\u00a0...", 
    "htmlSnippet": "Jul 18, 2014 <b>...</b> ... 4,888 accepted answers; Reputation: 24,502. on 20 Jul 2014. I want to <b>scrape</b> <br>\nthe text data from a table on a <b>website</b>. I have used urlfilter but&nbsp;...", 
    "link": "http://www.mathworks.com/matlabcentral/answers/142409-how-do-i-scrape-a-website-using-matlab", 
    "cacheId": "X4FFW5aJ3F4J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to Scrape Website Content | Power Tips For Google Docs", 
    "displayLink": "googledocstips.com", 
    "htmlTitle": "<b>How to Scrape Website</b> Content | Power Tips For Google Docs", 
    "formattedUrl": "googledocstips.com/2011/04/15/how-to-scrape-website-content/", 
    "htmlFormattedUrl": "googledocstips.com/2011/04/15/<b>how-to-scrape</b>-<b>website</b>-content/", 
    "pagemap": {
      "cse_thumbnail": [
        {
          "width": "205", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcS-pFIT2HbCR_tJ_2oUqP1nCsrf1-eu7r-SJM3g1e7jEr2fiu-PBK0-730", 
          "height": "240"
        }
      ], 
      "cse_image": [
        {
          "src": "http://googledocstips.com/wp-content/uploads/2011/04/getelement-257x300.png"
        }
      ], 
      "hcard": [
        {
          "url": "http://www.marketingonlineteam.com/", 
          "photo": "http://1.gravatar.com/avatar/3560a785f8bc5ecebe260d98daf4db3d?s=34&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "url_text": "Michele", 
          "nickname": "Michele", 
          "fn": "Michele"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/58aae6dc90715234b4ac2d2fa21fe627?s=34&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "admin", 
          "fn": "admin"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/bc4b338fff6e738fb63ec75ba6d92e94?s=34&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "mauren", 
          "fn": "mauren"
        }, 
        {
          "photo": "http://0.gravatar.com/avatar/ca49dd81c7f7758811010739c1b17ba3?s=34&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "darling", 
          "fn": "darling"
        }, 
        {
          "photo": "http://0.gravatar.com/avatar/89cd7efc01de7e13267cb9129d0a290b?s=34&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "Erica", 
          "fn": "Erica"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/76b435b983bf78243f05cd30257e2101?s=34&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "Greg", 
          "fn": "Greg"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/58aae6dc90715234b4ac2d2fa21fe627?s=34&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "admin", 
          "fn": "admin"
        }, 
        {
          "photo": "http://0.gravatar.com/avatar/4222a90ddb5171b4a5eb657ef611fca4?s=34&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "RMB", 
          "fn": "RMB"
        }, 
        {
          "photo": "http://0.gravatar.com/avatar/46d80655d1a622b93c801b4e8b58f1d5?s=34&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "Tori", 
          "fn": "Tori"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/995266c6dbb9e186d06f70bf07c4fe41?s=34&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D34&r=G", 
          "nickname": "chris", 
          "fn": "chris"
        }
      ]
    }, 
    "snippet": "Apr 15, 2011 ... While this tip might be a little more advanced, it shows how easy it is to \u201cscrape\u201d \ncontent from websites into your spreadsheets. We'll be relying\u00a0...", 
    "htmlSnippet": "Apr 15, 2011 <b>...</b> While this tip might be a little more advanced, it shows how easy it is to \u201c<b>scrape</b>\u201d <br>\ncontent from <b>websites</b> into your spreadsheets. We&#39;ll be relying&nbsp;...", 
    "link": "http://googledocstips.com/2011/04/15/how-to-scrape-website-content/", 
    "cacheId": "rlooS3EiMyQJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to Scrape a Website | Turn websites into useful data ...", 
    "displayLink": "www.promptcloud.com", 
    "htmlTitle": "<b>How to Scrape a Website</b> | Turn websites into useful data <b>...</b>", 
    "formattedUrl": "https://www.promptcloud.com/blog/how-to-scrape-a-website/", 
    "htmlFormattedUrl": "https://www.promptcloud.com/blog/<b>how-to-scrape-a-website</b>/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "https://www.promptcloud.com/blog/how-to-scrape-a-website/", 
          "og:locale": "en_US", 
          "article:modified_time": "2015-04-23T09:29:51+00:00", 
          "twitter:card": "summary", 
          "twitter:image": "https://www.promptcloud.com/wp-content/uploads/2015/04/Web-scraping.png?w=240", 
          "og:type": "article", 
          "og:description": "The scraping of a website is not a daunting task anymore. The technically aware professionals will help you out of how to go about it. How to scrap a website is just a click away. The scraping of a...", 
          "article:author": "https://www.promptcloud.com/author/dungaragmail-com/", 
          "og:title": "How to scrape a website", 
          "twitter:site": "@promptcloud", 
          "og:image": "https://www.promptcloud.com/wp-content/uploads/2015/04/Web-scraping.png", 
          "article:published_time": "2015-04-13T13:35:05+00:00", 
          "viewport": "width=device-width,initial-scale=1,user-scalable=no", 
          "og:site_name": "PromptCloud"
        }
      ], 
      "cse_image": [
        {
          "src": "https://www.promptcloud.com/wp-content/uploads/2015/04/Web-scraping.png"
        }
      ]
    }, 
    "snippet": "Apr 13, 2015 ... The scraping of a website is usually done to churn out the information from \nvarious websites for formulating of the strategy against the\u00a0...", 
    "htmlSnippet": "Apr 13, 2015 <b>...</b> The <b>scraping</b> of a <b>website</b> is usually done to churn out the information from <br>\nvarious <b>websites</b> for formulating of the strategy against the&nbsp;...", 
    "link": "https://www.promptcloud.com/blog/how-to-scrape-a-website/", 
    "cacheId": "hc5TJmyAHfIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Data Extraction, Web Scraping and Web Mining Made Easy ...", 
    "displayLink": "imacros.net", 
    "htmlTitle": "Data Extraction, Web <b>Scraping</b> and Web Mining Made Easy <b>...</b>", 
    "formattedUrl": "imacros.net/overview/data-extraction", 
    "htmlFormattedUrl": "imacros.net/overview/data-extraction", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://imacros.net/overview/data-extraction", 
          "og:site_name": "iMacros", 
          "og:type": "article", 
          "og:description": "Browser Automation, Data Extraction and Web Testing Software", 
          "og:title": "Data Extraction", 
          "og:image": "http://imacros.net/wp-content/uploads/2013/12/data-extraction.png", 
          "viewport": "width=device-width, initial-scale=1, maximum-scale=1"
        }
      ], 
      "Breadcrumb": [
        {
          "url": "Home", 
          "title": "Home"
        }, 
        {
          "url": "Overview", 
          "title": "Overview"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "380", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcRcoG2pXMVg-evaCNoIDH2DB-dQNVsIIoPcYVurhJYZq9OO1oj0n83EuS8j", 
          "height": "132"
        }
      ], 
      "cse_image": [
        {
          "src": "http://imacros.net/wp-content/uploads/2013/12/data-extraction.png"
        }
      ]
    }, 
    "snippet": "Do you need to screen-scrape web data into your database, spreadsheet or any \n... Check the meta information on pages of a website (description, keywords,\u00a0...", 
    "htmlSnippet": "Do you need to screen-<b>scrape</b> web data into your database, spreadsheet or any <br>\n... Check the meta information on pages of a <b>website</b> (description, keywords,&nbsp;...", 
    "link": "http://imacros.net/overview/data-extraction", 
    "cacheId": "uCWVqK8C1zAJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to Scrape Google Search Results with Google Sheets", 
    "displayLink": "www.labnol.org", 
    "htmlTitle": "<b>How to Scrape</b> Google Search Results with Google Sheets", 
    "formattedUrl": "www.labnol.org/internet/google-web-scraping/28450/", 
    "htmlFormattedUrl": "www.labnol.org/internet/google-web-<b>scraping</b>/28450/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@labnol", 
          "og:url": "http://www.labnol.org/internet/google-web-scraping/28450/", 
          "og:image": "http://img.labnol.org/di/google-search-scraper.png", 
          "og:site_name": "Digital Inspiration", 
          "twitter:card": "summary_large_image", 
          "twitter:description": "Learn how to easily scrape Google search results pages and save the keyword ranking data inside Google Spreadsheets using the ImportXML formula.", 
          "twitter:image:src": "http://img.labnol.org/di/google-search-scraper.png", 
          "og:description": "Learn how to easily scrape Google search results pages and save the keyword ranking data inside Google Spreadsheets using the ImportXML formula.", 
          "article:author": "https://www.facebook.com/agarwal.amit", 
          "twitter:title": "How to Scrape Google Search Results inside a Google Sheet", 
          "og:title": "How to Scrape Google Search Results inside a Google Sheet", 
          "twitter:site": "@howto_guides", 
          "article:publisher": "https://www.facebook.com/digital.inspiration", 
          "twitter:url": "http://www.labnol.org/internet/google-web-scraping/28450/", 
          "twitter:account_id": "1510093219", 
          "og:type": "article", 
          "viewport": "width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
        }
      ], 
      "Breadcrumb": [
        {
          "url": "Home", 
          "title": "Home"
        }, 
        {
          "url": "How-to Guides", 
          "title": "How-to Guides"
        }, 
        {
          "url": "Google", 
          "title": "Google"
        }, 
        {
          "url": "Google Docs", 
          "title": "Google Docs"
        }, 
        {
          "url": "How to Scrape Google Search Results inside a Google Sheet", 
          "title": "How to Scrape Google Search Results inside a Google Sheet"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "275", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQnush3ARhXgp8M4WW7Xvc0pGJI8bqdZ1SrDVBIDTraPM5K2LMNeOJH66eD", 
          "height": "183"
        }
      ], 
      "cse_image": [
        {
          "src": "http://img.labnol.org/di/google-search-scraper.png"
        }
      ], 
      "hcard": [
        {
          "fn": "Amit Agarwal"
        }
      ]
    }, 
    "snippet": "Mar 27, 2015 ... Learn how to easily scrape Google search results pages and save the ... the \norganic search rankings of your website in Google for particular\u00a0...", 
    "htmlSnippet": "Mar 27, 2015 <b>...</b> Learn how to easily <b>scrape</b> Google search results pages and save the ... the <br>\norganic search rankings of your <b>website</b> in Google for particular&nbsp;...", 
    "link": "http://www.labnol.org/internet/google-web-scraping/28450/", 
    "cacheId": "vvdn799V658J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Do you want to scrape a website? | MetaFilter", 
    "displayLink": "www.metafilter.com", 
    "htmlTitle": "Do you want to <b>scrape a website</b>? | MetaFilter", 
    "formattedUrl": "www.metafilter.com/148030/Do-you-want-to-scrape-a-website", 
    "htmlFormattedUrl": "www.metafilter.com/148030/Do-you-want-to-<b>scrape-a-website</b>", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://www.metafilter.com/148030/Do-you-want-to-scrape-a-website", 
          "og:image": "http://cdn.mefi.us/images/mefi/apple-touch-icon.png", 
          "application-name": "MetaFilter", 
          "twitter:card": "summary", 
          "twitter:image": "http://cdn.mefi.us/images/mefi/apple-touch-icon.png", 
          "twitter:description": "Did you ever just want a bunch of web data as painlessly as possible but don't know a thing about command-line webscrapers (curl, wget) or parsing libraries (BeautifulSoup, JSoup, pandas)? import....", 
          "og:type": "blog", 
          "og:description": "Did you ever just want a bunch of web data as painlessly as possible but don't know a thing about command-line webscrapers (curl, wget) or parsing libraries (BeautifulSoup, JSoup, pandas)? import....", 
          "twitter:site": "@metafilter", 
          "og:title": "\u266bDo you want to scrape a website?\u266b", 
          "twitter:title": "\u266bDo you want to scrape a website?\u266b", 
          "twitter:url": "http://www.metafilter.com/148030/Do-you-want-to-scrape-a-website", 
          "viewport": "width=device-width, initial-scale=1, user-scalable=1"
        }
      ], 
      "cse_image": [
        {
          "src": "http://cdn.mefi.us/images/mefi/apple-touch-icon.png"
        }
      ]
    }, 
    "snippet": "import.io will try to auto-magically hash any website you give it into .... Scraping \nwebsites was one of the first \"real programming\" things I\u00a0...", 
    "htmlSnippet": "import.io will try to auto-magically hash any website you give it into .... <b>Scraping</b> <br>\n<b>websites</b> was one of the first &quot;real programming&quot; things I&nbsp;...", 
    "link": "http://www.metafilter.com/148030/Do-you-want-to-scrape-a-website", 
    "cacheId": "A9mX2uuEtPQJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "An Introduction to Compassionate Screen Scraping - Irrational ...", 
    "displayLink": "lethain.com", 
    "htmlTitle": "An Introduction to Compassionate Screen <b>Scraping</b> - Irrational <b>...</b>", 
    "formattedUrl": "lethain.com/an-introduction-to-compassionate-screenscraping/", 
    "htmlFormattedUrl": "lethain.com/an-introduction-to-compassionate-screen<b>scraping</b>/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://lethain.com/an-introduction-to-compassionate-screenscraping/", 
          "author": "Will Larson", 
          "og:type": "article", 
          "og:description": "One of the most common quickie projects on the web is to screenscrape a website and play around with its data. These projects are a lot of fun, and can allow for inventive mashups, but often the screepscraping scripts cause unnecessary load on the site's servers due to inconsiderate technique. This is an introduction to the art of compassionate screenscraping.", 
          "og:title": "An Introduction to Compassionate Screen Scraping", 
          "viewport": "width=device-width, initial-scale=1"
        }
      ]
    }, 
    "snippet": "Aug 10, 2008 ... This is a tutorial on not just screen scraping, but socially responsible screen ... \nFor small websites 'hell' is a complete crash, while for bigger\u00a0...", 
    "htmlSnippet": "Aug 10, 2008 <b>...</b> This is a tutorial on not just screen <b>scraping</b>, but socially responsible screen ... <br>\nFor small <b>websites</b> &#39;hell&#39; is a complete crash, while for bigger&nbsp;...", 
    "link": "http://lethain.com/an-introduction-to-compassionate-screenscraping/", 
    "cacheId": "qgeJcvi6CF4J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping with BeautifulSoup", 
    "displayLink": "www.pythonforbeginners.com", 
    "htmlTitle": "Web <b>Scraping</b> with BeautifulSoup", 
    "formattedUrl": "www.pythonforbeginners.com/.../web-scraping-with-beautifulsoup/", 
    "htmlFormattedUrl": "www.pythonforbeginners.com/.../web-<b>scraping</b>-with-beautifulsoup/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://www.pythonforbeginners.com/python-on-the-web/web-scraping-with-beautifulsoup/", 
          "og:type": "website", 
          "og:site_name": "Python For Beginners", 
          "og:locale": "en_US", 
          "og:title": "Web Scraping with BeautifulSoup", 
          "viewport": "width=device-width"
        }
      ]
    }, 
    "snippet": "May 23, 2013 ... HTML parsing is easy in Python, especially with help of the BeautifulSoup library. \nIn this post we will scrape a website (our own) to extract all\u00a0...", 
    "htmlSnippet": "May 23, 2013 <b>...</b> HTML parsing is easy in Python, especially with help of the BeautifulSoup library. <br>\nIn this post we will <b>scrape a website</b> (our own) to extract all&nbsp;...", 
    "link": "http://www.pythonforbeginners.com/python-on-the-web/web-scraping-with-beautifulsoup/", 
    "cacheId": "8xWQ1Ls9BoUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Custom Scraper Tool for Web and Data Scraping", 
    "displayLink": "urlprofiler.com", 
    "htmlTitle": "Custom Scraper Tool for Web and Data <b>Scraping</b>", 
    "formattedUrl": "urlprofiler.com/blog/custom-scraper/", 
    "htmlFormattedUrl": "urlprofiler.com/blog/custom-<b>scrape</b>r/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@urlprofiler", 
          "twitter:domain": "URL Profiler", 
          "og:locale": "en_US", 
          "twitter:site": "@urlprofiler", 
          "article:publisher": "https://www.facebook.com/urlprofiler", 
          "og:url": "http://urlprofiler.com/blog/custom-scraper/", 
          "twitter:account_id": "4503599630263261", 
          "og:type": "article", 
          "fb:admins": "753580149", 
          "og:title": "Custom Scraper Tool for Web and Data Scraping", 
          "twitter:title": "Custom Scraper Tool for Web and Data Scraping", 
          "article:section": "How To", 
          "skype_toolbar": "SKYPE_TOOLBAR_PARSER_COMPATIBLE", 
          "article:modified_time": "2014-10-02T16:25:37+00:00", 
          "msvalidate.01": "656CF2AF18D4457E50FF286771D130FA", 
          "og:image": "http://urlprofiler.com/wp-content/uploads/2014/07/customwebscraper.png", 
          "article:published_time": "2014-07-23T20:01:39+00:00", 
          "viewport": "width=device-width, initial-scale=1.0", 
          "og:updated_time": "2014-10-02T16:25:37+00:00", 
          "og:site_name": "URL Profiler", 
          "twitter:card": "summary_large_image", 
          "twitter:description": "The custom scraper is URL Profiler\u2019s\u00a0web scraping tool, which\u00a0allows you to quickly extract data from thousands of URLs. Unlike many of the other solutions available, you can extract information from all the rendered source, including anything\u00a0not rendered in the browser. Some stuff you can scrape: Text URLs Tracking codes HTML Structured\u00a0Markup Inline JavaScript and CSS [\u2026]", 
          "og:description": "The custom scraper is URL Profiler\u2019s\u00a0web scraping tool, which\u00a0allows you to quickly extract data from thousands of URLs. Unlike many of the other solutions available, you can extract information from all the rendered source, including anything\u00a0not rendered in the browser. Some stuff you can scrape: Text URLs Tracking codes HTML Structured\u00a0Markup Inline JavaScript and CSS \u2026", 
          "twitter:image:src": "http://urlprofiler.com/wp-content/uploads/2014/07/customwebscraper.png", 
          "majestic-site-verification": "MJ12_017db368-69b5-4c91-804c-5d8abfe913ca"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "369", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSMcAwfd2SkmHjJgf1YIBYUQO3MEah4p0wh9f0egbuR_GRs7AC8vuQ8ElvT", 
          "height": "136"
        }
      ], 
      "cse_image": [
        {
          "src": "http://urlprofiler.com/wp-content/uploads/2014/07/customwebscraper.png"
        }
      ]
    }, 
    "snippet": "Jul 23, 2014 ... The custom scraper is URL Profiler's web scraping tool, which allows you to ... \nUser's Name; Job title; Place of work; User's website URL; Social\u00a0...", 
    "htmlSnippet": "Jul 23, 2014 <b>...</b> The custom scraper is URL Profiler&#39;s web <b>scraping</b> tool, which allows you to ... <br>\nUser&#39;s Name; Job title; Place of work; User&#39;s <b>website</b> URL; Social&nbsp;...", 
    "link": "http://urlprofiler.com/blog/custom-scraper/", 
    "cacheId": "tl-bTm33c6MJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Mozenda: Screen Scraping, Data Scraping, Data Extraction Software", 
    "displayLink": "www.mozenda.com", 
    "htmlTitle": "Mozenda: Screen <b>Scraping</b>, Data <b>Scraping</b>, Data Extraction Software", 
    "formattedUrl": "https://www.mozenda.com/", 
    "htmlFormattedUrl": "https://www.mozenda.com/", 
    "pagemap": {
      "cse_thumbnail": [
        {
          "width": "260", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcTaZQmsNnm4Y2SK2xemrd6dzgqEmSY6JGRKuJL7LOA17n3wp-V6FWyzoo4", 
          "height": "194"
        }
      ], 
      "cse_image": [
        {
          "src": "https://www.mozenda.com/Company2/Images/HomeVideo-ov.png"
        }
      ]
    }, 
    "snippet": "The Mozenda screen scraper provides web data extraction software and data \nscraping tools that make it easy to capture content from the web.", 
    "htmlSnippet": "The Mozenda screen scraper provides web data extraction software and data <br>\n<b>scraping</b> tools that make it easy to capture content from the web.", 
    "link": "https://www.mozenda.com/", 
    "cacheId": "tF7-Dm4CI0YJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How to Scrape a Website", 
    "displayLink": "www.websundew.com", 
    "htmlTitle": "<b>How to Scrape a Website</b>", 
    "formattedUrl": "www.websundew.com/how-to-scrape-website", 
    "htmlFormattedUrl": "www.websundew.com/<b>how-to-scrape</b>-<b>website</b>", 
    "pagemap": {
      "rating": [
        {
          "average": "9", 
          "votes": "784", 
          "ratingvalue": "9", 
          "best": "10"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "266", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTJFVhi2Yg6r4s21rZ3SiKVVDnLfT1pHydRD3De50_y3Sa6RDqHIfEaN8lL", 
          "height": "189"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.websundew.com/images/img-how-to-scrape-website_t.png"
        }
      ], 
      "review-aggregate": [
        {
          "itemreviewed": "WebSundew"
        }
      ]
    }, 
    "snippet": "More and more advanced Internet users ask us a question how to scrape a \nwebsite. Let us try to understand what web scraping is and how to scrape a \nwebsite\u00a0...", 
    "htmlSnippet": "More and more advanced Internet users ask us a question <b>how to scrape a</b> <br>\n<b>website</b>. Let us try to understand what web scraping is and <b>how to scrape a</b> <br>\n<b>website</b>&nbsp;...", 
    "link": "http://www.websundew.com/how-to-scrape-website", 
    "cacheId": "29zmtNBrMaoJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Website Scrape", 
    "displayLink": "www.mozenda.com", 
    "htmlTitle": "<b>Website Scrape</b>", 
    "formattedUrl": "https://www.mozenda.com/website-scrape", 
    "htmlFormattedUrl": "https://www.mozenda.com/<b>website</b>-<b>scrape</b>", 
    "snippet": "Performing a website scrape is to engage in collecting data presented on a \nwebsite in a browser, visibly or in the source code. \"Scrapes\" are done by \nsoftware\u00a0...", 
    "htmlSnippet": "Performing a <b>website scrape</b> is to engage in collecting data presented on a <br>\n<b>website</b> in a browser, visibly or in the source code. &quot;Scrapes&quot; are done by <br>\nsoftware&nbsp;...", 
    "link": "https://www.mozenda.com/website-scrape", 
    "cacheId": "oaAErLaSMDcJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Website Scraper - Scrape Websites and Extract Data", 
    "displayLink": "www.microsystools.com", 
    "htmlTitle": "Website Scraper - <b>Scrape Websites</b> and Extract Data", 
    "formattedUrl": "www.microsystools.com/products/website-scraper/", 
    "htmlFormattedUrl": "www.microsystools.com/products/<b>website</b>-<b>scrape</b>r/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "102", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcSl2a-Nj8hX4W9WHl4zTM85a7hX4mrpHP4JaxQxYrml1jyfaBUM5EF57Q", 
          "height": "102"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.microsystools.com/products/website-scraper/website-scraper-icon-128.png"
        }
      ]
    }, 
    "snippet": "Scrape websites and extract data into CSV files ready to be imported anywhere. \nMix and mash scraped website data to create new mashup website services.", 
    "htmlSnippet": "<b>Scrape websites</b> and extract data into CSV files ready to be imported anywhere. <br>\nMix and mash scraped website data to create new mashup website services.", 
    "link": "http://www.microsystools.com/products/website-scraper/", 
    "cacheId": "wu-vNLqN5EUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Basic web scraping and data visualization using Google Spreadsheets", 
    "displayLink": "www.mulinblog.com", 
    "htmlTitle": "Basic web <b>scraping</b> and data visualization using Google Spreadsheets", 
    "formattedUrl": "www.mulinblog.com/basic-web-scraping-data-visualization-using-google- spreadsheets/", 
    "htmlFormattedUrl": "www.mulinblog.com/basic-web-<b>scraping</b>-data-visualization-using-google- spreadsheets/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@mututemple", 
          "og:url": "http://www.mulinblog.com/basic-web-scraping-data-visualization-using-google-spreadsheets/", 
          "og:type": "article", 
          "article:modified_time": "2014-12-17T14:48:27+00:00", 
          "twitter:domain": "MulinBlog: A digital journalism blog", 
          "og:locale": "en_US", 
          "twitter:description": "A 3-step guide on how to scrape tabular data on a webpage, visualize the data and then share the visualizations", 
          "twitter:image:src": "http://www.mulinblog.com/wp-content/uploads/2013/10/U.S.-population-2013-10-15-14-02-52.png", 
          "og:description": "Google Spreadsheets provides a free, one-stop solution for journalists and researchers to retrieve tabular data from a web page, visualize the data, and embed the visualizations in a news or resear...", 
          "article:author": "https://www.facebook.com/mulinblogjschool", 
          "twitter:image": "http://www.mulinblog.com/wp-content/uploads/2013/10/U.S.-population-2013-10-15-14-02-52.png?w=240", 
          "twitter:site": "@mututemple", 
          "og:title": "Basic web scraping and data visualization using Google Spreadsheets", 
          "twitter:card": "summary", 
          "twitter:title": "Basic web scraping and data visualization using Google Spreadsheets", 
          "og:image": "http://www.mulinblog.com/wp-content/uploads/2013/10/chart-editor.jpg", 
          "article:published_time": "2013-10-16T02:30:22+00:00", 
          "og:site_name": "MulinBlog: A digital journalism blog"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "303", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcROyErVbfOuJK6I0lHcVnEChb6z1f4k8lmwCitO6pSS9T3y3-QXEIjftbuM", 
          "height": "166"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.mulinblog.com/wp-content/uploads/2013/10/chart-editor.jpg"
        }
      ], 
      "hcard": [
        {
          "url": "http://websitescraper.com/", 
          "photo": "http://1.gravatar.com/avatar/ae440ff43ee8edc4a4549aba5fe54264?s=40&d=mm&r=g", 
          "url_text": "Websitescrper", 
          "nickname": "Websitescrper", 
          "fn": "Websitescrper"
        }, 
        {
          "url": "http://www.mulinblog.com/", 
          "photo": "http://0.gravatar.com/avatar/39cd1920cef70ffe79720226bb9921ce?s=40&d=mm&r=g", 
          "url_text": "Mu Lin", 
          "fn": "Mu Lin"
        }, 
        {
          "url": "http://www.iwebscraping.com/", 
          "photo": "http://2.gravatar.com/avatar/b365ca1c2795936cee55b536573c15e8?s=40&d=mm&r=g", 
          "url_text": "iwebscraping", 
          "nickname": "iwebscraping", 
          "fn": "iwebscraping"
        }, 
        {
          "url": "http://www.mulinblog.com/", 
          "photo": "http://0.gravatar.com/avatar/39cd1920cef70ffe79720226bb9921ce?s=40&d=mm&r=g", 
          "url_text": "Mu Lin", 
          "fn": "Mu Lin"
        }, 
        {
          "url": "https://plus.google.com/114001793083497812652", 
          "photo": "http://1.gravatar.com/avatar/d3335303466ad8b0b685dfdcdd477239?s=40&d=mm&r=g", 
          "url_text": "Jos P", 
          "fn": "Jos P"
        }
      ]
    }, 
    "snippet": "Oct 15, 2013 ... A 3-step guide on how to scrape tabular data on a webpage, ... in a report, and \nthe data reside on a third-party website, in the form of a table.", 
    "htmlSnippet": "Oct 15, 2013 <b>...</b> A 3-step guide on <b>how to scrape</b> tabular data on a webpage, ... in a report, and <br>\nthe data reside on a third-party <b>website</b>, in the form of a table.", 
    "link": "http://www.mulinblog.com/basic-web-scraping-data-visualization-using-google-spreadsheets/", 
    "cacheId": "qQr0CidoqJsJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "A Guide to Grow Your Blog (or Any Blog) 10X | OkDork.com", 
    "displayLink": "okdork.com", 
    "htmlTitle": "A Guide to Grow Your Blog (or Any Blog) 10X | OkDork.com", 
    "formattedUrl": "okdork.com/.../the-step-by-step-guide-to-10x-growth-for-any-blog/", 
    "htmlFormattedUrl": "okdork.com/.../the-step-by-step-guide-to-10x-growth-for-any-blog/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@noahkagan", 
          "og:url": "http://okdork.com/2014/04/30/the-step-by-step-guide-to-10x-growth-for-any-blog/", 
          "twitter:url": "www.okdork.com", 
          "twitter:domain": "okdork.com", 
          "og:site_name": "OkDork.com", 
          "twitter:image:src": "http://okdork.com/wp-content/themes/okdork-vdamo/img/noah-fp.png", 
          "twitter:card": "summary", 
          "twitter:description": "A few months ago I saw this goofy looking kid getting his articles ranked high on two of my favorite marketing sites Inbound.org and Growthhackers. His name was Nate Desmond and what he was writing about was extremely impressive. Funny enough on his site was a link to hire him, I did part-time. Since then he\u2019s been impressively helping the AppSumo team with our latest product, SumoMe.com. He showed me a few weeks ago how he can simply scrape any website to get insanely actionable data. I forced him to teach it to you below, enjoy!    Note: This is a guest post by Nate Desmond. Be sure to read to the end for a sweet bonus!     ------------------------------------------------------------------------------------------------------------------- Ever notice how some of your blog posts garner massive attention while others flop like a failed startup? The funny thing is, if you just make a few small changes, you can dramatically increase social sharing for your posts. With a few minor changes", 
          "og:type": "article", 
          "og:description": "A few months ago I saw this goofy looking kid getting his articles ranked high on two of my favorite marketing sites Inbound.org and Growthhackers. His name was Nate Desmond and what he was writing about was extremely impressive. Funny enough on his site was a link to hire him, I did part-time. Since then he\u2019s been impressively helping the AppSumo team with our latest product, SumoMe.com. He showed me a few weeks ago how he can simply scrape any website to get insanely actionable data. I forced him to teach it to you below, enjoy!    Note: This is a guest post by Nate Desmond. Be sure to read to the end for a sweet bonus!     ------------------------------------------------------------------------------------------------------------------- Ever notice how some of your blog posts garner massive attention while others flop like a failed startup? The funny thing is, if you just make a few small changes, you can dramatically increase social sharing for your posts. With a few minor changes", 
          "twitter:title": "Get access to 85% of my best business hacks", 
          "twitter:site": "@noahkagan", 
          "og:title": "A Guide to Grow Your Blog (or Any Blog) 10X | OkDork.com", 
          "article:modified_time": "2014-10-29T22:59:02Z", 
          "og:image": "http://okdork.com/wp-content/uploads/2014/07/OkDorkOG.png", 
          "article:published_time": "2014-04-30T20:37:11Z", 
          "viewport": "width=device-width"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "259", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSB9mzv_gZ41E5m5hLCWGaq77NaldIr6Afpg3hDiF1wYgnPEKfosZJRz5Vr", 
          "height": "195"
        }
      ], 
      "cse_image": [
        {
          "src": "http://okdork.com/wp-content/uploads/2014/07/OkDorkOG.png"
        }
      ]
    }, 
    "snippet": "Apr 30, 2014 ... He showed me a few weeks ago how he can simply scrape any website to get \ninsanely actionable data. I forced him to teach it to you below,\u00a0...", 
    "htmlSnippet": "Apr 30, 2014 <b>...</b> He showed me a few weeks ago how he can simply <b>scrape</b> any <b>website</b> to get <br>\ninsanely actionable data. I forced him to teach it to you below,&nbsp;...", 
    "link": "http://okdork.com/2014/04/30/the-step-by-step-guide-to-10x-growth-for-any-blog/", 
    "cacheId": "uNFUhWTNFIAJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "microsoft excel - How can I scrape specific data from a website ...", 
    "displayLink": "superuser.com", 
    "htmlTitle": "microsoft excel - How can I <b>scrape</b> specific data from a <b>website</b> <b>...</b>", 
    "formattedUrl": "superuser.com/.../how-can-i-scrape-specific-data-from-a-website", 
    "htmlFormattedUrl": "superuser.com/.../how-can-i-<b>scrape</b>-specific-data-from-a-<b>website</b>", 
    "pagemap": {
      "answer": [
        {
          "text": "You can use iMacros to automate this task. It is a tool to automate repetative tasks, it can be used to extract data from a site and save it as a CSV file. As x in example.com/x follows a pattern...", 
          "upvotecount": "2"
        }, 
        {
          "text": "You can paste this code in a module: Option Explicit Sub get_data() Dim result As String Dim myURL As String Dim winHttpReq As Object Set winHttpReq = CreateObject(\"WinHttp.WinHttpRequest.5.1\")...", 
          "upvotecount": "1"
        }
      ], 
      "qapage": [
        {
          "image": "http://cdn.sstatic.net/superuser/img/apple-touch-icon@2.png?v=e869e4459439&a", 
          "description": "I'm trying to scrape data from a website for research. The urls are nicely organized in an example.com/x format, with x as an ascending number and all of the pages are structured in the same way. ...", 
          "primaryimageofpage": "http://cdn.sstatic.net/superuser/img/apple-touch-icon@2.png?v=e869e4459439&a", 
          "name": "How can I scrape specific data from a website", 
          "title": "How can I scrape specific data from a website"
        }
      ], 
      "cse_image": [
        {
          "src": "http://cdn.sstatic.net/superuser/img/apple-touch-icon@2.png?v=e869e4459439&a"
        }
      ], 
      "metatags": [
        {
          "og:url": "http://superuser.com/questions/473303/how-can-i-scrape-specific-data-from-a-website", 
          "twitter:app:url:iphone": "se-zaphod://superuser.com/questions/473303/how-can-i-scrape-specific-data-from-a-website", 
          "twitter:app:url:ipad": "se-zaphod://superuser.com/questions/473303/how-can-i-scrape-specific-data-from-a-website", 
          "twitter:app:country": "US", 
          "twitter:domain": "superuser.com", 
          "twitter:description": "I'm trying to scrape data from a website for research.  The urls are nicely organized in an example.com/x format, with x as an ascending number and all of the pages are structured in the same way. ...", 
          "og:type": "website", 
          "twitter:app:name:iphone": "Stack Exchange iOS", 
          "twitter:app:name:ipad": "Stack Exchange iOS", 
          "twitter:title": "How can I scrape specific data from a website", 
          "twitter:app:id:ipad": "871299723", 
          "twitter:app:name:googleplay": "Stack Exchange Android", 
          "twitter:app:url:googleplay": "http://superuser.com/questions/473303/how-can-i-scrape-specific-data-from-a-website", 
          "twitter:card": "summary", 
          "twitter:site": "@super_user", 
          "twitter:app:id:googleplay": "com.stackexchange.marvin", 
          "og:image": "http://cdn.sstatic.net/superuser/img/apple-touch-icon@2.png?v=e869e4459439&a", 
          "twitter:app:id:iphone": "871299723"
        }
      ], 
      "question": [
        {
          "answercount": "2", 
          "text": "I'm trying to scrape data from a website for research. The urls are nicely organized in an example.com/x format, with x as an ascending number and all of the pages are structured in the same...", 
          "image": "http://cdn.sstatic.net/superuser/img/apple-touch-icon.png?v=0ad5b7a83e49", 
          "name": "How can I scrape specific data from a website", 
          "upvotecount": "2"
        }
      ]
    }, 
    "snippet": "Sep 12, 2012 ... I'm trying to scrape data from a website for research. The urls are nicely \norganized in an example.com/x format, with x as an ascending number\u00a0...", 
    "htmlSnippet": "Sep 12, 2012 <b>...</b> I&#39;m trying to <b>scrape</b> data from a <b>website</b> for research. The urls are nicely <br>\norganized in an example.com/x format, with x as an ascending number&nbsp;...", 
    "link": "http://superuser.com/questions/473303/how-can-i-scrape-specific-data-from-a-website", 
    "cacheId": "Htj5vzgMtPkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Data Scraping Guide for SEO & Analytics | Optimize Smart", 
    "displayLink": "www.optimizesmart.com", 
    "htmlTitle": "Data <b>Scraping</b> Guide for SEO &amp; Analytics | Optimize Smart", 
    "formattedUrl": "www.optimizesmart.com/data-scraping-guide-for-seo/", 
    "htmlFormattedUrl": "www.optimizesmart.com/data-<b>scraping</b>-guide-for-seo/", 
    "pagemap": {
      "metatags": [
        {
          "og:updated_time": "2015-04-18T14:51:47+00:00", 
          "og:url": "http://www.optimizesmart.com/data-scraping-guide-for-seo/", 
          "article:section": "Web Analytics Tools", 
          "og:type": "article", 
          "twitter:domain": "Optimize Smart", 
          "og:site_name": "Optimize Smart", 
          "twitter:image:src": "http://optimizesmart.com/wp-content/uploads/2011/10/serps-scraping.png", 
          "twitter:card": "summary", 
          "twitter:description": "Web scraping or web data scraping is a technique used to extract data from web documents like HTML and XML files. Data scraping can help you a lot in competitive analysis.", 
          "og:locale": "en_US", 
          "og:description": "Web scraping or web data scraping is a technique used to extract data from web documents like HTML and XML files. Data scraping can help you a lot in competitive analysis.", 
          "twitter:title": "Data Scraping guide for SEO & Analytics", 
          "og:image": "http://optimizesmart.com/wp-content/uploads/2011/10/serps-scraping.png", 
          "og:title": "Data Scraping guide for SEO & Analytics", 
          "fb:app_id": "1047458588599837", 
          "article:modified_time": "2015-04-18T14:51:47+00:00", 
          "article:published_time": "2011-10-07T18:39:35+00:00", 
          "twitter:creator": "@optimizesmart"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "259", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTzpUR6ieS9E3oYNDUF7bBALWNVNBNrEBPvIubd-8dLI0Nw5aktIOOH_V-J", 
          "height": "194"
        }
      ], 
      "cse_image": [
        {
          "src": "http://i.ytimg.com/vi/MwEQTnIJWis/hqdefault.jpg"
        }
      ]
    }, 
    "snippet": "Data scraping can help you a lot in competitive analysis as well as pulling out \ndata from your client's website like extracting the titles, keywords and content\u00a0...", 
    "htmlSnippet": "Data <b>scraping</b> can help you a lot in competitive analysis as well as pulling out <br>\ndata from your client&#39;s <b>website</b> like extracting the titles, keywords and content&nbsp;...", 
    "link": "http://www.optimizesmart.com/data-scraping-guide-for-seo/", 
    "cacheId": "jTpBA_MgXh0J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping websites into Drupal using Feeds and Import.io | Fourword ...", 
    "displayLink": "fourword.fourkitchens.com", 
    "htmlTitle": "<b>Scraping websites</b> into Drupal using Feeds and Import.io | Fourword <b>...</b>", 
    "formattedUrl": "fourword.fourkitchens.com/.../scraping-websites-drupal-using-feeds-and- importio", 
    "htmlFormattedUrl": "fourword.fourkitchens.com/.../<b>scraping</b>-<b>websites</b>-drupal-using-feeds-and- importio", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "initial-scale=1.0"
        }
      ], 
      "UserAccount": [
        {
          "name": "Jon Peck"
        }, 
        {
          "name": "Jon Peck"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "393", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTVMjVifOMgw6I0pLkb_KbU8wYKnFH-HxG7A2jRfSvigrS7TKslPZ2fSBw1", 
          "height": "128"
        }
      ], 
      "cse_image": [
        {
          "src": "http://fourword.fourkitchens.com/sites/default/files/styles/blog_lead/public/blog/lead-images/ImportCover.jpg?itok=zAv7VsJV"
        }
      ]
    }, 
    "snippet": "Scraping websites into Drupal using Feeds and Import.io. import.io data set. Jon \nPeck. November 14, 2014. Recently, I was faced with an interesting challenge;\u00a0...", 
    "htmlSnippet": "<b>Scraping websites</b> into Drupal using Feeds and Import.io. import.io data set. Jon <br>\nPeck. November 14, 2014. Recently, I was faced with an interesting challenge;&nbsp;...", 
    "link": "http://fourword.fourkitchens.com/article/scraping-websites-drupal-using-feeds-and-importio", 
    "cacheId": "y-QqMq-hUTUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "html - Can I scrape a website for font stylings? - Programmers Stack ...", 
    "displayLink": "programmers.stackexchange.com", 
    "htmlTitle": "html - Can I <b>scrape a website</b> for font stylings? - Programmers Stack <b>...</b>", 
    "formattedUrl": "programmers.stackexchange.com/.../can-i-scrape-a-website-for-font-stylings", 
    "htmlFormattedUrl": "programmers.stackexchange.com/.../can-i-<b>scrape-a-website</b>-for-font-stylings", 
    "pagemap": {
      "answer": [
        {
          "text": "That seems like a terribly difficult way of doing things due to the need to completely comprehend all the tricks that you can do in CSS. Detecting headings (<h1>, <h2>, etc.) would be much...", 
          "upvotecount": "2"
        }
      ], 
      "qapage": [
        {
          "image": "http://cdn.sstatic.net/programmers/img/apple-touch-icon@2.png?v=8a6d048f3c78", 
          "description": "I am trying to scrape websites for valuable text for example the title of an article, the author's name, and other distinguished text. I cannot always guarantee that this sort of text will have", 
          "primaryimageofpage": "http://cdn.sstatic.net/programmers/img/apple-touch-icon@2.png?v=8a6d048f3c78", 
          "name": "Can I scrape a website for font stylings?", 
          "title": "Can I scrape a website for font stylings?"
        }
      ], 
      "cse_image": [
        {
          "src": "http://cdn.sstatic.net/programmers/img/apple-touch-icon@2.png?v=8a6d048f3c78"
        }
      ], 
      "metatags": [
        {
          "og:url": "http://programmers.stackexchange.com/questions/237805/can-i-scrape-a-website-for-font-stylings", 
          "twitter:app:url:iphone": "se-zaphod://programmers.stackexchange.com/questions/237805/can-i-scrape-a-website-for-font-stylings", 
          "twitter:app:url:ipad": "se-zaphod://programmers.stackexchange.com/questions/237805/can-i-scrape-a-website-for-font-stylings", 
          "twitter:app:country": "US", 
          "twitter:domain": "programmers.stackexchange.com", 
          "twitter:description": "I am trying to scrape websites for valuable text for example the title of an article, the author's name, and other distinguished text. I cannot always guarantee that this sort of text will have", 
          "og:type": "website", 
          "twitter:app:name:iphone": "Stack Exchange iOS", 
          "twitter:app:name:ipad": "Stack Exchange iOS", 
          "twitter:title": "Can I scrape a website for font stylings?", 
          "twitter:app:id:ipad": "871299723", 
          "twitter:app:name:googleplay": "Stack Exchange Android", 
          "twitter:app:url:googleplay": "http://programmers.stackexchange.com/questions/237805/can-i-scrape-a-website-for-font-stylings", 
          "twitter:card": "summary", 
          "twitter:site": "@StackProgrammer", 
          "twitter:app:id:googleplay": "com.stackexchange.marvin", 
          "og:image": "http://cdn.sstatic.net/programmers/img/apple-touch-icon@2.png?v=8a6d048f3c78", 
          "twitter:app:id:iphone": "871299723"
        }
      ], 
      "question": [
        {
          "answercount": "1", 
          "text": "I am trying to scrape websites for valuable text for example the title of an article, the author's name, and other distinguished text. I cannot always guarantee that this sort of text will...", 
          "image": "http://cdn.sstatic.net/programmers/img/apple-touch-icon.png", 
          "name": "Can I scrape a website for font stylings?", 
          "upvotecount": "0"
        }
      ]
    }, 
    "snippet": "I am trying to scrape websites for valuable text for example the title of ... That \nseems like a terribly difficult way of doing things due to the need to\u00a0...", 
    "htmlSnippet": "I am trying to <b>scrape websites</b> for valuable text for example the title of ... That <br>\nseems like a terribly difficult way of doing things due to the need to&nbsp;...", 
    "link": "http://programmers.stackexchange.com/questions/237805/can-i-scrape-a-website-for-font-stylings", 
    "cacheId": "_6GezL_ucAMJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "A Guide to Web Scraping Tools - Gareth James", 
    "displayLink": "www.garethjames.net", 
    "htmlTitle": "A Guide to Web <b>Scraping</b> Tools - Gareth James", 
    "formattedUrl": "www.garethjames.net/a-guide-to-web-scrapping-tools/", 
    "htmlFormattedUrl": "www.garethjames.net/a-guide-to-web-scrapping-tools/", 
    "pagemap": {
      "blogposting": [
        {
          "headline": "A Guide to Web Scraping Tools", 
          "text": "Post Last Updated:Saturday, April 4, 2015 Web Scrapers are tools designed to extract / gather data in a website via crawling engine usually made in Java, Python, Ruby and other programming...", 
          "datepublished": "2014-12-05T18:08:40+00:00"
        }
      ], 
      "metatags": [
        {
          "og:url": "http://www.garethjames.net/a-guide-to-web-scrapping-tools/", 
          "revised": "Saturday, April 4, 2015, 8:04 am", 
          "og:site_name": "Gareth James", 
          "og:type": "article", 
          "og:description": "Blog post at Gareth James :  Web Scrapers are tools designed to extract / gather data in a website via crawling engine usually made in Java, Python, Ruby and other pro[..]", 
          "og:title": "A Guide to Web Scraping Tools", 
          "msvalidate.01": "C6140A265856591637E151BCB54362C1", 
          "viewport": "width=device-width, initial-scale=1"
        }
      ], 
      "wpheader": [
        {
          "headline": "Gareth James"
        }
      ], 
      "usercomments": [
        {
          "url": "February 4, 2015 at 10:44 am", 
          "commenttext": "Hi. Great article. Have you checked also this one: http://www.uipath.com/automate/web-scraping-software ?", 
          "commenttime": "2015-02-04T10:44:26+00:00"
        }, 
        {
          "url": "February 19, 2015 at 5:05 am", 
          "commenttext": "Thanks for including import.io in your list. Give us a shout if you want to flesh out our entry a little bit\u2026 you could include our tutorial videos, our enterprise service and loads of other...", 
          "commenttime": "2015-02-19T05:05:07+00:00"
        }, 
        {
          "url": "February 27, 2015 at 6:56 pm", 
          "commenttext": "Hey \u2013 would love to get your feedback on cloudscrape.com. We provide a SaaS web scraping tool the needs only a browser. Using our visual robot editor and cloud infrastructure to take all...", 
          "commenttime": "2015-02-27T18:56:44+00:00"
        }, 
        {
          "url": "February 28, 2015 at 10:07 am", 
          "commenttext": "You can try our software FMiner(http://www.fminer.com/), it\u2019s a web scraping software with a macro recorder.", 
          "commenttime": "2015-02-28T10:07:21+00:00"
        }, 
        {
          "url": "March 9, 2015 at 9:24 am", 
          "commenttext": "Selenium is one of the best tool to web scrape.", 
          "commenttime": "2015-03-09T09:24:39+00:00"
        }
      ], 
      "person": [
        {
          "url": "Gareth", 
          "name": "Gareth"
        }, 
        {
          "name": "Andrei"
        }, 
        {
          "url": "Daniel Cave", 
          "name": "Daniel Cave"
        }, 
        {
          "url": "Henrik Hofmeister", 
          "name": "Henrik Hofmeister"
        }, 
        {
          "url": "philip lee", 
          "name": "philip lee"
        }, 
        {
          "url": "Data Extraction", 
          "name": "Data Extraction"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "355", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT-yA7tYzpOiXT-muZO5NndFISeXnaRotHgTcoUiHUZ9dEdRpau-bSm5v4c", 
          "height": "142"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.garethjames.net/wp-content/uploads/2012/12/web-scrape-data-to-business-systems.jpg"
        }
      ]
    }, 
    "snippet": "Dec 5, 2014 ... Web Scrapers are tools designed to extract / gather data in a website via crawling \nengine usually made in Java, Python, Ruby and other\u00a0...", 
    "htmlSnippet": "Dec 5, 2014 <b>...</b> Web Scrapers are tools designed to extract / gather data in a <b>website</b> via crawling <br>\nengine usually made in Java, Python, Ruby and other&nbsp;...", 
    "link": "http://www.garethjames.net/a-guide-to-web-scrapping-tools/", 
    "cacheId": "OhiavyP4wnIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Ultimate guide for scraping JavaScript rendered web pages ...", 
    "displayLink": "impythonist.wordpress.com", 
    "htmlTitle": "Ultimate guide for <b>scraping</b> JavaScript rendered web pages <b>...</b>", 
    "formattedUrl": "https://impythonist.wordpress.com/.../ultimate-guide-for-scraping-javascript- rendered-web-pages/", 
    "htmlFormattedUrl": "https://impythonist.wordpress.com/.../ultimate-guide-for-<b>scraping</b>-javascript- rendered-web-pages/", 
    "pagemap": {
      "metatags": [
        {
          "application-name": "impythonist", 
          "twitter:image": "https://impythonist.files.wordpress.com/2015/01/pcweenies_1039.jpg?w=240", 
          "og:locale": "en_US", 
          "twitter:site": "@wordpressdotcom", 
          "fb:app_id": "249643311490", 
          "article:publisher": "https://www.facebook.com/WordPresscom", 
          "msapplication-task": "name=Subscribe;action-uri=https://impythonist.wordpress.com/feed/;icon-uri=https://secure.gravatar.com/blavatar/13d93d451c1d3daaf50239762916ae3a?s=16", 
          "p:domain_verify": "<!-- ZnOeWmsARyJHKdDsmyLKLOs_Vy0 -->", 
          "title": "Ultimate guide for scraping  JavaScript rendered web\u00a0pages | impythonist on WordPress.com", 
          "og:type": "article", 
          "msapplication-window": "width=device-width;height=device-height", 
          "article:modified_time": "2015-01-07T04:49:11+00:00", 
          "og:title": "Ultimate guide for scraping  JavaScript rendered web pages", 
          "og:url": "https://impythonist.wordpress.com/2015/01/06/ultimate-guide-for-scraping-javascript-rendered-web-pages/", 
          "msapplication-tooltip": "An Intelligent  twist of Python and Math", 
          "article:author": "https://impythonist.wordpress.com/author/narenarya2014/", 
          "msvalidate.01": "7D9D0E56E68D5915F0131211E5329F82", 
          "og:image": "https://impythonist.files.wordpress.com/2015/01/pcweenies_1039.jpg", 
          "article:published_time": "2015-01-06T17:55:43+00:00", 
          "viewport": "width=device-width, initial-scale=1", 
          "og:site_name": "impythonist", 
          "twitter:card": "summary", 
          "og:description": "We all scraped web pages.HTML content returned as response has our data and we scrape it for fetching certain results.If web page has JavaScript implementation, original data is obtained after rend..."
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "208", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcToQi0ROFbRyLsov5kEVa4EU62NbEYtu4jsb4JPHF_4fAhgdE_7cOGwBU8", 
          "height": "243"
        }
      ], 
      "cse_image": [
        {
          "src": "https://impythonist.files.wordpress.com/2015/01/pcweenies_1039.jpg"
        }
      ], 
      "hcard": [
        {
          "nickname": "Prathmesh", 
          "fn": "Prathmesh"
        }, 
        {
          "url": "https://impythonist.wordpress.com/", 
          "url_text": "Naren arya", 
          "fn": "Naren arya"
        }, 
        {
          "fn": "Alexei Martchenko"
        }
      ]
    }, 
    "snippet": "Jan 6, 2015 ... So I came with a power pack solution to scrape any JavaScript rendered website \nvery easily. Many of us use below libraries to perform scraping\u00a0...", 
    "htmlSnippet": "Jan 6, 2015 <b>...</b> So I came with a power pack solution to <b>scrape</b> any JavaScript rendered <b>website</b> <br>\nvery easily. Many of us use below libraries to perform <b>scraping</b>&nbsp;...", 
    "link": "https://impythonist.wordpress.com/2015/01/06/ultimate-guide-for-scraping-javascript-rendered-web-pages/", 
    "cacheId": "k_595FlroHsJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How legal is content scraping? | VentureBeat | Entrepreneur | by ...", 
    "displayLink": "venturebeat.com", 
    "htmlTitle": "How legal is content <b>scraping</b>? | VentureBeat | Entrepreneur | by <b>...</b>", 
    "formattedUrl": "venturebeat.com/2011/05/30/how-legal-is-content-scraping/", 
    "htmlFormattedUrl": "venturebeat.com/2011/05/30/how-legal-is-content-<b>scraping</b>/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://venturebeat.com/2011/05/30/how-legal-is-content-scraping/", 
          "og:site_name": "VentureBeat", 
          "og:type": "article", 
          "og:description": "(Editor\u2019s note: Curtis Smolar is a partner at Ropers Majeski Kohn & Bentley. He submitted this column to VentureBeat.)", 
          "og:title": "How legal is content\u00a0scraping?", 
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "240", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSeJEBILwYry4bEt5kYCrDoYQR-WHsSsOY9tNBCvp7RggeGm1Gr7VvUh28", 
          "height": "175"
        }
      ], 
      "cse_image": [
        {
          "src": "http://venturebeat.com/wp-content/uploads/2011/05/yell-at-computer-300x219.png"
        }
      ]
    }, 
    "snippet": "May 30, 2011 ... A reader asks: I have a business in which we scrape content from other websites \nto our website. Do we face any significant legal hurdles in\u00a0...", 
    "htmlSnippet": "May 30, 2011 <b>...</b> A reader asks: I have a business in which we <b>scrape</b> content from other <b>websites</b> <br>\nto our <b>website</b>. Do we face any significant legal hurdles in&nbsp;...", 
    "link": "http://venturebeat.com/2011/05/30/how-legal-is-content-scraping/", 
    "cacheId": "Q43jx_HzWAAJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scrape Website Email API Documentation", 
    "displayLink": "www.mashape.com", 
    "htmlTitle": "<b>Scrape Website</b> Email API Documentation", 
    "formattedUrl": "https://www.mashape.com/tommytcchan/scrape-website-email", 
    "htmlFormattedUrl": "https://www.mashape.com/tommytcchan/<b>scrape</b>-<b>website</b>-email", 
    "pagemap": {
      "metatags": [
        {
          "fb:admins": "576641408", 
          "twitter:image": "http://i.imgur.com/rIiCpxM.png", 
          "twitter:description": "Scrape Website Email API Documentation. Scrape emails from a website programmatically. We are an api that scrapes emails from websites.    What it does:    Scrapes a website for you - We go through the website and scrapes the main page and any sub pages for e-mails and returns those to you in json.    Parses common e-mail patterns - We parse e-mails such as tom[at]site.com or tom (at) site (dot) com. Let us handle it!    Easy API - Just provide a website address as input and you're all set!    Excellent Support - Let us know if you have issues. We'll be on call. We also have 24/7 monitor on our API    About the endpoint:  Please note that subsequent calls to the same url will be fetched from the cache (flushed weekly).     Please do note we cannot parse sites that require a login (for now), so for some Facebook pages it is not possible at the moment to fetch the e-mail.    Finally, please note that a scrape will be terminated after 5 minutes if data cannot be fetched at that time.    More Detailed Information", 
          "og:type": "website", 
          "og:description": "Scrape Website Email API Documentation. Scrape emails from a website programmatically. We are an api that scrapes emails from websites.What it does:    Scrapes...", 
          "twitter:title": "Scrape Website Email API Documentation", 
          "og:title": "Scrape Website Email API Documentation", 
          "twitter:card": "summary", 
          "twitter:site": "@mashape", 
          "og:image": "https://d1g84eaw0qjo7s.cloudfront.net/images/mashape-6a93cd64.png", 
          "twitter:account_id": "21079776", 
          "viewport": "width=device-width,initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "128", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRGtnof110WQXWDS0vLyM_S92UOh2QEXMNalMKfM9jfjwfORQ5giYp5xS8", 
          "height": "64"
        }
      ], 
      "cse_image": [
        {
          "src": "https://s3.amazonaws.com/mashape-production-logos/apis/53aa6137e4b0f2c975471867_medium"
        }
      ]
    }, 
    "snippet": "Scrape Website Email API Documentation. Scrape emails from a website \nprogrammatically. We are an api that scrapes emails from websites.What it does:\n\u00a0...", 
    "htmlSnippet": "<b>Scrape Website</b> Email API Documentation. Scrape emails from a website <br>\nprogrammatically. We are an api that scrapes emails from websites.What it does:<br>\n&nbsp;...", 
    "link": "https://www.mashape.com/tommytcchan/scrape-website-email", 
    "cacheId": "RciX4AES78YJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web scraping using Google Docs spreadsheet - Xpath - YouTube", 
    "displayLink": "www.youtube.com", 
    "htmlTitle": "Web <b>scraping</b> using Google Docs spreadsheet - Xpath - YouTube", 
    "formattedUrl": "https://www.youtube.com/user/testresearch099", 
    "htmlFormattedUrl": "https://www.youtube.com/user/testresearch099", 
    "pagemap": {
      "metatags": [
        {
          "twitter:app:name:googleplay": "YouTube", 
          "twitter:app:url:ipad": "vnd.youtube://user/UC7P92tZ4F_C2iBm8gI3um3g", 
          "twitter:image": "//s.ytimg.com/yts/img/avatar_720-vflYJnzBZ.png", 
          "al:web:url": "https://www.youtube.com/user/testresearch099?feature=applinks", 
          "fb:app_id": "87741124305", 
          "twitter:app:url:googleplay": "https://www.youtube.com/user/testresearch099", 
          "twitter:site": "@youtube", 
          "og:url": "https://www.youtube.com/user/testresearch099", 
          "twitter:app:url:iphone": "vnd.youtube://user/UC7P92tZ4F_C2iBm8gI3um3g", 
          "og:image": "//s.ytimg.com/yts/img/avatar_720-vflYJnzBZ.png", 
          "al:ios:app_store_id": "544007664", 
          "title": "Web scraping using Google Docs spreadsheet - Xpath", 
          "og:type": "profile", 
          "al:android:package": "com.google.android.youtube", 
          "og:title": "Web scraping using Google Docs spreadsheet - Xpath", 
          "twitter:title": "Web scraping using Google Docs spreadsheet - Xpath", 
          "al:ios:url": "vnd.youtube://user/UC7P92tZ4F_C2iBm8gI3um3g", 
          "twitter:app:name:iphone": "YouTube", 
          "twitter:app:name:ipad": "YouTube", 
          "twitter:app:id:ipad": "544007664", 
          "al:ios:app_name": "YouTube", 
          "al:android:app_name": "YouTube", 
          "twitter:app:id:googleplay": "com.google.android.youtube", 
          "twitter:url": "https://www.youtube.com/user/testresearch099", 
          "twitter:app:id:iphone": "544007664", 
          "og:site_name": "YouTube", 
          "twitter:card": "summary", 
          "og:video:tag": "web", 
          "al:android:url": "https://www.youtube.com/user/testresearch099?feature=applinks"
        }
      ], 
      "imageobject": [
        {
          "url": "https://s.ytimg.com/yts/img/avatar_720-vflYJnzBZ.png", 
          "width": "900", 
          "height": "900"
        }, 
        {
          "url": "https://s.ytimg.com/yts/img/avatar_720-vflYJnzBZ.png", 
          "width": "900", 
          "height": "900"
        }
      ], 
      "person": [
        {
          "url": "http://www.youtube.com/user/testresearch099"
        }, 
        {
          "url": "http://www.youtube.com/user/testresearch099"
        }
      ], 
      "youtubechannelv2": [
        {
          "name": "Web scraping using Google Docs spreadsheet - Xpath", 
          "url": "https://www.youtube.com/user/testresearch099", 
          "channelid": "UC7P92tZ4F_C2iBm8gI3um3g", 
          "isfamilyfriendly": "True", 
          "paid": "False", 
          "thumbnailurl": "https://s.ytimg.com/yts/img/avatar_720-vflYJnzBZ.png", 
          "regionsallowed": "AD,AE,AF,AG,AI,AL,AM,AO,AQ,AR,AS,AT,AU,AW,AX,AZ,BA,BB,BD,BE,BF,BG,BH,BI,BJ,BL,BM,BN,BO,BQ,BR,BS,BT,BV,BW,BY,BZ,CA,CC,CD,CF,CG,CH,CI,CK,CL,CM,CN,CO,CR,CU,CV,CW,CX,CY,CZ,DE,DJ,DK,DM,DO,DZ,EC,EE,EG,EH..."
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "256", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT_L8n-K3IMNMUeLUQiXmcJw82hz4Iw3ReVkkUMfkZmZzC-4mxnd50fV-Rc", 
          "height": "144"
        }
      ], 
      "cse_image": [
        {
          "src": "https://i.ytimg.com/vi/EXhmF9rjqP4/mqdefault.jpg"
        }
      ]
    }, 
    "snippet": "Scrape any website using xpath in Google Docs. Web scraping can be done \neasily through Google Documents Spreadsheets using simple xpath statements.", 
    "htmlSnippet": "<b>Scrape</b> any <b>website</b> using xpath in Google Docs. Web <b>scraping</b> can be done <br>\neasily through Google Documents Spreadsheets using simple xpath statements.", 
    "link": "https://www.youtube.com/user/testresearch099", 
    "cacheId": "Mr336bFCk24J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "fallanic/cheers \u00b7 GitHub", 
    "displayLink": "github.com", 
    "htmlTitle": "fallanic/cheers \u00b7 GitHub", 
    "formattedUrl": "https://github.com/fallanic/cheers", 
    "htmlFormattedUrl": "https://github.com/fallanic/cheers", 
    "pagemap": {
      "webpage": [
        {
          "keywords": "JavaScript", 
          "maincontentofpage": "Cheers Scrape a website efficiently, block by block, page by page. Motivations This is a Cheerio based scraper, useful to extract data from a website using CSS selectors. The motivation behind..."
        }
      ], 
      "metatags": [
        {
          "octolytics-dimension-repository_network_root_nwo": "fallanic/cheers", 
          "octolytics-host": "collector.githubapp.com", 
          "msapplication-tilecolor": "#ffffff", 
          "pjax-timeout": "1000", 
          "csrf-token": "9gmG5KZiV5eJK6EFTSTyHk6s+DTEohhIUSFNWuThnsNL8TtHdTpZBKCkGScJyhp0iLJdUQTz2deSyPVwE1O+Gw==", 
          "octolytics-app-id": "github", 
          "analytics-event": "Rails, view, files#disambiguate", 
          "fb:app_id": "1401488693436528", 
          "browser-stats-url": "https://api.github.com/_private/browser/stats", 
          "twitter:site": "@github", 
          "og:url": "https://github.com/fallanic/cheers", 
          "og:type": "object", 
          "octolytics-dimension-request_id": "42F9438F:741F:1BF992A:55412117", 
          "og:title": "fallanic/cheers", 
          "twitter:title": "fallanic/cheers", 
          "octolytics-dimension-repository_is_fork": "false", 
          "octolytics-script-host": "collector-cdn.github.com", 
          "browser-errors-url": "https://api.github.com/_private/browser/errors", 
          "octolytics-dimension-user_login": "fallanic", 
          "octolytics-dimension-user_id": "1240520", 
          "csrf-param": "authenticity_token", 
          "octolytics-dimension-repository_network_root_id": "23554011", 
          "msapplication-tileimage": "/windows-tile.png", 
          "is-dotcom": "true", 
          "og:image": "https://avatars0.githubusercontent.com/u/1240520?v=3&s=400", 
          "octolytics-dimension-repository_public": "true", 
          "dimension2": "Header v3", 
          "og:site_name": "GitHub", 
          "twitter:card": "summary", 
          "twitter:description": "cheers - Scrape a website efficiently, block by block, page by page. Based on cheerio and curl.", 
          "dimension1": "Logged Out", 
          "og:description": "cheers - Scrape a website efficiently, block by block, page by page. Based on cheerio and curl.", 
          "octolytics-dimension-repository_id": "23554011", 
          "twitter:image:src": "https://avatars0.githubusercontent.com/u/1240520?v=3&s=400", 
          "go-import": "github.com/fallanic/cheers git https://github.com/fallanic/cheers.git", 
          "google-analytics": "UA-3769691-2", 
          "octolytics-dimension-repository_nwo": "fallanic/cheers", 
          "hostname": "github.com"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "225", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcRQByYbwLuae7tzKWKxUU6WAIB3dgQcozR9-0iveWFIX8jtamziNauhc3Y", 
          "height": "225"
        }
      ], 
      "cse_image": [
        {
          "src": "https://avatars0.githubusercontent.com/u/1240520?v=3&s=400"
        }
      ], 
      "breadcrumb": [
        {
          "url": "fallanic", 
          "title": "fallanic"
        }
      ]
    }, 
    "snippet": "Oct 4, 2014 ... cheers - Scrape a website efficiently, block by block, page by page. Based on \ncheerio and curl.", 
    "htmlSnippet": "Oct 4, 2014 <b>...</b> cheers - <b>Scrape a website</b> efficiently, block by block, page by page. Based on <br>\ncheerio and curl.", 
    "link": "https://github.com/fallanic/cheers", 
    "cacheId": "7qDB4pMIGTUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Using node.js and jquery to scrape websites | animesh kumar", 
    "displayLink": "anismiles.wordpress.com", 
    "htmlTitle": "Using node.js and jquery to <b>scrape websites</b> | animesh kumar", 
    "formattedUrl": "https://anismiles.wordpress.com/.../node-js-and-jquery-to-scrape-websites/", 
    "htmlFormattedUrl": "https://anismiles.wordpress.com/.../node-js-and-jquery-to-<b>scrape</b>-<b>websites</b>/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "https://anismiles.wordpress.com/2010/11/29/node-js-and-jquery-to-scrape-websites/", 
          "og:locale": "en_US", 
          "og:title": "Using node.js and jquery to scrape websites", 
          "application-name": "animesh kumar", 
          "twitter:card": "summary", 
          "twitter:image": "https://secure.gravatar.com/blavatar/136f6461102698029b64dc2ebc6a7db4?s=240", 
          "og:type": "article", 
          "og:description": "I have been playing with Node.js for last few days and am totally head over heels. Madly in love! It\u2019s awesome to know how much you can build with how little. I have ranted about Node.js earlier an...", 
          "msapplication-tooltip": "Running water never grows stale. Keep flowing!", 
          "article:author": "https://anismiles.wordpress.com/author/smileanimeshblog/", 
          "fb:app_id": "249643311490", 
          "msapplication-window": "width=device-width;height=device-height", 
          "title": "Using node.js and jquery to scrape\u00a0websites | animesh kumar on WordPress.com", 
          "article:modified_time": "2010-11-29T10:18:04+00:00", 
          "twitter:site": "@wordpressdotcom", 
          "article:publisher": "https://www.facebook.com/WordPresscom", 
          "og:image": "https://secure.gravatar.com/blavatar/136f6461102698029b64dc2ebc6a7db4?s=200", 
          "article:published_time": "2010-11-29T10:17:13+00:00", 
          "msapplication-task": "name=Subscribe;action-uri=https://anismiles.wordpress.com/feed/;icon-uri=https://secure.gravatar.com/blavatar/f5168fecec17ed4fc3745bf5a0f69730?s=16", 
          "og:site_name": "animesh kumar"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "160", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSp2y6iakFGeIiKJumP0rFa7l9AE3TGfTLFCT2bnGHb5WGbHV5ISXSuur6z", 
          "height": "160"
        }
      ], 
      "cse_image": [
        {
          "src": "https://secure.gravatar.com/blavatar/136f6461102698029b64dc2ebc6a7db4?s=200"
        }
      ], 
      "hcard": [
        {
          "url": "http://js.darmowe-blogi.pisz.pl/bez-kategorii/using-node-js-and-jquery-to-scrape-websites-%C2%AB-coding-is-an-act-of.html", 
          "url_text": "Using node.js and jquery to scrape websites \u00ab Coding is an act of \u2026 \u2013 js - dowiedz si\u0119 wi\u0119cej!", 
          "fn": "Using node.js and jquery to scrape websites \u00ab Coding is an act of \u2026 \u2013 js - dowiedz si\u0119 wi\u0119cej!"
        }, 
        {
          "fn": "Jorge Ventura"
        }, 
        {
          "url": "http://karmshala.wordpress.com/", 
          "url_text": "Animesh", 
          "nickname": "Animesh", 
          "fn": "Animesh"
        }, 
        {
          "url": "http://aaroncruz.com/", 
          "url_text": "aaron", 
          "nickname": "aaron", 
          "fn": "aaron"
        }, 
        {
          "fn": "Jorge Ventura"
        }, 
        {
          "fn": "Jorge Ventura"
        }, 
        {
          "url": "http://www.robfaraj.com/", 
          "url_text": "Rob", 
          "nickname": "Rob", 
          "fn": "Rob"
        }, 
        {
          "url": "http://karmshala.wordpress.com/", 
          "url_text": "Animesh", 
          "nickname": "Animesh", 
          "fn": "Animesh"
        }, 
        {
          "url": "http://www.robfaraj.com/", 
          "url_text": "Rob", 
          "nickname": "Rob", 
          "fn": "Rob"
        }, 
        {
          "url": "http://karmshala.wordpress.com/", 
          "url_text": "Animesh", 
          "nickname": "Animesh", 
          "fn": "Animesh"
        }
      ]
    }, 
    "snippet": "Nov 29, 2010 ... I have been playing with Node.js for last few days and am totally head over heels. \nMadly in love! It's awesome to know how much you can build\u00a0...", 
    "htmlSnippet": "Nov 29, 2010 <b>...</b> I have been playing with Node.js for last few days and am totally head over heels. <br>\nMadly in love! It&#39;s awesome to know how much you can build&nbsp;...", 
    "link": "https://anismiles.wordpress.com/2010/11/29/node-js-and-jquery-to-scrape-websites/", 
    "cacheId": "qefeMZUmMOMJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Five easy steps for scraping data from web pages.", 
    "displayLink": "www.unt.edu", 
    "htmlTitle": "Five easy steps for <b>scraping</b> data from web pages.", 
    "formattedUrl": "www.unt.edu/rss/class/Jon/.../ScrapingData_L_JDS_Nov2013.pdf", 
    "htmlFormattedUrl": "www.unt.edu/rss/class/Jon/.../<b>Scraping</b>Data_L_JDS_Nov2013.pdf", 
    "pagemap": {
      "metatags": [
        {
          "creationdate": "D:20131105150815-06'00'", 
          "creator": "LaTeX with hyperref package", 
          "producer": "dvips + GPL Ghostscript 8.71", 
          "moddate": "D:20131105150815-06'00'"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "240", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSi7jbF1i5DXe1zsN9slERR7OrO1BYHca5dq8wGao_XSpYUFiIypA91CWU", 
          "height": "210"
        }
      ], 
      "cse_image": [
        {
          "src": "x-raw-image:///e3dd69f62b269781f6bb7ebd70c33fd10bf3d8d9a8a44c35451f7c313f4833c8"
        }
      ]
    }, 
    "fileFormat": "PDF/Adobe Acrobat", 
    "snippet": "Nov 5, 2013 ... The functions used to scrape data are fairly straightforward and ... average from \nthe Reuters Commodities (2013) website; specifically, the fol-.", 
    "htmlSnippet": "Nov 5, 2013 <b>...</b> The functions used to <b>scrape</b> data are fairly straightforward and ... average from <br>\nthe Reuters Commodities (2013) <b>website</b>; specifically, the fol-.", 
    "link": "http://www.unt.edu/rss/class/Jon/Benchmarks/ScrapingData_L_JDS_Nov2013.pdf", 
    "mime": "application/pdf", 
    "cacheId": "S6vev53MEU4J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Finding contact details from websites | ScraperWiki", 
    "displayLink": "blog.scraperwiki.com", 
    "htmlTitle": "Finding contact details from <b>websites</b> | ScraperWiki", 
    "formattedUrl": "https://blog.scraperwiki.com/.../finding-contact-details-from-websites/", 
    "htmlFormattedUrl": "https://blog.<b>scrape</b>rwiki.com/.../finding-contact-details-from-<b>websites</b>/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "240", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTnWuOOp4KYns_NNWNW2pIJrIhHb_GwJ5rWIKN_4M2knY_RgFwdukrkhmA", 
          "height": "205"
        }
      ], 
      "cse_image": [
        {
          "src": "https://blog.scraperwiki.com/wp-content/uploads/2013/11/UI-300x257.png"
        }
      ]
    }, 
    "snippet": "Nov 25, 2013 ... When I've visited company websites to get, for example, their email address or ... \nInstead of sitting there having to scrape websites by hand or\u00a0...", 
    "htmlSnippet": "Nov 25, 2013 <b>...</b> When I&#39;ve visited company websites to get, for example, their email address or ... <br>\nInstead of sitting there having to <b>scrape websites</b> by hand or&nbsp;...", 
    "link": "https://blog.scraperwiki.com/2013/11/finding-contact-details-from-websites/", 
    "cacheId": "6whmFOBUy3AJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping - web scraping, screen scraping, data parsing and ...", 
    "displayLink": "scraping.pro", 
    "htmlTitle": "Web <b>Scraping</b> - web <b>scraping</b>, screen <b>scraping</b>, data parsing and <b>...</b>", 
    "formattedUrl": "scraping.pro/", 
    "htmlFormattedUrl": "<b>scraping</b>.pro/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://scraping.pro", 
          "og:type": "website", 
          "twitter:domain": "Web Scraping", 
          "og:site_name": "Web Scraping", 
          "twitter:image:src": "http://scraping.pro/res/common/ewd256.png", 
          "twitter:card": "summary", 
          "twitter:description": "web scraping, screen scraping, data parsing and other related things", 
          "og:locale": "en_US", 
          "og:description": "Web scraping, data parsing and data intergation", 
          "twitter:site": "@ExtractWebData", 
          "og:title": "Web Scraping - web scraping, screen scraping, data parsing and other related things", 
          "twitter:title": "Web Scraping - web scraping, screen scraping, data parsing and other related things", 
          "og:image": "http://scraping.pro/res/common/ewd256.png", 
          "viewport": "width=device-width,minimum-scale=1,maximum-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "204", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcRMS49CORoqQLyUH3atqWylUbRoNtEl5Qw3yNW_HE5WZkRe_P1jVM3gJqIc", 
          "height": "204"
        }
      ], 
      "cse_image": [
        {
          "src": "http://scraping.pro/res/common/ewd256.png"
        }
      ]
    }, 
    "snippet": "Here we come to one new milestone: the JavaScript-driven web sites scrape. \nRecently a friend of mine got stumped as he was trying to get content of a website\n\u00a0...", 
    "htmlSnippet": "Here we come to one new milestone: the JavaScript-driven web sites <b>scrape</b>. <br>\nRecently a friend of mine got stumped as he was trying to get content of a <b>website</b><br>\n&nbsp;...", 
    "link": "http://scraping.pro/", 
    "cacheId": "py_i_qWZFqkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping websites with Outwit Hub: Step by step tutorial | DIRKMJK", 
    "displayLink": "dirkmjk.nl", 
    "htmlTitle": "<b>Scraping websites</b> with Outwit Hub: Step by step tutorial | DIRKMJK", 
    "formattedUrl": "dirkmjk.nl/2014/07/scraping-websites-outwit-hub-step-step-tutorial", 
    "htmlFormattedUrl": "dirkmjk.nl/2014/07/<b>scraping</b>-<b>websites</b>-outwit-hub-step-step-tutorial", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1, maximum-scale=5, minimum-scale=1, user-scalable=yes"
        }
      ], 
      "Item": [
        {
          "date": "2014-07-05T16:28:58+02:00", 
          "encoded": "Some websites offer data that you can download as an Excel or CSV file (e.g., Eurostat), or they may offer structured data in the form of an API. Other websites contain useful information,...", 
          "created": "2014-07-05T16:28:58+02:00", 
          "num_replies": "0", 
          "title": "Scraping websites with Outwit Hub: Step by step tutorial"
        }
      ]
    }, 
    "snippet": "Jul 5, 2014 ... Below I will provide some step by step examples of how you can use Outwit Hub \nto scrape websites and export the results as an Excel file.", 
    "htmlSnippet": "Jul 5, 2014 <b>...</b> Below I will provide some step by step examples of how you can use Outwit Hub <br>\nto <b>scrape websites</b> and export the results as an Excel file.", 
    "link": "http://dirkmjk.nl/2014/07/scraping-websites-outwit-hub-step-step-tutorial", 
    "cacheId": "-oKtNIt4W48J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Using Cheerio and MongoDB to scrape a large website", 
    "displayLink": "blog.ragingflame.co.za", 
    "htmlTitle": "Using Cheerio and MongoDB to <b>scrape</b> a large <b>website</b>", 
    "formattedUrl": "blog.ragingflame.co.za/.../using-cheerio-and-mongodb-to-scrape-a-large- website", 
    "htmlFormattedUrl": "blog.ragingflame.co.za/.../using-cheerio-and-mongodb-to-<b>scrape</b>-a-large- <b>website</b>", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1, maximum-scale=1"
        }
      ]
    }, 
    "snippet": "Jun 27, 2014 ... Disclaimer: Scraping has a moral grey area, as much as the information on a \nwebsite is publicly available, I don't think that mass cloning the\u00a0...", 
    "htmlSnippet": "Jun 27, 2014 <b>...</b> Disclaimer: <b>Scraping</b> has a moral grey area, as much as the information on a <br>\n<b>website</b> is publicly available, I don&#39;t think that mass cloning the&nbsp;...", 
    "link": "http://blog.ragingflame.co.za/2014/6/27/using-cheerio-and-mongodb-to-scrape-a-large-website", 
    "cacheId": "hOPsg2pjPDkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Using Firefox for scraping \u2014 Scrapy 0.24.6 documentation", 
    "displayLink": "doc.scrapy.org", 
    "htmlTitle": "Using Firefox for <b>scraping</b> \u2014 Scrapy 0.24.6 documentation", 
    "formattedUrl": "doc.scrapy.org/en/latest/topics/firefox.html", 
    "htmlFormattedUrl": "doc.scrapy.org/en/latest/topics/firefox.html", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ]
    }, 
    "snippet": "Using Firefox for scraping\u00b6. Here is a list of tips and advice on using Firefox for \nscraping, along with a list of useful Firefox add-ons to ease the scraping process.", 
    "htmlSnippet": "Using Firefox for <b>scraping</b>\u00b6. Here is a list of tips and advice on using Firefox for <br>\n<b>scraping</b>, along with a list of useful Firefox add-ons to ease the <b>scraping</b> process.", 
    "link": "http://doc.scrapy.org/en/latest/topics/firefox.html", 
    "cacheId": "8sYGFtlfWEgJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How To Use node.js, request and cheerio to Set Up Simple Web ...", 
    "displayLink": "www.digitalocean.com", 
    "htmlTitle": "How To Use node.js, request and cheerio to Set Up Simple Web <b>...</b>", 
    "formattedUrl": "https://www.digitalocean.com/.../how-to-use-node-js-request-and-cheerio-to- set-up-simple-web-scraping", 
    "htmlFormattedUrl": "https://www.digitalocean.com/.../how-to-use-node-js-request-and-cheerio-to- set-up-simple-web-<b>scraping</b>", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "DigitalOcean", 
          "twitter:url": "https://www.digitalocean.com/community/tutorials/how-to-use-node-js-request-and-cheerio-to-set-up-simple-web-scraping", 
          "og:site_name": "DigitalOcean", 
          "twitter:card": "photo", 
          "csrf-token": "H4HrdcBVsiz1bNH8QWhal/CUocChnqtKzSORBmJvSes=", 
          "twitter:image": "https://www.digitalocean.com/assets/community/tags/node-js-5d5032180bd14d76ee723d33d5aa0317.png", 
          "twitter:description": "Here's how to use node.js, request and cheerio to setup simple web-scraping.", 
          "og:type": "article", 
          "og:description": "Here's how to use node.js, request and cheerio to setup simple web-scraping.", 
          "csrf-param": "authenticity_token", 
          "twitter:title": "How To Use node.js, request and cheerio to Set Up Simple Web-Scraping | DigitalOcean", 
          "og:title": "How To Use node.js, request and cheerio to Set Up Simple Web-Scraping | DigitalOcean", 
          "twitter:site": "DigitalOcean", 
          "og:image": "https://www.digitalocean.com/assets/community/tags/node-js-5d5032180bd14d76ee723d33d5aa0317.png", 
          "viewport": "initial-scale=1, maximum-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "74", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcRV4GiXiAXph2qG6eI0XAkS5Tf2yDRashi8DKKbuIWoQGYhyk8Kpw0inQ", 
          "height": "74"
        }
      ], 
      "cse_image": [
        {
          "src": "https://www.digitalocean.com/assets/community/tags/node-js-5d5032180bd14d76ee723d33d5aa0317.png"
        }
      ]
    }, 
    "snippet": "Sep 16, 2013 ... In this tutorial, we will scrape the front page of Hacker News to get all the top ..... If \nyou want to scrape a website, check it's TOS (or you can even\u00a0...", 
    "htmlSnippet": "Sep 16, 2013 <b>...</b> In this tutorial, we will scrape the front page of Hacker News to get all the top ..... If <br>\nyou want to <b>scrape a website</b>, check it&#39;s TOS (or you can even&nbsp;...", 
    "link": "https://www.digitalocean.com/community/tutorials/how-to-use-node-js-request-and-cheerio-to-set-up-simple-web-scraping", 
    "cacheId": "CiWWXMJu3MIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "GivenTheData: R and the web (for beginners), Part III: Scraping MPs ...", 
    "displayLink": "giventhedata.blogspot.com", 
    "htmlTitle": "GivenTheData: R and the web (for beginners), Part III: <b>Scraping</b> MPs <b>...</b>", 
    "formattedUrl": "giventhedata.blogspot.com/.../r-and-web-for-beginners-part-iii.html", 
    "htmlFormattedUrl": "giventhedata.blogspot.com/.../r-and-web-for-beginners-part-iii.html", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=1100"
        }
      ], 
      "person": [
        {
          "url": "http://www.blogger.com/profile/07454210300858598312", 
          "name": "GivenTheData"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "248", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS98cBEkaCb3DrXjiDR3Z6uWMltu4hNH1uCMHRbBafjP6qC_PB0CwGeY68", 
          "height": "203"
        }
      ], 
      "cse_image": [
        {
          "src": "http://2.bp.blogspot.com/-b32dDh_D4gg/UDcsY7aboWI/AAAAAAAAADQ/mROoanK-pdY/s400/plot_post3.jpeg"
        }
      ], 
      "blogposting": [
        {
          "articlebody": "In this last post of my little series (see my latest post) on R and the web I explain how to extract data of a website (web scraping/screen scraping) with R. If the data you want to analyze...", 
          "description": "In this last post of my little series (see my latest post) on R and the web I explain how to extract data of a website (web scraping/screen scraping) with R. If the data you want to analyze...", 
          "url": "http://giventhedata.blogspot.com/2012/08/r-and-web-for-beginners-part-iii.html", 
          "datepublished": "7:31 PM", 
          "image_url": "http://2.bp.blogspot.com/-b32dDh_D4gg/UDcsY7aboWI/AAAAAAAAADQ/mROoanK-pdY/s400/plot_post3.jpeg", 
          "postid": "4026930564728361424", 
          "blogid": "6826920449905386749", 
          "name": "R and the web (for beginners), Part III: Scraping MPs' expenses in detail from the web"
        }
      ]
    }, 
    "snippet": "Aug 23, 2012 ... In this last post of my little series (see my latest post) on R and the web I explain \nhow to extract data of a website (web scraping/screen\u00a0...", 
    "htmlSnippet": "Aug 23, 2012 <b>...</b> In this last post of my little series (see my latest post) on R and the web I explain <br>\nhow to extract data of a <b>website</b> (web <b>scraping</b>/screen&nbsp;...", 
    "link": "http://giventhedata.blogspot.com/2012/08/r-and-web-for-beginners-part-iii.html", 
    "cacheId": "vpA1dQ_jMQkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "How To Scrape The Web Using Google Docs - Annielytics.com", 
    "displayLink": "www.annielytics.com", 
    "htmlTitle": "<b>How To Scrape</b> The Web Using Google Docs - Annielytics.com", 
    "formattedUrl": "www.annielytics.com/.../how-to-scrape-the-web-using-google-docs/", 
    "htmlFormattedUrl": "www.annielytics.com/.../<b>how-to-scrape</b>-the-web-using-google-docs/", 
    "pagemap": {
      "blogposting": [
        {
          "headline": "How To Scrape The Web Using Google Docs", 
          "text": "Web scraping is like picking strawberries. (Okay, fine \u2013 not really, but they were really cute.) Ever looked at a delicious list on a website and copied and pasted it, bit by bit, into an...", 
          "datepublished": "2012-11-17T03:48:00+00:00"
        }
      ], 
      "metatags": [
        {
          "og:updated_time": "2014-09-03T18:41:47+00:00", 
          "og:url": "http://www.annielytics.com/blog/google-docs/how-to-scrape-the-web-using-google-docs/", 
          "article:section": "Google Docs", 
          "og:type": "article", 
          "twitter:domain": "Annielytics.com", 
          "og:site_name": "Annielytics.com", 
          "twitter:image:src": "http://annielytics.com/wp-content/uploads/2012/11/cherry-pick-with-web-scraping.jpg", 
          "twitter:card": "summary_large_image", 
          "og:locale": "en_US", 
          "og:description": "Learn how to easily scrape the Web using the ImportFeed, ImportHTML, and ImportXML functions in Google Docs.", 
          "og:image": "http://annielytics.com/wp-content/uploads/2012/11/cherry-pick-with-web-scraping.jpg", 
          "og:title": "How To Scrape The Web Using Google Docs - Annielytics.com", 
          "article:modified_time": "2014-09-03T18:41:47+00:00", 
          "twitter:creator": "@anniecushing", 
          "article:tag": "Presentations", 
          "article:published_time": "2012-11-17T03:48:00+00:00", 
          "twitter:site": "@anniecushing", 
          "viewport": "width=device-width, initial-scale=1"
        }
      ], 
      "wpheader": [
        {
          "headline": "Annielytics.com", 
          "description": "I make data sexy"
        }
      ], 
      "usercomments": [
        {
          "url": "August 13, 2013 at 10:22 am", 
          "commenttext": "Hi Annie, Have you tried to import Google\u2019s \u201cAbout 5,000 results\u201d # (just below search). Any idea how to go about doing that?", 
          "commenttime": "2013-08-13T10:22:00+00:00"
        }, 
        {
          "url": "August 13, 2013 at 8:03 pm", 
          "commenttext": "I\u2019d use Scrapebox and some very good proxies.", 
          "commenttime": "2013-08-13T20:03:00+00:00"
        }, 
        {
          "url": "August 29, 2013 at 2:57 pm", 
          "commenttext": "Awesome!", 
          "commenttime": "2013-08-29T14:57:00+00:00"
        }, 
        {
          "url": "April 30, 2014 at 7:57 am", 
          "commenttext": "Hi Annie, Slide 43, bullet point 5 says you\u2019ve used it to pull GA metrics \u2013 I\u2019ve been trying to get some Google analytics data into a spreadsheet but the ImportXML function does not work....", 
          "commenttime": "2014-04-30T07:57:00+00:00"
        }, 
        {
          "url": "May 6, 2014 at 8:27 am", 
          "commenttext": "You can\u2019t scrape GA metrics; you need to use the API for that. I wrote a post on how to use a free tool: http://searchengineland.com/how-to-use-the-google-analytics-api-in-plain-english-and-a-fre...", 
          "commenttime": "2014-05-06T08:27:00+00:00"
        }, 
        {
          "url": "June 2, 2014 at 6:53 am", 
          "commenttext": "thanks", 
          "commenttime": "2014-06-02T06:53:00+00:00"
        }, 
        {
          "url": "September 29, 2014 at 12:02 pm", 
          "commenttext": "hello annie! i would like to view the google doc but it doesn\u2019t seem to be shared publicly? it says i need to request permission just after clicking the link to view it. thanks heaps! you...", 
          "commenttime": "2014-09-29T12:02:14+00:00"
        }, 
        {
          "url": "October 2, 2014 at 4:23 pm", 
          "commenttext": "Are you seeing it now? I lost all of my Google Docs when Google Sheets updated. But I think they\u2019re all fixed now.", 
          "commenttime": "2014-10-02T16:23:11+00:00"
        }, 
        {
          "url": "January 16, 2015 at 4:13 pm", 
          "commenttext": "CONTINUE function doesn\u2019t work anymore\u2026any suggestions?", 
          "commenttime": "2015-01-16T16:13:34+00:00"
        }
      ], 
      "person": [
        {
          "url": "Annie", 
          "name": "Annie"
        }, 
        {
          "name": "Brad_Zomick"
        }, 
        {
          "url": "Annie Cushing", 
          "name": "Annie Cushing"
        }, 
        {
          "url": "Mina Younan", 
          "name": "Mina Younan"
        }, 
        {
          "name": "Yordan"
        }, 
        {
          "url": "Annie Cushing", 
          "name": "Annie Cushing"
        }, 
        {
          "url": "Moud Nuri", 
          "name": "Moud Nuri"
        }, 
        {
          "name": "Grace"
        }, 
        {
          "name": "Annie Cushing"
        }, 
        {
          "name": "ALex"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "301", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRXqCgxa8vn4CKPXrTk1Ixu54WvWHDGYolBzMhyvK-ZLnBCZUCDW3Bqj3g", 
          "height": "168"
        }
      ], 
      "cse_image": [
        {
          "src": "http://annielytics.com/wp-content/uploads/2012/11/cherry-pick-with-web-scraping.jpg"
        }
      ]
    }, 
    "snippet": "Nov 17, 2012 ... Learn how to easily scrape the Web using the ImportFeed, ... Ever looked at a \ndelicious list on a website and copied and pasted it, bit by bit, into\u00a0...", 
    "htmlSnippet": "Nov 17, 2012 <b>...</b> Learn how to easily <b>scrape</b> the Web using the ImportFeed, ... Ever looked at a <br>\ndelicious list on a <b>website</b> and copied and pasted it, bit by bit, into&nbsp;...", 
    "link": "http://www.annielytics.com/blog/google-docs/how-to-scrape-the-web-using-google-docs/", 
    "cacheId": "sXM2Dd9bhhQJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping, Data Extraction, Data Scraping and Text Parsing ...", 
    "displayLink": "webdata-scraping.com", 
    "htmlTitle": "Web <b>Scraping</b>, Data Extraction, Data <b>Scraping</b> and Text Parsing <b>...</b>", 
    "formattedUrl": "webdata-scraping.com/", 
    "htmlFormattedUrl": "webdata-<b>scraping</b>.com/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://webdata-scraping.com/", 
          "og:type": "article", 
          "og:site_name": "WebData Scraping", 
          "og:locale": "en_US", 
          "og:description": "We provide risk free Web Scraping service, text parsing, data extraction services. You can submit your website scraping requirements to get free sample scrape.", 
          "og:title": "Web Scraping, Data Extraction, Data Scraping and Text Parsing Service", 
          "og:image": "http://webdata-scraping.com/wp-content/uploads/2013/11/web-scraping-services.png", 
          "viewport": "width=device-width"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "385", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcSIZniu9o2-LRrwCojPR_cKoU_ocKOpQf13K2ZRAtHIQPA4p3jIOFRAsAc", 
          "height": "131"
        }
      ], 
      "cse_image": [
        {
          "src": "http://webdata-scraping.com/wp-content/uploads/2013/11/web-scraping-services.png"
        }
      ]
    }, 
    "snippet": "We provide risk free Web Scraping service, text parsing, data extraction services. \nYou can submit your website scraping requirements to get free sample scrape.", 
    "htmlSnippet": "We provide risk free Web <b>Scraping</b> service, text parsing, data extraction services. <br>\nYou can submit your <b>website scraping</b> requirements to get free sample <b>scrape</b>.", 
    "link": "http://webdata-scraping.com/", 
    "cacheId": "djOUZNeHUOMJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Data scraping tool for non-coding journalists launches | Media news", 
    "displayLink": "www.journalism.co.uk", 
    "htmlTitle": "Data <b>scraping</b> tool for non-coding journalists launches | Media news", 
    "formattedUrl": "https://www.journalism.co.uk/news/data-scraping-tool.../a554002/", 
    "htmlFormattedUrl": "https://www.journalism.co.uk/news/data-<b>scraping</b>-tool.../a554002/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "https://www.journalism.co.uk/news/data-scraping-tool-for-non-coding-journalists-launches/s2/a554002/", 
          "article:section": "Media news", 
          "article:tag": "data journalism", 
          "og:title": "Data scraping tool for non-coding journalists launches", 
          "twitter:card": "summary", 
          "og:type": "article", 
          "og:description": "Import.io lets you scrape data from any website and create a single searchable database containing information from several different sources", 
          "fb:app_id": "237383240541", 
          "article:modified_time": "2013-09-09T09:55:35+01:00", 
          "twitter:site": "@journalismnews", 
          "article:publisher": "https://www.facebook.com/Journalismnews", 
          "og:image": "//www.journalism.co.uk/agile_assets/132/spreadsheet.jpg", 
          "article:published_time": "2013-09-09T09:31:00+01:00"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "288", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcRz_mIq4HWRxOU7Z4FCRNsFDbtk79sbE-0FU-aHt5TNkz5EAXrEP7Kpq4o", 
          "height": "175"
        }
      ], 
      "cse_image": [
        {
          "src": "https://www.journalism.co.uk/agile_assets/132/spreadsheet.jpg_resized_460_.jpeg"
        }
      ]
    }, 
    "snippet": "Sep 9, 2013 ... Import.io lets you scrape data from any website and create a single searchable \ndatabase containing information from several different sources.", 
    "htmlSnippet": "Sep 9, 2013 <b>...</b> Import.io lets you <b>scrape</b> data from any <b>website</b> and create a single searchable <br>\ndatabase containing information from several different sources.", 
    "link": "https://www.journalism.co.uk/news/data-scraping-tool-for-non-coding-journalists-launches/s2/a554002/", 
    "cacheId": "zdpqmKayJBAJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Using PHP and cURL to Scrape Web Pages | Syntaxxx", 
    "displayLink": "www.syntaxxx.com", 
    "htmlTitle": "Using PHP and cURL to <b>Scrape</b> Web Pages | Syntaxxx", 
    "formattedUrl": "www.syntaxxx.com/using-php-and-curl-to-scrape-web-pages/", 
    "htmlFormattedUrl": "www.syntaxxx.com/using-php-and-curl-to-<b>scrape</b>-web-pages/", 
    "pagemap": {
      "metatags": [
        {
          "og:image": "/wp-content/uploads/2014/04/using-php-and-curl-to-scrape-web-pages.jpg", 
          "viewport": "width=device-width,initial-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "225", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT6XUgwq_z2IfJ8qoy0KlUF43FDXLh7df35dAKMZAWDH20TG4SZ-Phao3Q", 
          "height": "225"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.syntaxxx.com/wp-content/uploads/2014/04/using-php-and-curl-to-scrape-web-pages.jpg"
        }
      ], 
      "hcard": [
        {
          "fn": "P G"
        }, 
        {
          "nickname": "Mika", 
          "fn": "Mika"
        }, 
        {
          "nickname": "gagan", 
          "fn": "gagan"
        }, 
        {
          "nickname": "Tim", 
          "fn": "Tim"
        }, 
        {
          "nickname": "Denise", 
          "fn": "Denise"
        }, 
        {
          "nickname": "Bo", 
          "fn": "Bo"
        }, 
        {
          "nickname": "Nasib", 
          "fn": "Nasib"
        }, 
        {
          "nickname": "Ray", 
          "fn": "Ray"
        }
      ]
    }, 
    "snippet": "Apr 14, 2014 ... Today, we're going to use cURL and PHP to scrape a website for data, \nspecifically the list of most often downloaded ebooks at Project\u00a0...", 
    "htmlSnippet": "Apr 14, 2014 <b>...</b> Today, we&#39;re going to use cURL and PHP to <b>scrape a website</b> for data, <br>\nspecifically the list of most often downloaded ebooks at Project&nbsp;...", 
    "link": "http://www.syntaxxx.com/using-php-and-curl-to-scrape-web-pages/", 
    "cacheId": "D2AJQ8mhNMoJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping Tools for Non-developers - marcua's blog", 
    "displayLink": "blog.marcua.net", 
    "htmlTitle": "Web <b>Scraping</b> Tools for Non-developers - marcua&#39;s blog", 
    "formattedUrl": "blog.marcua.net/post/74655674340", 
    "htmlFormattedUrl": "blog.marcua.net/post/74655674340", 
    "pagemap": {
      "metatags": [
        {
          "twitter:app:name:googleplay": "Tumblr", 
          "twitter:site": "tumblr", 
          "twitter:app:url:ipad": "tumblr://x-callback-url/blog?blogName=marcua&postID=74655674340&referrer=twitter-cards", 
          "twitter:app:url:googleplay": "tumblr://x-callback-url/blog?blogName=marcua&postID=74655674340&referrer=twitter-cards", 
          "color:chat name": "#333000", 
          "al:android:app_name": "Tumblr", 
          "og:determiner": "a", 
          "fb:app_id": "48119224995", 
          "color:post footer text": "#333000", 
          "color:titles": "#333000", 
          "og:url": "http://blog.marcua.net/post/74655674340", 
          "twitter:app:url:iphone": "tumblr://x-callback-url/blog?blogName=marcua&postID=74655674340&referrer=twitter-cards", 
          "twitter:url": "http://blog.marcua.net/post/74655674340", 
          "al:ios:app_store_id": "305343404", 
          "color:background": "#FFFFFF", 
          "og:type": "tumblr-feed:entry", 
          "al:android:package": "com.tumblr", 
          "color:borders": "#BABABA", 
          "og:title": "Web Scraping Tools for Non-developers", 
          "twitter:title": "Web Scraping Tools for Non-developers", 
          "twitter:app:id:iphone": "305343404", 
          "al:ios:url": "tumblr://x-callback-url/blog?blogName=marcua&postID=74655674340", 
          "twitter:app:name:iphone": "Tumblr", 
          "twitter:app:name:ipad": "Tumblr", 
          "twitter:app:id:ipad": "305343404", 
          "color:link hover": "#FFCC00", 
          "al:ios:app_name": "Tumblr", 
          "color:footer background": "#FFFFFF", 
          "twitter:app:id:googleplay": "com.tumblr", 
          "og:image": "http://assets.tumblr.com/images/og/text_200.png", 
          "color:footer links": "#333000", 
          "twitter:card": "summary", 
          "twitter:description": "I recently spoke with a resource-limited organization that is investigating government corruption and wants to access various public datasets to monitor politicians and law firms. They don&rsquo;t have developers in-house, but feel pretty comfortable analyzing datasets in CSV form. While many public datasources are available in structured form, some sources are hidden in what us data folks call the deep web.  Amazon is a nice example of a deep website, where you have to enter text into a search box, click on a few buttons to narrow down your results, and finally access relatively structured data (prices, model numbers, etc.) embedded in HTML.  Amazon has a structured database of their products somewhere, but all you get to see is a bunch of webpages trapped behind some forms.   A developer usually isn&rsquo;t hindered by the deep web.  If we want the data on a webpage, we can automate form submissions and key presses, and we can parse some ugly HTML before emitting reasonably structured CSVs or JSON. But what", 
          "og:description": "I recently spoke with a resource-limited organization that is investigating government corruption and wants to access various public datasets to monitor politicians and law firms. They don\u2019t have...", 
          "color:body text": "#333000", 
          "color:links": "#333000", 
          "color:footer border": "#333000", 
          "al:android:url": "tumblr://x-callback-url/blog?blogName=marcua&postID=74655674340", 
          "color:date": "#333000", 
          "color:quotes": "#333000"
        }
      ], 
      "cse_image": [
        {
          "src": "http://assets.tumblr.com/images/og/text_200.png"
        }
      ]
    }, 
    "snippet": "Jan 26, 2014 ... Amazon is a nice example of a deep website, where you have to enter text into a \n... Because the source I wanted to scrape required filling out a\u00a0...", 
    "htmlSnippet": "Jan 26, 2014 <b>...</b> Amazon is a nice example of a deep <b>website</b>, where you have to enter text into a <br>\n... Because the source I wanted to <b>scrape</b> required filling out a&nbsp;...", 
    "link": "http://blog.marcua.net/post/74655674340", 
    "cacheId": "8dFaRCS1aA8J"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "WebSite Scraping - CodeProject", 
    "displayLink": "www.codeproject.com", 
    "htmlTitle": "<b>WebSite Scraping</b> - CodeProject", 
    "formattedUrl": "www.codeproject.com/.../Scraping-Dynamic-WebSite-data-using-Watin", 
    "htmlFormattedUrl": "www.codeproject.com/.../<b>Scraping</b>-Dynamic-<b>WebSite</b>-data-using-Watin", 
    "pagemap": {
      "aggregaterating": [
        {
          "ratingvalue": "4.95", 
          "ratingcount": "14", 
          "worstrating": "1", 
          "bestrating": "5"
        }
      ], 
      "metatags": [
        {
          "rating": "General", 
          "viewport": "width=device-width, initial-scale=1.0", 
          "google-translate-customization": "d908bb7ce7aff658-4c2f3a504525c916-g629383f736781a8a-13", 
          "application-name": "CodeProject", 
          "author": "shah vatsal"
        }
      ], 
      "person": [
        {
          "name": "shah vatsal"
        }
      ], 
      "article": [
        {
          "articlebody": "Download source code - 440.4 KB Download demo - 223.1 KB Introduction The main objective of this article is to demonstrate scraping of web pages using Testing tools like Watin testing tool....", 
          "name": "WebSite Scraping", 
          "url": "Permalink", 
          "datepublished": "2013-03-28", 
          "articlesection": "Applications & Tools", 
          "datemodified": "2013-06-02 03:28:00"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "284", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQF_JrhxTykJvnVA_bEX5gQNdg2E2AuRd6QHIkFuNxh5dNSdXAeUN4-FL-c", 
          "height": "177"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.codeproject.com/KB/applications/568502/WebScraping_Watin_small.png"
        }
      ], 
      "hreviewaggregate": [
        {
          "votes": "14"
        }
      ]
    }, 
    "snippet": "Mar 28, 2013 ... Website scraping using Watin; Author: shah vatsal; Updated: 2 Jun 2013; Section\n: Applications & Tools; Chapter: Web Development; Updated:\u00a0...", 
    "htmlSnippet": "Mar 28, 2013 <b>...</b> <b>Website scraping</b> using Watin; Author: shah vatsal; Updated: 2 Jun 2013; Section<br>\n: Applications &amp; Tools; Chapter: Web Development; Updated:&nbsp;...", 
    "link": "http://www.codeproject.com/Articles/568502/Scraping-Dynamic-WebSite-data-using-Watin", 
    "cacheId": "JGIIUrWraKoJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Website to Visuals \u2013 Scraping Website int... | SCN", 
    "displayLink": "scn.sap.com", 
    "htmlTitle": "Website to Visuals \u2013 <b>Scraping Website</b> int... | SCN", 
    "formattedUrl": "scn.sap.com/.../website-to-visuals-scraping-website-into-data-within-sap- lumira", 
    "htmlFormattedUrl": "scn.sap.com/.../<b>website</b>-to-visuals-<b>scraping</b>-<b>website</b>-into-data-within-sap- lumira", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://scn.sap.com/community/lumira/blog/2015/03/12/website-to-visuals-scraping-website-into-data-within-sap-lumira", 
          "ga_space": "2487", 
          "ga_pagetype": "Blogpost-Detail", 
          "og:type": "website", 
          "og:description": "Digital business demands dictate an ever increasing need for the extraction of information and useful deductions from live/ real time data on the web. Be it manufacturing or sales or any other departm...", 
          "ga_event1": "sap_teched", 
          "ga_systemtype": "Prod", 
          "ga_product1": "sap_lumira", 
          "ga_targetkey": "sap_teched,sap_lumira,Lumira,within,Data,into,Website,Scraping,Visuals,Website", 
          "og:title": "Website to Visuals \u2013 Scraping Website into Data within SAP Lumira", 
          "ga_blog": "70221", 
          "og:image": "http://scn.sap.com/people/shankarsgs/avatar/social.png?a=41889", 
          "ga_blogpost": "122279", 
          "adslots": "scn_blog_ad,scn_blog_inhouse"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "160", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQtkqwcvoqrmF_i9JfuE7pBzrlMr83HAWPBzVsFxMQLgWK1bEiPnAYvAio", 
          "height": "160"
        }
      ], 
      "cse_image": [
        {
          "src": "http://scn.sap.com/people/shankarsgs/avatar/social.png?a=41889"
        }
      ]
    }, 
    "snippet": "Mar 12, 2015 ... Website to Visuals \u2013 Scraping Website into Data within SAP Lumira ... Read on to \nfind out how to scrape a website and bring in live data for\u00a0...", 
    "htmlSnippet": "Mar 12, 2015 <b>...</b> Website to Visuals \u2013 <b>Scraping Website</b> into Data within SAP Lumira ... Read on to <br>\nfind out <b>how to scrape a website</b> and bring in live data for&nbsp;...", 
    "link": "http://scn.sap.com/community/lumira/blog/2015/03/12/website-to-visuals-scraping-website-into-data-within-sap-lumira", 
    "cacheId": "45sYqWNVVlMJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Hire Web scraping Specialists - Upwork", 
    "displayLink": "www.upwork.com", 
    "htmlTitle": "Hire Web <b>scraping</b> Specialists - Upwork", 
    "formattedUrl": "https://www.upwork.com/o/profiles/browse/skill/web-scraping/", 
    "htmlFormattedUrl": "https://www.upwork.com/o/profiles/browse/skill/web-<b>scraping</b>/", 
    "pagemap": {
      "cse_thumbnail": [
        {
          "width": "80", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmPBDz4qsvxpJW191YzRSfQlmn97CY5ecNlC9-cwHDWaXIQyFjY4VA", 
          "height": "80"
        }
      ], 
      "cse_image": [
        {
          "src": "https://odesk-prod-portraits.s3.amazonaws.com/Users:daveman:PortraitUrl_100?AWSAccessKeyId=1XVAX3FNQZAFC9GJCFR2&Expires=2147483647&Signature=W0ZXkF3UuV6yT3bsSi%2F4WWZGFkA%3D"
        }
      ]
    }, 
    "snippet": "May 1, 2015 ... My experience lies in automated web scraping with well defined specifications \nincluding website and output format. Website data delivered\u00a0...", 
    "htmlSnippet": "May 1, 2015 <b>...</b> My experience lies in automated web <b>scraping</b> with well defined specifications <br>\nincluding <b>website</b> and output format. <b>Website</b> data delivered&nbsp;...", 
    "link": "https://www.upwork.com/o/profiles/browse/skill/web-scraping/", 
    "cacheId": "BiP4rZh29aYJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "ScrapeLogo | Logo database with an API", 
    "displayLink": "scrapelogo.com", 
    "htmlTitle": "<b>ScrapeLogo</b> | Logo database with an API", 
    "formattedUrl": "scrapelogo.com/", 
    "htmlFormattedUrl": "<b>scrape</b>logo.com/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "405", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcRLFrER37MZYxzINJ4b0WOMmhd7XU7M-H3QqVjQQnpLtWZTrPofEX8KkO8", 
          "height": "124"
        }
      ], 
      "cse_image": [
        {
          "src": "http://scrapelogo.com/wp-content/uploads/2012/12/frontpage.png"
        }
      ]
    }, 
    "snippet": "Knowing only the internet domain of a company, we scrape its logo from websites\n, social networks and public databases in 80% of the cases. Test it for yourself.", 
    "htmlSnippet": "Knowing only the internet domain of a company, we <b>scrape</b> its logo from <b>websites</b><br>\n, social networks and public databases in 80% of the cases. Test it for yourself.", 
    "link": "http://scrapelogo.com/", 
    "cacheId": "eXQs-qkKDZkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping Ajax and Javascript Sites | Data Big Bang Blog", 
    "displayLink": "blog.databigbang.com", 
    "htmlTitle": "Web <b>Scraping</b> Ajax and Javascript Sites | Data Big Bang Blog", 
    "formattedUrl": "blog.databigbang.com/web-scraping-ajax-and-javascript-sites/", 
    "htmlFormattedUrl": "blog.databigbang.com/web-<b>scraping</b>-ajax-and-javascript-sites/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "240", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcRLm95824XFbWz1yqgXnDQwJXYPAm_UX2_jVcmQyfSdAHdjsPO4WOdmlmc", 
          "height": "162"
        }
      ], 
      "cse_image": [
        {
          "src": "http://blog.databigbang.com/wp-content/uploads/2011/01/spider-bilbao-300x203.png"
        }
      ]
    }, 
    "snippet": "Jan 11, 2011 ... Most crawling frameworks used for scraping cannot be used for ... a lot of \nresources, especially if we need to scrape websites with a lot of pages\u00a0...", 
    "htmlSnippet": "Jan 11, 2011 <b>...</b> Most crawling frameworks used for scraping cannot be used for ... a lot of <br>\nresources, especially if we need to <b>scrape websites</b> with a lot of pages&nbsp;...", 
    "link": "http://blog.databigbang.com/web-scraping-ajax-and-javascript-sites/", 
    "cacheId": "1e_uBaVhFBcJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Python 2.7 Tutorial Pt 13 Website Scraping", 
    "displayLink": "www.newthinktank.com", 
    "htmlTitle": "Python 2.7 Tutorial Pt 13 <b>Website Scraping</b>", 
    "formattedUrl": "www.newthinktank.com/.../python-2-7-tutorial-pt-13-website-scraping/", 
    "htmlFormattedUrl": "www.newthinktank.com/.../python-2-7-tutorial-pt-13-<b>website</b>-<b>scraping</b>/", 
    "pagemap": {
      "cse_thumbnail": [
        {
          "width": "120", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTUcblJxjSGpsMQ1bLlTebLcKDWIw7u6NUuJYGZ81VnTii6mu1fut0l", 
          "height": "120"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.newthinktank.com/wp-content/uploads/2010/08/Python-Logo.gif"
        }
      ], 
      "hcard": [
        {
          "photo": "http://0.gravatar.com/avatar/cb6351fea8d51889b37901ae84d1f4f0?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "nickname": "Matt", 
          "fn": "Matt"
        }, 
        {
          "url": "http://www.newthinktank.com/", 
          "photo": "http://0.gravatar.com/avatar/674acf5b2ac00d1f1fc0f3dd40f74091?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "url_text": "admin", 
          "nickname": "admin", 
          "fn": "admin"
        }, 
        {
          "photo": "http://0.gravatar.com/avatar/cb6351fea8d51889b37901ae84d1f4f0?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "nickname": "Matt", 
          "fn": "Matt"
        }, 
        {
          "photo": "http://0.gravatar.com/avatar/cb6351fea8d51889b37901ae84d1f4f0?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "nickname": "Matt", 
          "fn": "Matt"
        }, 
        {
          "url": "http://www.newthinktank.com/", 
          "photo": "http://0.gravatar.com/avatar/674acf5b2ac00d1f1fc0f3dd40f74091?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "url_text": "admin", 
          "nickname": "admin", 
          "fn": "admin"
        }, 
        {
          "url": "http://www.newthinktank.com/", 
          "photo": "http://0.gravatar.com/avatar/674acf5b2ac00d1f1fc0f3dd40f74091?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "url_text": "admin", 
          "nickname": "admin", 
          "fn": "admin"
        }, 
        {
          "photo": "http://0.gravatar.com/avatar/cb6351fea8d51889b37901ae84d1f4f0?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "nickname": "Matt", 
          "fn": "Matt"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/74046c6d14172889622677ea42cede10?s=60&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "nickname": "Tito", 
          "fn": "Tito"
        }, 
        {
          "url": "http://www.newthinktank.com/", 
          "photo": "http://0.gravatar.com/avatar/674acf5b2ac00d1f1fc0f3dd40f74091?s=60&d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "url_text": "admin", 
          "nickname": "admin", 
          "fn": "admin"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/74046c6d14172889622677ea42cede10?s=60&d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&r=G", 
          "nickname": "Tito", 
          "fn": "Tito"
        }
      ]
    }, 
    "snippet": "Nov 12, 2010 ... As per what Website Scraping is. It is the act of removing information from one or \nmany sites using some automated program. I provide you a\u00a0...", 
    "htmlSnippet": "Nov 12, 2010 <b>...</b> As per what <b>Website Scraping</b> is. It is the act of removing information from one or <br>\nmany sites using some automated program. I provide you a&nbsp;...", 
    "link": "http://www.newthinktank.com/2010/11/python-2-7-tutorial-pt-13-website-scraping/", 
    "cacheId": "dSbCoYfgZ7UJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping the Web with Power Query | Disorderly Data", 
    "displayLink": "kzhendev.wordpress.com", 
    "htmlTitle": "<b>Scraping</b> the Web with Power Query | Disorderly Data", 
    "formattedUrl": "https://kzhendev.wordpress.com/.../scraping-the-web-with-power-query/", 
    "htmlFormattedUrl": "https://kzhendev.wordpress.com/.../<b>scraping</b>-the-web-with-power-query/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@kzhen", 
          "application-name": "Disorderly Data", 
          "twitter:image": "https://kzhendev.files.wordpress.com/2014/04/1-index-by-shape_thumb.png?w=240", 
          "og:locale": "en_US", 
          "twitter:site": "@kzhen", 
          "fb:app_id": "249643311490", 
          "article:publisher": "https://www.facebook.com/WordPresscom", 
          "msapplication-task": "name=Subscribe;action-uri=https://kzhendev.wordpress.com/feed/;icon-uri=https://s2.wp.com/i/favicon.ico", 
          "og:url": "https://kzhendev.wordpress.com/2014/04/14/scraping-the-web-with-power-query/", 
          "title": "Scraping the Web with Power\u00a0Query | Disorderly Data on WordPress.com", 
          "og:type": "article", 
          "msapplication-window": "width=device-width;height=device-height", 
          "article:modified_time": "2014-04-14T09:37:04+00:00", 
          "og:title": "Scraping the Web with Power Query", 
          "msapplication-tooltip": "My .Net and Business Intelligence Ramblings", 
          "article:author": "https://kzhendev.wordpress.com/author/kennyr/", 
          "og:image": "https://kzhendev.files.wordpress.com/2014/04/1-index-by-shape_thumb.png", 
          "article:published_time": "2014-04-14T08:36:08+00:00", 
          "viewport": "width=device-width", 
          "og:site_name": "Disorderly Data", 
          "twitter:card": "summary", 
          "og:description": "Last year I entered the PowerBI video demo contest. Whilst I didn\u2019t win any prizes I did learn a fair bit from going through the exercise of putting together a screencast demo (more on that another..."
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "117", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTUdrFtugl1pMMQgNV9CTwk5mpEkyVVEHrij7USl4E7DwyJOHqLCeH98o4", 
          "height": "195"
        }
      ], 
      "cse_image": [
        {
          "src": "https://kzhendev.files.wordpress.com/2014/04/1-index-by-shape_thumb.png"
        }
      ], 
      "hcard": [
        {
          "nickname": "Matt", 
          "fn": "Matt"
        }, 
        {
          "url": "https://kzhendev.wordpress.com/", 
          "url_text": "KenR", 
          "nickname": "KenR", 
          "fn": "KenR"
        }, 
        {
          "url": "https://kzhendev.wordpress.com/", 
          "url_text": "KenR", 
          "nickname": "KenR", 
          "fn": "KenR"
        }, 
        {
          "nickname": "Chris", 
          "fn": "Chris"
        }, 
        {
          "url": "https://kzhendev.wordpress.com/", 
          "url_text": "KenR", 
          "nickname": "KenR", 
          "fn": "KenR"
        }, 
        {
          "nickname": "ChrisG", 
          "fn": "ChrisG"
        }, 
        {
          "url": "https://kzhendev.wordpress.com/", 
          "url_text": "KenR", 
          "nickname": "KenR", 
          "fn": "KenR"
        }, 
        {
          "nickname": "ChrisG", 
          "fn": "ChrisG"
        }, 
        {
          "url": "https://kzhendev.wordpress.com/", 
          "url_text": "KenR", 
          "nickname": "KenR", 
          "fn": "KenR"
        }, 
        {
          "nickname": "ChrisG", 
          "fn": "ChrisG"
        }
      ]
    }, 
    "snippet": "Apr 14, 2014 ... In this post I'm going to walk-through the web scraping part of my demo. The \nwebsite that I choose to use for my demo was the National UFO\u00a0...", 
    "htmlSnippet": "Apr 14, 2014 <b>...</b> In this post I&#39;m going to walk-through the web <b>scraping</b> part of my demo. The <br>\n<b>website</b> that I choose to use for my demo was the National UFO&nbsp;...", 
    "link": "https://kzhendev.wordpress.com/2014/04/14/scraping-the-web-with-power-query/", 
    "cacheId": "I0hws2V1c3IJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Data Scraping and More With Ruby, Nokogiri, Sinatra and Heroku ...", 
    "displayLink": "hunterpowers.com", 
    "htmlTitle": "Data <b>Scraping</b> and More With Ruby, Nokogiri, Sinatra and Heroku <b>...</b>", 
    "formattedUrl": "hunterpowers.com/data-scraping-and-more-with-ruby-nokogiri-sinatra-and- heroku/", 
    "htmlFormattedUrl": "hunterpowers.com/data-<b>scraping</b>-and-more-with-ruby-nokogiri-sinatra-and- heroku/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "264", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSIZoLmEhQ0MLNS7-b7KRgCo1__u_PnCcNp9QQz1DOHCt0We9IT39mLEXiS", 
          "height": "191"
        }
      ], 
      "cse_image": [
        {
          "src": "http://hunterpowers.com/wp-content/uploads/2012/06/930.jpg"
        }
      ]
    }, 
    "snippet": "Jun 22, 2012 ... In this article, you will learn the basics of scraping and parsing data from websites \nwith Ruby and Nokogiri. You will then take this information\u00a0...", 
    "htmlSnippet": "Jun 22, 2012 <b>...</b> In this article, you will learn the basics of <b>scraping</b> and parsing data from <b>websites</b> <br>\nwith Ruby and Nokogiri. You will then take this information&nbsp;...", 
    "link": "http://hunterpowers.com/data-scraping-and-more-with-ruby-nokogiri-sinatra-and-heroku/", 
    "cacheId": "UdJSiIthjjUJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scrape Data Automatically Websites| Excel VBA Training| Video", 
    "displayLink": "www.familycomputerclub.com", 
    "htmlTitle": "<b>Scrape</b> Data Automatically <b>Websites</b>| Excel VBA Training| Video", 
    "formattedUrl": "www.familycomputerclub.com/scrpae-pull-data-from-websites-into-excel. html", 
    "htmlFormattedUrl": "www.familycomputerclub.com/scrpae-pull-data-from-<b>websites</b>-into-excel. html", 
    "pagemap": {
      "metatags": [
        {
          "alexaverifyid": "MTa3-H41LNn2mxzymgp5wry6e8k", 
          "author": "Family Computer Club"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "259", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTcSfN3A5gD9MwfVBQ3uBb4nD3yOLMZbGujkwHzJjSNRTvABYS8VIjcmVu6", 
          "height": "194"
        }
      ], 
      "cse_image": [
        {
          "src": "http://i.ytimg.com/vi/qbOdUaf4yfI/hqdefault.jpg"
        }
      ]
    }, 
    "snippet": "You can scrape, pull or get data from websites into Excel by performing a few \nsimple steps. 1. record a macro to find out how one or many tables or data can be\n\u00a0...", 
    "htmlSnippet": "You can <b>scrape</b>, pull or get data from <b>websites</b> into Excel by performing a few <br>\nsimple steps. 1. record a macro to find out how one or many tables or data can be<br>\n&nbsp;...", 
    "link": "http://www.familycomputerclub.com/scrpae-pull-data-from-websites-into-excel.html", 
    "cacheId": "YH83ohiv2msJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Scraping Definition", 
    "displayLink": "techterms.com", 
    "htmlTitle": "<b>Scraping</b> Definition", 
    "formattedUrl": "techterms.com/definition/scraping", 
    "htmlFormattedUrl": "techterms.com/definition/<b>scraping</b>", 
    "pagemap": {
      "metatags": [
        {
          "apple-itunes-app": "app-id=923672016, affiliate-data=11l68F"
        }
      ]
    }, 
    "snippet": "Sep 22, 2011 ... Scraping, or \"web scraping,\" is the process of extracting large amounts of \ninformation from a website. This may involve downloading several\u00a0...", 
    "htmlSnippet": "Sep 22, 2011 <b>...</b> <b>Scraping</b>, or &quot;web <b>scraping</b>,&quot; is the process of extracting large amounts of <br>\ninformation from a <b>website</b>. This may involve downloading several&nbsp;...", 
    "link": "http://techterms.com/definition/scraping", 
    "cacheId": "P4MeAuNyLeIJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Let's scrape the page, Using Python Beautiful Soup", 
    "displayLink": "kochi-coders.com", 
    "htmlTitle": "Let&#39;s <b>scrape</b> the page, Using Python Beautiful Soup", 
    "formattedUrl": "kochi-coders.com/.../lets-scrape-the-page-using-python-beautifulsoup/", 
    "htmlFormattedUrl": "kochi-coders.com/.../lets-<b>scrape</b>-the-page-using-python-beautifulsoup/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1.0"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "140", 
          "src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTruQ0yR7Uv1fEvqsPMhPabOrV5uCZ0BP3o5i2WQVIMXl7P5Y8yb3lC9AWq", 
          "height": "170"
        }
      ], 
      "cse_image": [
        {
          "src": "http://kochi-coders.com/wp-content/uploads/2014/01/9554OS_Mini_Cover.png"
        }
      ], 
      "hcard": [
        {
          "url": "http://dohmatob.blogspot.fr/", 
          "url_text": "dop", 
          "nickname": "dop", 
          "fn": "dop"
        }, 
        {
          "fn": "Bhupendrasinh Thakre"
        }, 
        {
          "nickname": "Anon", 
          "fn": "Anon"
        }, 
        {
          "nickname": "kk", 
          "fn": "kk"
        }, 
        {
          "url": "http://kochi-coders.com/", 
          "url_text": "Vineeth G Nair", 
          "fn": "Vineeth G Nair"
        }, 
        {
          "nickname": "ssdc", 
          "fn": "ssdc"
        }, 
        {
          "url": "http://kochi-coders.com/", 
          "url_text": "Vineeth G Nair", 
          "fn": "Vineeth G Nair"
        }, 
        {
          "fn": "Shailesh Patil"
        }, 
        {
          "url": "http://kochi-coders.com/", 
          "url_text": "Vineeth G Nair", 
          "fn": "Vineeth G Nair"
        }, 
        {
          "nickname": "Josh", 
          "fn": "Josh"
        }
      ]
    }, 
    "snippet": "May 30, 2011 ... Python script using Beautiful Soup to extract data from a website. ... Tutorial of \npython BeautifulSoup for a dummy, Web Scraping Using Python\u00a0...", 
    "htmlSnippet": "May 30, 2011 <b>...</b> Python script using Beautiful Soup to extract data from a <b>website</b>. ... Tutorial of <br>\npython BeautifulSoup for a dummy, Web <b>Scraping</b> Using Python&nbsp;...", 
    "link": "http://kochi-coders.com/2011/05/30/lets-scrape-the-page-using-python-beautifulsoup/", 
    "cacheId": "fH-znzs9nFkJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "A Content Marketer's Guide to Data Scraping - Moz", 
    "displayLink": "moz.com", 
    "htmlTitle": "A Content Marketer&#39;s Guide to Data <b>Scraping</b> - Moz", 
    "formattedUrl": "https://moz.com/blog/a-content-marketers-guide-to-data-scraping", 
    "htmlFormattedUrl": "https://moz.com/blog/a-content-marketers-guide-to-data-<b>scraping</b>", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@matthewbarby", 
          "og:url": "https://moz.com/blog/a-content-marketers-guide-to-data-scraping", 
          "og:image": "http://d1avok0lzls2w.cloudfront.net/img_users/393029.jpg?1348821332", 
          "og:site_name": "Moz", 
          "fb:admins": "22408537", 
          "twitter:description": "Taking advantage of big data doesn't necessarily require expensive tools. With a free plugin for Excel, you can scrape what you need directly into a spreadsheet and take matters into your own hands.", 
          "og:type": "article", 
          "og:description": "Taking advantage of big data doesn't necessarily require expensive tools. With a free plugin for Excel, you can scrape what you need directly into a spreadsheet and take matters into your own hands.", 
          "twitter:title": "A Content Marketer's Guide to Data Scraping", 
          "referer": "origin", 
          "og:title": "A Content Marketer's Guide to Data Scraping", 
          "twitter:card": "summary", 
          "twitter:site": "@Moz", 
          "fb:page_id": "8489236245", 
          "twitter:account_id": "15651700", 
          "viewport": "width=device-width, initial-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "74", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcR9aaH-fuI1ggr9R2ph8LWbJNZaQmht7dTzLIlPgnwvBKFS4oe6t8lN", 
          "height": "74"
        }
      ], 
      "cse_image": [
        {
          "src": "http://d1avok0lzls2w.cloudfront.net/img_users/393029.jpg?1348821332"
        }
      ]
    }, 
    "snippet": "Jun 2, 2014 ... Disclaimer: One thing that I really need to stress before you read on is the fact \nthat scraping a website may breach its terms of service.", 
    "htmlSnippet": "Jun 2, 2014 <b>...</b> Disclaimer: One thing that I really need to stress before you read on is the fact <br>\nthat <b>scraping a website</b> may breach its terms of service.", 
    "link": "https://moz.com/blog/a-content-marketers-guide-to-data-scraping", 
    "cacheId": "vN-bYQhwtGQJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Power Search by Inspyder - Search and Scrape Any Website", 
    "displayLink": "www.inspyder.com", 
    "htmlTitle": "Power Search by Inspyder - Search and <b>Scrape</b> Any <b>Website</b>", 
    "formattedUrl": "www.inspyder.com/products/PowerSearch/", 
    "htmlFormattedUrl": "www.inspyder.com/products/PowerSearch/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://www.inspyder.com/products/PowerSearch/Default.aspx", 
          "og:image": "http://www.inspyder.com/images/logos/logo_powersearch.png", 
          "slider_speed": "5000"
        }
      ], 
      "softwareapplication": [
        {
          "image": "http://www.inspyder.com/images/logos/logo_powersearch_sml.png", 
          "name": "Power Search 4", 
          "operatingsystems": "Windows"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "204", 
          "src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQKWozpf4DhzV2IQ7JCvt43qetaQBW0-mRtzuAmz9NpZgOSppidIXJ1-46C", 
          "height": "204"
        }
      ], 
      "cse_image": [
        {
          "src": "http://www.inspyder.com/images/logos/logo_powersearch.png"
        }
      ], 
      "review-aggregate": [
        {
          "rating": "4.4", 
          "votes": "184", 
          "datepublished": "2014-10-22", 
          "softwareversion": "4.1.0", 
          "filesize": "14950192", 
          "itemreviewed": "Power Search 4"
        }
      ]
    }, 
    "snippet": "Power Search from Inspyder is the easiest way to search and scrape data from \nvirtually any website. Crawl websites to look for specific words and phrases,\u00a0...", 
    "htmlSnippet": "Power Search from Inspyder is the easiest way to search and <b>scrape</b> data from <br>\nvirtually any <b>website</b>. Crawl <b>websites</b> to look for specific words and phrases,&nbsp;...", 
    "link": "http://www.inspyder.com/products/PowerSearch/", 
    "cacheId": "ZFjhKSGIxMgJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Data Scraping Wikipedia with Google Spreadsheets | OUseful.Info ...", 
    "displayLink": "blog.ouseful.info", 
    "htmlTitle": "Data <b>Scraping</b> Wikipedia with Google Spreadsheets | OUseful.Info <b>...</b>", 
    "formattedUrl": "blog.ouseful.info/.../data-scraping-wikipedia-with-google-spreadsheets/", 
    "htmlFormattedUrl": "blog.ouseful.info/.../data-<b>scraping</b>-wikipedia-with-google-spreadsheets/", 
    "pagemap": {
      "metatags": [
        {
          "twitter:creator": "@psychemedia", 
          "og:url": "http://blog.ouseful.info/2008/10/14/data-scraping-wikipedia-with-google-spreadsheets/", 
          "og:locale": "en_US", 
          "article:modified_time": "2013-02-05T17:28:49+00:00", 
          "application-name": "OUseful.Info, the blog...", 
          "twitter:card": "summary", 
          "twitter:image": "http://farm4.static.flickr.com/3286/2942047723_6b93f078ee.jpg?w=240", 
          "og:type": "article", 
          "og:description": "Prompted in part by a presentation I have to give tomorrow as an OU eLearning community session (I hope some folks turn up - the 90 minute session on Mashing Up the PLE - RSS edition is the only re...", 
          "msapplication-tooltip": "Trying to find useful things to do with emerging technologies in open education", 
          "article:author": "http://blog.ouseful.info/author/psychemedia/", 
          "msapplication-window": "width=device-width;height=device-height", 
          "title": "Data Scraping Wikipedia with Google\u00a0Spreadsheets | OUseful.Info, the blog... on WordPress.com", 
          "msapplication-task": "name=Subscribe;action-uri=http://blog.ouseful.info/feed/;icon-uri=http://s2.wp.com/i/favicon.ico", 
          "og:title": "Data Scraping Wikipedia with Google Spreadsheets", 
          "twitter:site": "@psychemedia", 
          "article:publisher": "https://www.facebook.com/WordPresscom", 
          "og:image": "http://farm4.static.flickr.com/3286/2942047723_6b93f078ee.jpg", 
          "article:published_time": "2008-10-14T22:21:09+00:00", 
          "viewport": "width=device-width", 
          "og:site_name": "OUseful.Info, the blog..."
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "274", 
          "src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTgNsu66H-6EUGKEB20B4TPWOP_KmfHIW4fxsi-XqYZVSOIhIvxcinmWwI", 
          "height": "184"
        }
      ], 
      "cse_image": [
        {
          "src": "http://farm4.static.flickr.com/3286/2942047723_6b93f078ee.jpg"
        }
      ]
    }, 
    "snippet": "Oct 14, 2008 ... Works even with password protected websites, Excel will ask you for your .... The \nonly issue I have is that the wiki I want to scrape data from is\u00a0...", 
    "htmlSnippet": "Oct 14, 2008 <b>...</b> Works even with password protected <b>websites</b>, Excel will ask you for your .... The <br>\nonly issue I have is that the wiki I want to <b>scrape</b> data from is&nbsp;...", 
    "link": "http://blog.ouseful.info/2008/10/14/data-scraping-wikipedia-with-google-spreadsheets/", 
    "cacheId": "d7BFQHCY07cJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraping: Creating APIs Where There Were None ACRL ...", 
    "displayLink": "acrl.ala.org", 
    "htmlTitle": "Web <b>Scraping</b>: Creating APIs Where There Were None ACRL <b>...</b>", 
    "formattedUrl": "acrl.ala.org/techconnect/?p=3850", 
    "htmlFormattedUrl": "acrl.ala.org/techconnect/?p=3850", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "http://acrl.ala.org/techconnect/?p=3850", 
          "og:title": "Web Scraping: Creating APIs Where There Were None", 
          "twitter:card": "summary", 
          "twitter:image": "http://acrl.ala.org/techconnect/wp-content/uploads/2013/09/doaj-search-results-300x242.png?w=240", 
          "og:type": "article", 
          "og:description": "Websites are human-readable. That's great for us, we're humans. It's not so great for computer programs, which tend to be better at navigating structured data rather than visuals. Web scraping is t...", 
          "article:author": "http://acrl.ala.org/techconnect?author_name=phette23", 
          "article:modified_time": "2013-11-02T02:44:38+00:00", 
          "twitter:site": "@jetpack", 
          "og:image": "http://acrl.ala.org/techconnect/wp-content/uploads/2013/09/doaj-search-results-300x242.png", 
          "article:published_time": "2013-09-30T14:06:37+00:00", 
          "og:site_name": "ACRL TechConnect Blog"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "240", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcStJKnYT1ZWuegClz0DRA33moTSO9QizdUsI8ldqeF6Ne8DJfi1y4Uwskc", 
          "height": "193"
        }
      ], 
      "cse_image": [
        {
          "src": "http://acrl.ala.org/techconnect/wp-content/uploads/2013/09/doaj-search-results-300x242.png"
        }
      ], 
      "hcard": [
        {
          "url": "http://twitter.com/bibliotechy", 
          "photo": "http://i0.wp.com/a0.twimg.com/profile_images/3429554246/2d615e24eaae2eb7dce0a97f6b1f80d9_normal.png?resize=26%2C26", 
          "url_text": "chad nelson (@bibliotechy)", 
          "fn": "chad nelson (@bibliotechy)"
        }, 
        {
          "url": "http://library.citytech.cuny.edu/", 
          "photo": "http://2.gravatar.com/avatar/bbf232239ec5cbe0ea18d35de2f7c930?s=26&d=mm&r=g", 
          "url_text": "Junior Tidal", 
          "fn": "Junior Tidal"
        }, 
        {
          "photo": "http://1.gravatar.com/avatar/4f831ebb3be036a072fcd1d90317e682?s=26&d=mm&r=g", 
          "fn": "Eric Phetteplace"
        }
      ]
    }, 
    "snippet": "Sep 30, 2013 ... Web scraping is the practice of \u201cscraping\u201d information from a website's HTML. At \nits core, web scraping lets programs visit and manipulate a\u00a0...", 
    "htmlSnippet": "Sep 30, 2013 <b>...</b> Web <b>scraping</b> is the practice of \u201c<b>scraping</b>\u201d information from a <b>website&#39;s</b> HTML. At <br>\nits core, web <b>scraping</b> lets programs visit and manipulate a&nbsp;...", 
    "link": "http://acrl.ala.org/techconnect/?p=3850", 
    "cacheId": "XGAQ8Na0h-MJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Get started with screenscraping using Google Chrome's Scraper ...", 
    "displayLink": "dataist.wordpress.com", 
    "htmlTitle": "Get started with screenscraping using Google Chrome&#39;s Scraper <b>...</b>", 
    "formattedUrl": "https://dataist.wordpress.com/.../get-started-with-screenscraping-using-google -chromes-scraper-extension/", 
    "htmlFormattedUrl": "https://dataist.wordpress.com/.../get-started-with-screen<b>scraping</b>-using-google -chromes-<b>scrape</b>r-extension/", 
    "pagemap": {
      "metatags": [
        {
          "og:url": "https://dataist.wordpress.com/2012/10/12/get-started-with-screenscraping-using-google-chromes-scraper-extension/", 
          "og:locale": "en_US", 
          "og:title": "Get started with screenscraping using Google Chrome's Scraper extension", 
          "application-name": "dataist", 
          "twitter:card": "summary", 
          "twitter:image": "https://dataist.files.wordpress.com/2012/10/add-to-chrome.png?w=240", 
          "og:type": "article", 
          "og:description": "How do you get information from a website to a Excel spreadsheet? The answer is screenscraping. There are a number of softwares and plattforms (such as OutWit Hub, Google Docs and Scraper Wiki) tha...", 
          "msapplication-tooltip": "a blog about data exploration", 
          "article:author": "https://dataist.wordpress.com/author/dataist/", 
          "fb:app_id": "249643311490", 
          "msapplication-window": "width=device-width;height=device-height", 
          "title": "Get started with screenscraping using Google Chrome\u2019s Scraper\u00a0extension | dataist on WordPress.com", 
          "article:modified_time": "2012-10-12T13:46:15+00:00", 
          "twitter:site": "@wordpressdotcom", 
          "article:publisher": "https://www.facebook.com/WordPresscom", 
          "og:image": "https://dataist.files.wordpress.com/2012/10/add-to-chrome.png?w=219", 
          "article:published_time": "2012-10-12T13:46:15+00:00", 
          "msapplication-task": "name=Subscribe;action-uri=https://dataist.wordpress.com/feed/;icon-uri=https://s2.wp.com/i/favicon.ico", 
          "og:site_name": "dataist"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "175", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcTOz6Z3kzNCkihHy0ob78vhumWX11AjtyZQOTKOHhDsyJCBf-tEbqUuKA", 
          "height": "39"
        }
      ], 
      "cse_image": [
        {
          "src": "https://dataist.files.wordpress.com/2012/10/add-to-chrome.png?w=219"
        }
      ], 
      "hcard": [
        {
          "url": "http://fajk.wordpress.com/2012/11/24/dokumentation-slidesen-klippen-tweetsen/", 
          "url_text": "Dokumentation: Slidesen, klippen, tweetsen \u00ab Fajk", 
          "fn": "Dokumentation: Slidesen, klippen, tweetsen \u00ab Fajk"
        }, 
        {
          "url": "http://blogs.albawaba.com/antonycarv", 
          "url_text": "Continued", 
          "nickname": "Continued", 
          "fn": "Continued"
        }, 
        {
          "url": "http://wallinside.com/post.php?id=3970787", 
          "url_text": "visit this website", 
          "fn": "visit this website"
        }, 
        {
          "url": "http://blogs.journalism.co.uk/2013/06/28/tip-scrape-web-pages-using-this-chrome-extension/", 
          "url_text": "#Tip: Scrape web pages using this Chrome extension | Editors Blog | Journalism.co.uk", 
          "fn": "#Tip: Scrape web pages using this Chrome extension | Editors Blog | Journalism.co.uk"
        }, 
        {
          "url": "http://multiplesclerosiscure.info/", 
          "url_text": "multiple sclerosis facts", 
          "fn": "multiple sclerosis facts"
        }, 
        {
          "url": "http://ahappycustomer.dreamhosters.com/dreamhost-coupons.html", 
          "url_text": "DreamHost Discount", 
          "fn": "DreamHost Discount"
        }, 
        {
          "url": "http://bookos.org/", 
          "url_text": "Anton", 
          "nickname": "Anton", 
          "fn": "Anton"
        }, 
        {
          "url": "http://www.ronxingqm.com/", 
          "url_text": "Tory Burch \u30d0\u30ea\u30fc \u8ca1\u5e03", 
          "fn": "Tory Burch \u30d0\u30ea\u30fc \u8ca1\u5e03"
        }, 
        {
          "url": "http://www.cnjgov.com/", 
          "url_text": "\u30d6\u30fc\u30c4 \u30d5\u30a1\u30c3\u30b7\u30e7\u30f3", 
          "fn": "\u30d6\u30fc\u30c4 \u30d5\u30a1\u30c3\u30b7\u30e7\u30f3"
        }, 
        {
          "url": "http://blog.chryswu.com/2013/02/27/tools-slides-links-tutorials-nicar13/", 
          "url_text": "Tools, Slides and Links from NICAR13 // Ricochet by Chrys Wu", 
          "fn": "Tools, Slides and Links from NICAR13 // Ricochet by Chrys Wu"
        }
      ]
    }, 
    "snippet": "Oct 12, 2012 ... How do you get information from a website to a Excel spreadsheet? ... Start by \nright-clicking the name of any person and chose Scrape similar.", 
    "htmlSnippet": "Oct 12, 2012 <b>...</b> How do you get information from a <b>website</b> to a Excel spreadsheet? ... Start by <br>\nright-clicking the name of any person and chose <b>Scrape</b> similar.", 
    "link": "https://dataist.wordpress.com/2012/10/12/get-started-with-screenscraping-using-google-chromes-scraper-extension/", 
    "cacheId": "lpewQImDr7YJ"
  }, 
  {
    "kind": "customsearch#result", 
    "title": "Web Scraper, Web Extractor, Screen Scraping, Web Ripper, Web ...", 
    "displayLink": "webextract.net", 
    "htmlTitle": "Web Scraper, Web Extractor, Screen <b>Scraping</b>, Web Ripper, Web <b>...</b>", 
    "formattedUrl": "webextract.net/", 
    "htmlFormattedUrl": "webextract.net/", 
    "pagemap": {
      "metatags": [
        {
          "viewport": "width=device-width, initial-scale=1, maximum-scale=1"
        }
      ], 
      "cse_thumbnail": [
        {
          "width": "361", 
          "src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSaZ55t9Qqe9HS9TbgVe3WUqXVh77De-3_M6tf4YvOOj_MHVhmpvYqBHjg", 
          "height": "140"
        }
      ], 
      "cse_image": [
        {
          "src": "http://webextract.net/images/sample/slide3.png"
        }
      ]
    }, 
    "snippet": "Web Data Pattern Specifying: Define what & where you want to scrape ... \nExtracted results can be posted to your website or created product price \ncomparision\u00a0...", 
    "htmlSnippet": "Web Data Pattern Specifying: Define what &amp; where you want to <b>scrape</b> ... <br>\nExtracted results can be posted to your <b>website</b> or created product price <br>\ncomparision&nbsp;...", 
    "link": "http://webextract.net/", 
    "cacheId": "Iy3q0x1T4DwJ"
  }
]